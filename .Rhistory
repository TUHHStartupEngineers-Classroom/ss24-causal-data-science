#| include: false
sysfonts::font_add_google("Poppins", "Poppins", regular.wt = 300)
showtext::showtext_auto()
source("../R/setup-ggplot2-tie.R")
#| echo: true
#| code-fold: true
#| code-summary: "Show code"
library(ggdag)
library(ggplot2)
coord_dag <- list(
x = c(SEM = 0, Intent = 1, Sales = 2),
y = c(SEM = 0, Intent = 1, Sales = 0)
)
dag <- ggdag::dagify(SEM ~ Intent,
Sales ~ SEM,
Sales ~ Intent,
coords = coord_dag)
dag %>%
ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
geom_dag_point(colour = "grey") +
geom_dag_edges() +
geom_dag_text(colour = "black", size = 5) +
theme_dag(legend.position = "none")
#| include: false
# sysfonts::font_add_google("Poppins", "Poppins", regular.wt = 300)
showtext::showtext_auto()
source("../assets/setup-ggplot2-tie.R")
#| echo: false
#| eval: true
# Load required packages
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
# suppress messages during fitting
lgr::get_logger("mlr3")$set_threshold("warn")
# load data as a data.table
data = fetch_401k(return_type = "data.table", instrument = TRUE)
# Set up basic model: Specify variables for data-backend
features_base = c("age", "inc", "educ", "fsize","marr", "twoearn", "db", "pira", "hown")
# Initialize DoubleMLData (data-backend of DoubleML)
data_dml_base = DoubleMLData$new(data,
y_col = "net_tfa", # outcome variable
d_cols = "e401", # treatment variable
x_cols = features_base) # covariates
# Initialize Random Forrest Learner
randomForest = lrn("regr.ranger")
randomForest_class = lrn("classif.ranger")
# Random Forest
set.seed(123)
dml_irm_forest = DoubleMLIRM$new(data_dml_base,
ml_g = randomForest,
ml_m = randomForest_class,
score = "ATE",
trimming_threshold = 0.01,
apply_cross_fitting = TRUE,
n_folds = 5)
# Set nuisance-part specific parameters
dml_irm_forest$set_ml_nuisance_params(
"ml_g0", "e401", list(max.depth = 6, mtry = 4, min.node.size = 7)) # learner for outcome 0
dml_irm_forest$set_ml_nuisance_params(
"ml_g1", "e401", list(max.depth = 6, mtry = 3, min.node.size = 5)) # learner for outcome 1
dml_irm_forest$set_ml_nuisance_params(
"ml_m", "e401", list(max.depth = 6, mtry = 3, min.node.size = 6)) # learner for treatment
dml_irm_forest$fit()
dml_irm_forest$summary()
# Get the indvidual ATEs (pseudo-outcomes)
data$ate_i <- dml_irm_forest[["psi_b"]] # get numerator of score function, which is equal to pseudo outcome
mean_ate = mean(data$ate_i) # mean of pseudo outcomes = ATE
library(estimatr) # for linear robust post estimation
summary(lm_robust(ate_i ~ hown, data = data))
#| echo: true
#| eval: false
library(np) # for kernel post estimation
age = data$age
ate_i = data$ate_i
np_model = npreg(ate_i ~ age)  # kernel regression
plot(np_model)  # plot the kernel regression
