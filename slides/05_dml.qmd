---
# TITLE & AUTHOR
title: "(5) Double Machine Learning"
subtitle: "Causal Data Science for Business Analytics"
author: "Christoph Ihl"
institute: "Hamburg University of Technology"
date: today
date-format: "dddd, D. MMMM YYYY"
# FORMAT OPTIONS
format: 
  revealjs:
    width: 1600
    height: 900
    footer: "Causal Data Science: (5) Double Machine Learning"
    slide-number: true
---



# Preliminaries {data-stack-name="Preliminaries"}


```{r}
#| include: false
sysfonts::font_add_google("Poppins", "Poppins", regular.wt = 300)
showtext::showtext_auto()
source("../R/setup-ggplot2-tie.R")
```


```{scss}
#| echo: false
div.callout-note {
  border-left-color: #00C1D4 !important;
}

div.callout-note.callout-style-default .callout-title {
  background-color: #005e73;
  color: white;
}

.callout.callout-style-default {
  border-left: solid #005e73 .3rem;
  border-right: solid 1px #005e73;
  border-top: solid 1px #005e73;
  border-bottom: solid 1px #005e73;
}

```




## Observed Confounding {.smaller}

- We need these assumptions:

::: {.callout-note icon=false}

## Assumption `A1`: "Conditional Exchangeability / Unconfoundedness / Ignorability / Independence".

$Y_i(t) \perp\!\!\!\perp T_i \mid \mathbf{X_i = x}, \forall t \in \{0,1,\dots\}, \text{ and } \mathbf{x} \in \mathbb{X}$.

:::


::: {.callout-note icon=false}

## Assumption `A2`: "Positivity / Overlap / Common Support".

$0 < P(T_i = t|\mathbf{X_i = x}), \forall t \in \{0,1,\dots\}, \text{ and } \mathbf{x} \in \mathbb{X}$.

:::


::: {.callout-note icon=false}

## Assumption `A3`: "Stable Unit Treatment Value Assumption (SUTVA)."

$Y_i = Y(T_i)$

:::

- ... to achieve identification of the ATE:

::: {.callout-note icon=false}

## Theorem: "Identification of the ATE":

$\tau_{\text{ATE}} = \mathbb{E}[Y_i(1)] - \mathbb{E}[Y_i(0)] = \mathbb{E_X}[\mathbb{E}[Y_i|T_i=1,\mathbf{X_i = x}] - \mathbb{E}[Y_i|T_i=0, \mathbf{X_i = x}]]$

:::


## Types of Parameters

Causal Machine Learning methods force us to distinguish between two types of parameters:

- 1. `Target parameter` is motivated by the research question and defined under modelling assumption,
  - e.g. effect of a treatment on some outcome.
- 2. `Nuisance parameters` are inputs that are required to obtain the target parameter, but are not relevant for our research question.
  - e.g. propensity scores. 

- Focus on the target parameter and do not get tempted to interpret every single coefficient from a regression.


## Frisch-Waugh-Lovell (FWL) Theorem

- We can estimate $\beta_T$ in a standard linear regression $Y_i = \beta_0 + \beta_T T_i + \mathbf{\beta_{X}' X_i} + \epsilon_i$ in a `three-stage procedure`:

1. Run a regression of the form $Y_i = \beta_{Y0} + \mathbf{\beta_{Y \sim X}' X_i} + \epsilon_{Y_i \sim X_i}$ and extract the estimated residuals $\hat\epsilon_{Y_i \sim X_i}$.

2. Run a regression of the form $T_i = \beta_{T0} + \mathbf{\beta_{T \sim X}' X_i} + \epsilon_{T_i \sim X_i}$ and extract the estimated residuals $\hat\epsilon_{T_i \sim X_i}$.

3. Run a residual-on-residual regression of the form $\hat\epsilon_{Y_i \sim X_i} = \beta_T \hat\epsilon_{T_i \sim X_i} + \epsilon_i$ (no constant).

The resulting estimate $\hat\beta_T$ is `numerically identical` to the estimate we would get if we just run the full OLS model.




## Target Parameters

- `Average potential outcome (APO)`: $\mu_t := \mathbb{E}[Y_i(t)]$.
  - What is the expected `outcome if everybody receives treatment t`?
- `Average Treatment Effect (ATE)`: $\tau_{\text{ATE}} := \mathbb{E}[Y_i(1)] -  \mathbb{E}[Y_i(0)] = \mu_1 - \mu_0$.
  - What is the expected treatment `effect in the population`?

::: {.fragment}

- Note that the target parameters are just `different aggregations of the Conditional Average Potential Outcome (CAPO)`: $\mathbb{E}[Y_i(t) \mid  \mathbf{X_i = x} ]$
  - $\mu_t := \mathbb{E}[Y_i(t)] \overset{LIE}{=} \mathbb{E}[\mathbb{E}[Y_i(t) \mid \mathbf{X_i = x}]]$
  - $\tau_{\text{ATE}} := \mathbb{E}[Y_i(1)] -  \mathbb{E}[Y_i(0)] \overset{LIE}{=} \mathbb{E}[\mathbb{E}[Y_i(1) \mid  \mathbf{X_i = x}]] - \mathbb{E}[\mathbb{E}[Y_i(0) \mid  \mathbf{X_i = x} ]]$.
- It suffices to show that the CAPO is identified.



:::

## General Approach

- Causal Machine Learning methods are mostly about `rewriting stuff` such that we are allowed to leverage `supervised ML to estimate the nuisance parameters`.
- Importantly, the `target parameters of interest remain the same` although the rewritten form can look quite different to the original/familiar model.
- The methods usually boil down to running `multiple supervised ML regressions` and combining their predictions into a `final OLS regression`.
- Supervised ML holds the promise of `data-driven model selection` and `complex non-linear relationships`, and thus, `getting (one of) the nuisance parameters right`.
- The crucial point is that the `statistical inference in this final OLS regression is valid if we follow a particular recipe`.
  - Recipe of how to split the estimation of causal effects into prediction tasks.











# Doubly Robust Methods {data-stack-name="Doubly Robust Methods"}

## Doubly Robust Methods: Idea {.smaller}

- Given the three assumptions hold, we have seen two ways to identify the ATE: $\tau_{\text{ATE}} = \mathbb{E}[Y_i(1)] - \mathbb{E}[Y_i(0)] = \mu_1 - \mu_0$

::: {.fragment}


- `Conditional outcome regression:` 
  - $\tau_{\text{ATE}} = \mathbb{E_X}[\mathbb{E}[Y_i | T_i = 1, \mathbf{X_i = x}] - \mathbb{E}[Y_i | T_i = 0, \mathbf{X_i = x}]]$
  - Simplified notation with `nuisance parameter` $\mu(t, \mathbf{x}) = \mathbb{E}[Y_i | T_i = t, \mathbf{X_i = x}]$ as conditional average potential outcome:
  - $\tau_{\text{ATE}} = \mathbb{E_X}[\mu(t = 1, \mathbf{x}) - \mu(t=0,\mathbf{x})]$

::: 

::: {.fragment}
- `Inverse probability weighting:` 
  - $\tau_{\text{ATE}} = \mathbb{E}\left[\frac{T_i Y_i}{P(T_i = 1 \mid \mathbf{X_i = x})}\right] - \mathbb{E}\left[\frac{(1 - T_i) Y_i}{1 - P(T_i = 1 \mid \mathbf{X_i})}\right]$ 
  - $\tau_{\text{ATE}} = \mathbb{E}\left[\frac{T_i Y_i}{PS(\mathbf{X_i})}\right] - \mathbb{E}\left[\frac{(1 - T_i) Y_i}{1 - PS(\mathbf{X_i})}\right]$
  - Simplified notation with `nuisance parameter` $e_t(\mathbf{x}) = P(T_i = t \mid \mathbf{X_i = x})$ as propensity score:
  - $\tau_{\text{ATE}} = \mathbb{E}\left[\frac{\mathbb{1}(T_i = 1) Y_i}{e_{t=1}(\mathbf{x})}\right] - \mathbb{E}\left[\frac{\mathbb{1}(T_i = 0) Y_i}{e_{t=0}(\mathbf{x})}\right]$

::: 

::: {.fragment}
- Idea of `doubly robust` methods: 
  - Combine both approaches, such that the ATE estimator is consistent, `even if only one of the two models is correctly specified`. 
::: 


## Doubly Robust Estimator: Definition {.smaller}

- `Doubly robust` or `Augmented Inverse Propensity Score Weighting (AIPW)` estimator:
- Conditional average potential outcome (CAPO) given by:

$$
\begin{align*}
\mu_t^{\text{AIPW}}(\mathbf{x}) := \mathbb{E}[Y_i(t) | \mathbf{X_i = x}] &\overset{(A1,A3)}{=} \mathbb{E}[Y_i | T_i = 0, \mathbf{X_i = x}] := \mu(t, \mathbf{x}) \\
&\text{(conditional outcome regression)} \\
&\overset{(2)}{=} \mathbb{E}\left[\frac{\mathbb{1}(T_i = t)Y_i}{e_t(x)} \bigg| \mathbf{X_i = x}\right] \\
&\text{(inverse probability weighting)} \\
&\overset{(3)}{=} \mathbb{E}\bigg[\mu(t, \mathbf{x}) + \frac{\mathbb{1}(T_i = t)(Y_i - \mu(t, \mathbf{x}))}{e_t(\mathbf{x})} \bigg| \mathbf{X_i = x}\bigg] \\
&\text{(augmenting outcome regression with IPW weights)} \\
\end{align*}
$$

::: {.fragment}
  - Average potential outcome (APO) given by:

    $$\mu_t^{\text{AIPW}} = \mathbb{E_x}\bigg[\mathbb{E}\bigg[\mu(t, \mathbf{x}) + \frac{\mathbb{1}(T_i = t)(Y_i - \mu(t, \mathbf{x}))}{e_t(\mathbf{x})} \bigg| \mathbf{X_i = x}\bigg] \bigg] = \mathbb{E}\bigg[\mu(t, \mathbf{x}) + \frac{\mathbb{1}(T_i = t)(Y_i - \mu(t, \mathbf{x}))}{e_t(\mathbf{x})} \bigg] \\$$
:::


## Doubly Robust Estimator: Proof {.smaller}


- Proof for Equation (2):


$$
\begin{align*}
\mu_t(\mathbf{x}) := \mathbb{E}[Y_i(t) | \mathbf{X_i = x}] &= \mathbb{E}[Y_i | T_i = 0, \mathbf{X_i = x}]\\
&= \mathbb{E}[\underbrace{\mathbb{1}(T_i = t)}_{=1} Y_i \mid T_i = t, \mathbf{X_i = x}]\\
&= \mathbb{E}\left[ \mathbb{1}(T_i = t) \frac{e_t(\mathbf{x})}{e_t(\mathbf{x})} \mid {T_i = t, \mathbf{X_i = x}}\right] + (1 - e_t(\mathbf{x})) \mathbb{E}[\underbrace{\mathbb{1}(T_i = t)}_{=0} Y_i \mid T_i \neq t, \mathbf{X_i = x}]/e_t(\mathbf{x})\\
&= \frac{\overbrace{e_t(\mathbf{x}) \mathbb{E}[\mathbb{1}(T_i = t) Y_i \mid T_i = t, \mathbf{X_i = x}] + (1 - e_t(\mathbf{x})) \mathbb{E}[\mathbb{1}(T_i = t) Y_i \mid T_i \neq t, \mathbf{X_i = x}]}^{\overset{LIE}{=}\mathbb{E}[\mathbb{1}(T_i = t) Y_i | \mathbf{X_i = x}]}}{e_t(\mathbf{x})} \\
&= \frac{\mathbb{E}\left[\mathbb{1}(T_i = t)Y_i \mid \mathbf{X_i = x} \right]}{e_t(\mathbf{x})} = \mathbb{E}\left[\frac{\mathbb{1}(T_i = t)Y_i}{e_t(\mathbf{x})} \bigg| \mathbf{X_i = x}\right]
\end{align*}
$$

## Doubly Robust Estimator: Proof {.smaller}


- Proof for Equation (3):


$$
\begin{align*}
\mu_t(\mathbf{x}) := \mathbb{E}[Y_i(t) | \mathbf{X_i = x}] &= \mathbb{E}\left[\mu(t, \mathbf{x}) + \frac{\mathbb{1}(T_i = t)(Y_i - \mu(t, \mathbf{x}))}{e_t(\mathbf{x})} \bigg| \mathbf{X_i = x}\right] \\
&= \mathbb{E}\left[Y_i(t) - Y_i(t) + \mu(t, \mathbf{x}) + \frac{\mathbb{1}(T_i = t)(Y_i - \mu(t, \mathbf{x}))}{e_t(\mathbf{x})} \bigg| \mathbf{X_i = x}\right] \\
&= \mathbb{E}\left[Y_i(t) - Y_i(t) + \mu(t, \mathbf{x}) + \frac{\mathbb{1}(T_i = t)(Y_i(t) - \mu(t, \mathbf{x}))}{e_t(\mathbf{x})} \bigg| \mathbf{X_i = x}\right] \\
&= \mathbb{E}[Y_i(t) \mid \mathbf{X_i = x}] + \mathbb{E} \left[(Y_i(t) - \mu(t, \mathbf{x})) \bigg(\frac{\mathbb{1}(T_i = t) - e_t(\mathbf{x})}{e_t(\mathbf{x})}\bigg) \bigg| \mathbf{X_i = x} \right] \\
&\overset{(4)}{=} \mu_t(\mathbf{x}) + \underbrace{\mathbb{E} \left[ (Y_i(t) - \mu(t, \mathbf{x})) \bigg(\frac{\mathbb{1}(T_i = t) - e_t(\mathbf{x})}{e_t(\mathbf{x})}\bigg) \bigg| \mathbf{X_i = x} \right]}_{\text{needs to be 0 for the conditional APO to be identified}}
\end{align*}
$$


## Doubly Robust Estimator: Proof {.smaller}


- Proof for Equation (4):

- Let $\tilde{\mu}(t,\mathbf{x})$ and $\tilde{e}_{t}(\mathbf{x})$ be some candidate functions for the conditional outcome regression and the propensity score, respectively. 

$$
\begin{align*}
\mathbb{E} \left[ (Y_i(t) - \tilde{\mu}(t, \mathbf{x})) \bigg(\frac{\mathbb{1}(T_i = t) - \tilde{e}_t(\mathbf{x})}{\tilde{e}_t(\mathbf{x})}\bigg) \bigg| \mathbf{X_i = x} \right] &= \mathbb{E} [ (Y_i(t) - \tilde{\mu}(t, \mathbf{x})) \mid \mathbf{X_i = x}] \mathbb{E} \left[ \bigg(\frac{\mathbb{1}(T_i = t) - \tilde{e}_t(\mathbf{x})}{\tilde{e}_t(\mathbf{x})}\bigg) \bigg| \mathbf{X_i = x} \right] \\
&\text{(ignorability allows to separate expectations)} \\
&= (\mathbb{E} [ Y_i(t) \mid \mathbf{X_i = x}] - \tilde{\mu}(t, \mathbf{x}))   \bigg(\frac{\mathbb{E} [\mathbb{1}(T_i = t \mid \mathbf{X_i = x} ] - \tilde{e}_t(\mathbf{x})}{\tilde{e}_t(\mathbf{x})}\bigg)  \\
&= (\mu_t(\mathbf{x}) - \tilde{\mu}(t, \mathbf{x})) \frac{(e_t(\mathbf{x}) - \tilde{e}_t(\mathbf{x}))}{\tilde{e}_t(\mathbf{x})} \\
\end{align*}
$$

::: {.fragment}

- the last expression becomes 0 if either $\tilde{\mu}(t, \mathbf{x}) = \mu_t(\mathbf{x})$ or $\tilde{e}_t(\mathbf{x}) = e_t(\mathbf{x})$.

:::


## Doubly Robust Estimator: Theorem

- Augmentation leads to the following theoretical properties:

::: {.callout-note icon=false}

## Theorem 4.3: "Doubly Robust Estimator".

Given $Y_i(t) \perp\!\!\!\perp T_i \mid \mathbf{X_i = x}$ (conditional unconfoundedness) and given $0 < P(T_i = t|\mathbf{X_i = x}), \forall t$ (positivity), then:

(1) If either $\tilde{e}_{t}(\mathbf{x}) = e_t(\mathbf{x})$ or $\tilde{\mu}(t = 1,\mathbf{x}) = \mu_1(\mathbf{x})$, then $\mu_{1} = \mathbb{E}[Y_i(1)]$

(1) If either $\tilde{e}_{t}(\mathbf{x}) = e_t(\mathbf{x})$ or $\tilde{\mu}(t = 0,\mathbf{x}) = \mu_0(\mathbf{x})$, then $\mu_{0} = \mathbb{E}[Y_i(0)]$

(3) If either $\tilde{e}_{t}(\mathbf{x}) = e_t(\mathbf{x})$ or $\tilde{\mu}(t = 1,\mathbf{x}) = \mu_1(\mathbf{x}), \tilde{\mu}(t = 0,\mathbf{x}) = \mu_0(\mathbf{x})$, then $\mu_{1} - \mu_{0} = \tau_{\text{ATE}}$

:::

- with $\tilde{\mu}(t,\mathbf{x})$ and $\tilde{e}_{t}(\mathbf{x})$ being some candidate functions for the conditional outcome regression and the propensity score, respectively. 


## Doubly Robust Estimator: Theorem {.smaller}


- `Proof` showing that $\mu_{t} = \mathbb{E}[Y_i(t)]$:

$$
\begin{align*}
\tilde{\mu}_{t} - \mathbb{E}[Y_i(t)] &= \mathbb{E}\bigg[\tilde{\mu}(t, \mathbf{x}) + \frac{\mathbb{1}(T_i = t)(Y_i - \tilde{\mu}(t, \mathbf{x}))}{\tilde{e}_t(\mathbf{x})} \bigg] -  \mathbb{E}[Y_i(t)] &\text{(by defintion)} \\
&= \mathbb{E}\bigg[\frac{\mathbb{1}(T_i = t)(Y_i - \tilde{\mu}(t, \mathbf{x}))}{\tilde{e}_t(\mathbf{x})} - (Y_i(t) -  \tilde{\mu}(t, \mathbf{x}))\bigg] &\text{(linearity of expectations)} \\
&= \mathbb{E}\left[\frac{\mathbb{1}(T_i = t) - \tilde{e}_t(\mathbf{x})}{\tilde{e}_t(\mathbf{x})}(Y_i(t) - \tilde{\mu}(t, \mathbf{x}))\right] &\text{(combining terms)} \\
&= \mathbb{E}\left(\mathbb{E}\left[\frac{\mathbb{1}(T_i = t) - \tilde{e}_t(\mathbf{x})}{\tilde{e}_t(\mathbf{x})}(Y_i(t) - \tilde{\mu}(t, \mathbf{x}) \bigg| \mathbf{X_i}\right]\right) &\text{(law of iterated expectations)} \\
&= \mathbb{E}\left(\mathbb{E}\left[\frac{\mathbb{1}(T_i = t) - \tilde{e}_t(\mathbf{x})}{\tilde{e}_t(\mathbf{x})} \bigg| \mathbf{X_i}\right] \cdot \mathbb{E}\left[Y_i(t) - \tilde{\mu}(t, \mathbf{x})  \bigg| \mathbf{X_i}\right]\right) &\text{(ignorability allows to separate expectations)} \\
&= \mathbb{E}\left( \frac{(e_t(\mathbf{x}) - \tilde{e}_t(\mathbf{x}))}{\tilde{e}_t(\mathbf{x})}(\mu_t(\mathbf{x}) - \tilde{\mu}(t, \mathbf{x}))\right) \\
\end{align*}
$$



## Doubly Robust Estimator: Sample Version

- `Step 1`: obtain the fitted values of the propensity scores: 
  - $\hat{e}_t(\mathbf{X_i})$
- `Step 2`: obtain the fitted values of the outcome regressions: 
  - $\hat{\mu}(t, \mathbf{X_i})$.
- `Step 3`: construct the doubly robust estimator: 
  - $\hat{\tau}_{\text{ATE}} = \hat{\mu}_{1} - \hat{\mu}_{0}$ with

  - $\hat{\mu}_{1} = \frac{1}{n} \sum_{i=1}^n \left[\hat{\mu}(t= 1, \mathbf{X_i}) + \frac{\mathbb{1}(T_i = 1)(Y_i - \hat{\mu}(t = 1, \mathbf{ X_i})}{\hat{e}_1(\mathbf{X_i})}\right]$

  - $\hat{\mu}_{0} = \frac{1}{n} \sum_{i=1}^n \left[\hat{\mu}(t= 0, \mathbf{X_i}) + \frac{\mathbb{1}(T_i = 0)(Y_i - \hat{\mu}(t = 0, \mathbf{ X_i})}{\hat{e}_0(\mathbf{X_i})}\right]$


## Doubly Robust Estimator: Example {.smaller}

- Assess the impact of participating in the U.S. National Supported Work (NSW) training program targeted to 445 individuals with social and economic problems on their real earnings. 


```{r}
#| echo: true

library(Matching)                       # load Matching package
data(lalonde)                           # load lalonde data
attach(lalonde)                         # store all variables in own objects
library(drgee)                          # load drgee package
T = treat                              # define treatment (training)
Y = re78                                # define outcome 
X = cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates
dr = drgee(oformula = formula(Y ~ X), eformula = formula(T ~ X), elink="logit") # DR reg
summary(dr)                             # show results

```


# Double Machine Learning with Partially Linear Regression {data-stack-name="DML-PLR"}

## Partially Linear Regression Model

- Observed $Y_i$ and $T_i$ are a partially linear function of confounding variables $X_i$:
  $\begin{align}\begin{aligned}Y_i = \tau T_i + g(\mathbf{X_i}) + \epsilon_{Y_i}, & &\mathbb{E}(\epsilon_{Y_i} | T_i,\mathbf{X_i}) = 0 \\T_i = m(\mathbf{X_i}) + \epsilon_{T_i}, & &\mathbb{E}(\epsilon_{T_i} | \mathbf{X_i}) = 0\end{aligned}\end{align}$

::: {.fragment}

- Conditional average potential outcome: 
  - $\mathbb{E}[Y_i(t) | \mathbf{X_i}] \overset{(A1, A3)}{=} \mathbb{E}[Y_i | T_i = t, \mathbf{X_i}] = \tau t + g(\mathbf{X_i})$

:::


::: {.fragment}

- Target parameters:
  - $\tau_{\text{CATE}} = \mathbb{E}[Y_i | T_i = 1, \mathbf{X_i}] - \mathbb{E}[Y_i | T_i = 0, \mathbf{X_i}]$
  - $\tau_{\text{CATE}} = (\tau 1 + g(\mathbf{X_i})) - (\tau 0 + g(\mathbf{X_i})) = \tau$
  - $\tau_{\text{ATE}} = \mathbb{E_X}[\beta_T] = \tau$
  - => homogeneous treatment effects

:::

## Identification under Partial Linearity {.smaller}

- Following [Robinson (1988)](https://journals.sagepub.com/doi/10.1177/00491241221099552), we can write the partially linear regression model as a generalization of the Frisch-Waugh-Lovell theorem:
  - $\underbrace{Y_i - \overbrace{\mathbb{E}[Y_i \mid \mathbf{X_i}]}^{\mu(\mathbf{X_i})}}_{\text{outcome residual}} = \tau \underbrace{( T_i - \overbrace{\mathbb{E}[T_i \mid \mathbf{X_i}]}^{e(\mathbf{X_i})})}_{\text{treatment residual}} + \epsilon_{Y_i}$
  
::: {.fragment}

- $\tau_{\text{ATE}}$ is identified by a residual-on-residual regression without constant:
  - Population estimand: 
    - $\tau_{\text{ATE}} = \arg \min_{\tilde{\tau}} \mathbb{E}[( \underbrace{ Y_i - \mu(\mathbf{X_i})}_{\text{pseudo outcome}} - \tilde{\tau} \underbrace{( T_i - e(\mathbf{X_i}))}_{\text{single regressor}})^2] = \frac{\text{Cov}[(Y_i - \mu(\mathbf{X_i})) (T_i - e(\mathbf{X_i}))]}{\text{Var}[T_i - e(\mathbf{X_i})]}$
  - Sample estimator: 
    - $\hat{\tau}_{\text{ATE}} = \arg \min_{\tilde{\tau}} \frac{1}{N}\sum_{i=1}^n ( \underbrace{Y_i - \mu(\mathbf{X_i})}_{\text{pseudo outcome}} - \tilde{\tau} \underbrace{( T_i - e(\mathbf{X_i}))}_{\text{single regressor}})^2 = \frac{\sum_{i=1}^n (Y_i - \mu(\mathbf{X_i})) (T_i - e(\mathbf{X_i}))}{\sum_{i=1}^n (T_i - e(\mathbf{X_i}))^2}$

:::

::: {.fragment}
-  However, regression not feasible because nuisance parameters unknown: ML toolbox might be useful.
::: 


## Double Machine Learning under Partial Linearity 



- [Chernozhukov et al. (2018)](https://doi.org/10.1111/ectj.12097) propose a three step procedure:

  1. Form prediction model for the treatment: $\hat{e}(\mathbf{X_i})$
  
  2. Form prediction model for the outcome: $\hat{\mu}(\mathbf{X_i})$
  
  3. Run feasible residual-on-residual regression: 
    - $\hat{\tau}_{\text{ATE}} = \arg \min_{\tilde{\tau}} \frac{1}{N}\sum_{i=1}^n ( Y_i - \hat{\mu}(\mathbf{X_i}) - \tilde{\tau} ( T_i - \hat{e}(\mathbf{X_i})))^2 = \frac{\sum_{i=1}^n (Y_i - \hat{\mu}(\mathbf{X_i})) (T_i - \hat{e}(\mathbf{X_i}))}{\sum_{i=1}^n (T_i - \hat{e}(\mathbf{X_i}))^2}$



::: {.fragment}

- Predictions of nuisance parameters $\hat{e}(\mathbf{X_i})$ and  $\hat{\mu}(\mathbf{X_i})$ have to fulfill `two conditions`:
  1. `High-quality`: consistency and convergence rates faster than $N^{\frac{1}{4}}$.
  2. `Out-of-sample`: individual predictions formed without the observation itself.
  
  => `standard (robust) OLS inference` is valid (see [Chernozhukov et al. (2018)](https://doi.org/10.1111/ectj.12097)).

:::

## High Quality Predictions in DML

- `Consistency`: ML methods converge to the true nuisance parameters as $N \to \infty$.
- `Convergence rate`:
  - Parametric models like OLS converge at the rate $N^{\frac{1}{2}}$: 
    - RMSE ($\mathbb{E}[\sqrt{(\hat{\mu}(\mathbf{X_i}) - \mu(\mathbf{X_i}))^2}]$) expected to halve if sample increases by factor four
  - ML methods usually do not converge as quickly because they can not leverage the structural information of a parametric model.
  - For Double ML to work, it suffices that the RMSE more than halves if we increase sample size by factor 16 (convergence rate: $N^{\frac{1}{4}}$).
  - Achievable with popular ML methods like [(Post-) LASSO](https://projecteuclid.org/journals/bernoulli/volume-19/issue-2/Least-squares-after-model-selection-in-high-dimensional-sparse-models/10.3150/11-BEJ410.full), [Random Forests](https://arxiv.org/abs/2007.03210), or [Neural Networks](https://www.econometricsociety.org/publications/econometrica/2021/01/01/deep-neural-networks-estimation-and-inference) .




## Out-of-Sample Predictions in DML {.smaller}

::: {.columns}


::: {.column width="50%"}

- `K-fold Cross-Fitting`:
  - Split the sample into $K$ folds.
  - For each fold $k$, train a prediction model for the nuisance parameters on the remaining $K-1$ folds.
  - Predict the nuisance parameters for fold $k$ using the model trained on the remaining $K-1$ folds.
  - Repeat for all $K$ folds to obtain predictions for each individual observation in each fold.
  - Use combined predictions for the residual-on-residual regression.

:::


::: {.column width="50%"}


![](_images/_5/cross_validation.jpg){fig-align="center" height=70% width=70%}
:::

:::


::: {.fragment}

=> Predictions are formed without the observation itself, still no waste of information.

=> Nuisance parameters induce `no bias by overfitting` ([Chernozhukov et al. (2018)](https://doi.org/10.1111/ectj.12097)).

::: 


## Neyman-orthogonal Score Functions {.smaller}

- Predicted nuisance parameters have to be used in a `Neyman-orthogonal score function` (score) $\psi$! 
- $\psi$ has to satisfy `moment condition` $\mathbb{E}[\psi(Y_i,T_i,\hat{\tau}, \hat{\mu}(\mathbf{X_i}), \hat{e}(\mathbf{X_i}))] = 0$ to identify the target parameter $\tau_{\text{ATE}}$.
- In PLR, $\psi$ is the solution to the minimization problem of the residual-on-residual regression - derivative w.r.t. $\hat{\tau}$:

$$\begin{align*}
&\frac{1}{N} \sum_{i=1}^N \underbrace{(Y_i - \hat{\mu}(\mathbf{X_i}) - \hat{\tau}(T_i - \hat{e}(\mathbf{X_i}))) (T_i - \hat{e}(X_i))}_{\psi(Y_i, T_i, \hat{\tau}, \hat{\mu}(\mathbf{X_i}), \hat{e}(\mathbf{X_i}))} = 0 \\
\Rightarrow \hat{\tau}_{\text{ATE}} &= \frac{\sum_{i=1}^n (Y_i - \hat{\mu}(\mathbf{X_i})) (T_i - \hat{e}(\mathbf{X_i}))}{\sum_{i=1}^n (T_i - \hat{e}(\mathbf{X_i}))^2}
\end{align*}$$



::: {.fragment}

- `Neyman-orthogonality` of score $\psi(Y_i,T_i,\hat{\tau}, \hat{\mu}(\mathbf{X_i}), \hat{e}(\mathbf{X_i}))$:
  - (Gateaux) derivative of the score function with respect to the nuisance parameters is zero in expectation at the true value of the nuisance parameters:
    - $\partial_r \mathbb{E}[\psi(Y_i, T_i, \hat{\tau}, \mu(\mathbf{X_i}) + r(\mu(\mathbf{X_i}) - \hat{\mu}(\mathbf{X_i})), e(\mathbf{X_i}) + r(e(\mathbf{X_i}) - \hat{e}(\mathbf{X_i})))]\mid_{r=0} = 0$
  - Ensures that the $\hat{\tau}$ is robust against biases in the prediction of nuisance parameters (e.g. by regularization).
  - Note (without proof): residual-on-residual regression fulfills this requirement!

:::



## Overcoming Regularization & Overfitting Bias {.smaller}

- Compare a non-orthogonal score function, e.g. $\hat{\tau}_{\text{ATE}} = \frac{\sum_{i=1}^n T_i (Y_i - \hat{\mu}(\mathbf{X_i}))}{\sum_{i=1}^n T_i^2}$ to orthogonal one: $\hat{\tau}_{\text{ATE}} = \frac{\sum_{i=1}^n (Y_i - \hat{\mu}(\mathbf{X_i})) (T_i - \hat{e}(\mathbf{X_i}))}{\sum_{i=1}^n (T_i - \hat{e}(\mathbf{X_i}))^2}$.



::: {.columns}


::: {.column width="50%"}

- Compare with and without K-fold Cross-Fitting.


```{r}
#| echo: false

# simulating the data
library(DoubleML)
library(ggplot2)
library(data.table)

set.seed(1234)
n_rep = 1000 # number samples
n_obs = 500 # number of observations
n_vars = 20 # number of covariates
alpha = 0.5 # true treatment effect


data = list()
for (i_rep in seq_len(n_rep)) {
  # command to simulate Y_i and T_i based on true non-linear nuisance functions m(x) and e(x)
  data[[i_rep]] = make_plr_CCDDHNR2018(alpha=alpha, n_obs=n_obs, dim_x=n_vars,
                                       return_type="data.frame")
}

# to speed up the illustration we hard-code the simulation results
theta_nonorth = c(0.555490805, 0.626761547, 0.527232714, 0.590215088, 0.379737837, 0.398791295, 0.471529799, 0.447306859, 0.398580212, 0.544042875, 0.580504564, 0.474363062, 0.544946070, 0.492569324, 0.476388613, 0.432095547, 0.463801034, 0.538834518, 0.498974469, 0.541736784, 0.556051749, 0.414388248, 0.465484169, 0.523789310, 0.450045410, 0.462671128, 0.483402627, 0.665449409, 0.444034892, 0.571431921, 0.514748934, 0.504854642, 0.543430321, 0.607804819, 0.425343408, 0.461166556, 0.473782998, 0.626301926, 0.554365067, 0.498898748, 0.539603020, 0.588260718, 0.392087266, 0.563189621, 0.622539334, 0.603381790, 0.537399218, 0.450688767, 0.506590096, 0.375848237, 0.518585287, 0.549772758, 0.621927569, 0.488298153, 0.590428253, 0.696371638, 0.627708633, 0.433970065, 0.425033876, 0.537542890, 0.480869086, 0.458919543, 0.653851249, 0.584819357, 0.587246769, 0.459961246, 0.518142266, 0.511701654, 0.620336868, 0.476887219, 0.481538784, 0.616313409, 0.529185572, 0.618412368, 0.522084966, 0.580750958, 0.477682206, 0.574414735, 0.508342507, 0.371303328, 0.527577838, 0.398635240, 0.494730015, 0.508128512, 0.603642166, 0.655167716, 0.601126516, 0.440808052, 0.544282497, 0.708230201, 0.541813291, 0.378489246, 0.437844992, 0.580074282, 0.426458304, 0.644148033, 0.571626341, 0.600921811, 0.710259470, 0.450440901, 0.540628619, 0.431058282, 0.442400358, 0.561393132, 0.523929900, 0.483505805, 0.519636552, 0.607386052, 0.535609002, 0.510519531, 0.490837474, 0.607186868, 0.475418778, 0.614141891, 0.398599358, 0.474117625, 0.532997363, 0.352785069, 0.599932209, 0.506270174, 0.582559300, 0.573352058, 0.688411509, 0.459070744, 0.633930860, 0.531340117, 0.554952484, 0.476316494, 0.586937919, 0.531143264, 0.531667832, 0.604187114, 0.474454410, 0.634159600, 0.515934881, 0.528853550, 0.561666177, 0.632040507, 0.573736861, 0.634677664, 0.545228666, 0.452539377, 0.602514389, 0.406644548, 0.526514048, 0.484831291, 0.515626324, 0.694950769, 0.558903366, 0.543989664, 0.595270602, 0.544302473, 0.701224740, 0.462491671, 0.721976217, 0.509779134, 0.608551613, 0.511985210, 0.610036501, 0.523291208, 0.571238422, 0.486944282, 0.457603820, 0.605811112, 0.602538755, 0.437573404, 0.572777807, 0.540359885, 0.503639372, 0.643482254, 0.542442515, 0.557072215, 0.548365345, 0.520257386, 0.559477646, 0.589800976, 0.620407048, 0.519814608, 0.515998436, 0.361384876, 0.548933980, 0.501600804, 0.627079396, 0.645484925, 0.495473132, 0.442635400, 0.584397481, 0.585125950, 0.352607330, 0.563273699, 0.503440598, 0.488867579, 0.557098343, 0.612293879, 0.463620892, 0.592306697, 0.546759827, 0.643941943, 0.354424800, 0.598255795, 0.484472850, 0.612693579, 0.410380974, 0.598567337, 0.512124207, 0.466188290, 0.416940820, 0.541944143, 0.586775221, 0.546650192, 0.536563665, 0.576996348, 0.503872606, 0.505680665, 0.555680519, 0.518350769, 0.652987312, 0.627428041, 0.552042874, 0.504864880, 0.611606827, 0.517154197, 0.544605688, 0.406896793, 0.597414935, 0.582586483, 0.590689714, 0.495941043, 0.498246261, 0.543623886, 0.555031880, 0.551186152, 0.478571512, 0.472812207, 0.518706192, 0.563640332, 0.554419638, 0.515959815, 0.458494588, 0.549400619, 0.490260796, 0.597798784, 0.510691719, 0.684161072, 0.506404568, 0.397770673, 0.514802604, 0.655332528, 0.472896035, 0.546293061,
                  0.450750417, 0.577340695, 0.547787327, 0.599718155, 0.544373382, 0.516858470, 0.511922800, 0.536369798, 0.499136617, 0.378726334, 0.617034292, 0.478520873, 0.521760931, 0.540347935, 0.655351297, 0.571225200, 0.512656762, 0.483168208, 0.605376870, 0.458754981, 0.422778271, 0.559776438, 0.700760982, 0.552098162, 0.582239482, 0.682263179, 0.534457440, 0.424484890, 0.517715608, 0.515762565, 0.498068539, 0.434358715, 0.671502664, 0.485220049, 0.415942514, 0.534758763, 0.619185459, 0.546414463, 0.568457400, 0.457187636, 0.650218256, 0.485625253, 0.407528701, 0.524748207, 0.454240783, 0.515931350, 0.480874561, 0.484779080, 0.550198966, 0.603725101, 0.576954166, 0.565338393, 0.606319473, 0.515972696, 0.618398708, 0.592751447, 0.589232898, 0.529610016, 0.552006633, 0.554400179, 0.696469507, 0.514473164, 0.576544908, 0.550114416, 0.526571101, 0.511727507, 0.643502178, 0.553529481, 0.631429147, 0.513860803, 0.712015201, 0.395955817, 0.537149164, 0.576820745, 0.472036962, 0.510995078, 0.559692897, 0.712613979, 0.548511940, 0.603141209, 0.646451322, 0.578597740, 0.650072597, 0.595784184, 0.444147267, 0.431644371, 0.470301501, 0.534208588, 0.570610331, 0.555056229, 0.507935162, 0.316119055, 0.557401212, 0.527316271, 0.605040348, 0.538434426, 0.576806205, 0.452004053, 0.544753597, 0.512988932, 0.619476411, 0.396076184, 0.566070831, 0.566438419, 0.450220982, 0.484173158, 0.620380771, 0.457030217, 0.436522912, 0.527267470, 0.495845368, 0.530519106, 0.592038170, 0.493137420, 0.590874952, 0.617868220, 0.486070270, 0.557348301, 0.536603623, 0.442690115, 0.498870579, 0.522430964, 0.586517685, 0.570256169, 0.589559448, 0.571328252, 0.492033061, 0.535250779, 0.512178730, 0.460879072, 0.500807069, 0.600888729, 0.517356646, 0.451303618, 0.587678099, 0.529998865, 0.471530533, 0.559646452, 0.593765971, 0.480317206, 0.466479902, 0.529183809, 0.510594353, 0.466759937, 0.437646506, 0.472243995, 0.482003863, 0.597815242, 0.425598907, 0.561641434, 0.508943548, 0.584697847, 0.636510983, 0.660346903, 0.454066017, 0.462487897, 0.505506043, 0.461258540, 0.535885979, 0.534607554, 0.470024303, 0.562676413, 0.586149433, 0.591356781, 0.455978848, 0.416752953, 0.418661640, 0.419590718, 0.571766706, 0.446425494, 0.588554376, 0.550779772, 0.550332231, 0.582390257, 0.462180960, 0.564796119, 0.607846426, 0.534457252, 0.522840491, 0.445373229, 0.549251612, 0.514152907, 0.501535072, 0.511931118, 0.614990004, 0.546573038, 0.498853768, 0.491775889, 0.637549986, 0.620760302, 0.540748899, 0.545831441, 0.489000728, 0.555212756, 0.516338580, 0.654872002, 0.482842368, 0.564765308, 0.503483424, 0.565809729, 0.623620196, 0.606398633, 0.545202760, 0.434323485, 0.592081701, 0.600379316, 0.552709762, 0.599656634, 0.472034047, 0.533803354, 0.531558379, 0.565841531, 0.350490085, 0.397840404, 0.548444844, 0.561229603, 0.563060424, 0.476912213, 0.564984359, 0.364141386, 0.502445480, 0.498539394, 0.513570785, 0.555188996, 0.448156175, 0.512119255, 0.445386379, 0.549415579, 0.341524411, 0.559606604, 0.593945702, 0.712481162, 0.587995572, 0.547201619, 0.466410676, 0.380301797, 0.562187203, 0.627409297, 0.558438269, 0.485853148, 0.587346549, 0.428806963, 0.655803314, 0.555888423, 0.542544980, 0.481775583, 0.480071956, 0.553643949, 0.552254460, 0.480791541,
                  0.560288765, 0.420843103, 0.361128494, 0.580809347, 0.527009418, 0.624330658, 0.532888624, 0.501396826, 0.618831171, 0.580389499, 0.629836529, 0.626352731, 0.571653376, 0.618028332, 0.357476413, 0.633596384, 0.518716872, 0.485010063, 0.574022133, 0.614519740, 0.602180299, 0.539065547, 0.553195187, 0.566421759, 0.478586567, 0.599254258, 0.543793383, 0.494030057, 0.310873684, 0.617009882, 0.404612458, 0.473790800, 0.534740643, 0.467572927, 0.498699660, 0.595133903, 0.455755429, 0.434058956, 0.594241142, 0.500503867, 0.572898720, 0.503342001, 0.532700074, 0.358150489, 0.412343967, 0.593475196, 0.374554699, 0.572783358, 0.442674990, 0.572843680, 0.575662283, 0.430268257, 0.467648882, 0.485725966, 0.579486503, 0.542010045, 0.400613627, 0.599057054, 0.563136422, 0.601306038, 0.500426996, 0.683184450, 0.470516049, 0.542721091, 0.563799526, 0.479949143, 0.636318482, 0.474724140, 0.482722868, 0.478795197, 0.543045187, 0.508977326, 0.547923904, 0.656525818, 0.604179155, 0.617628939, 0.469231387, 0.611045344, 0.667565827, 0.526248076, 0.606692621, 0.456038037, 0.482437027, 0.550598196, 0.454910374, 0.498118203, 0.555453296, 0.388227585, 0.533219722, 0.465068971, 0.557911420, 0.525542619, 0.443990102, 0.652073439, 0.528233460, 0.484280433, 0.541355253, 0.576684202, 0.523036842, 0.408319970, 0.617762803, 0.475120963, 0.662496201, 0.542095207, 0.571554663, 0.598805910, 0.638052186, 0.411580462, 0.557013065, 0.536381225, 0.511820061, 0.597580866, 0.518459700, 0.575230334, 0.696764491, 0.478841907, 0.551567186, 0.442349951, 0.522234760, 0.467536070, 0.513388134, 0.433268867, 0.383600813, 0.510964693, 0.536118893, 0.440663782, 0.579161992, 0.657013957, 0.501574228, 0.563880082, 0.570798093, 0.490814322, 0.582170037, 0.625847586, 0.549656969, 0.584665763, 0.529731144, 0.585040100, 0.507699586, 0.594906651, 0.542939508, 0.398198811, 0.371421696, 0.424559307, 0.521478929, 0.520841332, 0.557020071, 0.632433927, 0.540125247, 0.715177321, 0.635280103, 0.527653695, 0.462895585, 0.493750242, 0.499309380, 0.646233121, 0.535371808, 0.597260111, 0.484279193, 0.513683043, 0.457277699, 0.467642751, 0.499138169, 0.589887038, 0.534180778, 0.545297904, 0.517087020, 0.428642229, 0.464747534, 0.523041568, 0.518719639, 0.584106122, 0.533317756, 0.612415820, 0.461592490, 0.514983428, 0.518066482, 0.601919812, 0.530134121, 0.570187117, 0.528290332, 0.555818843, 0.453708364, 0.565527574, 0.607981783, 0.561120053, 0.669381588, 0.502013841, 0.564757923, 0.649643755, 0.570801738, 0.518847480, 0.468506826, 0.470142833, 0.499153449, 0.570689436, 0.479974005, 0.584116226, 0.488575346, 0.502941116, 0.473483029, 0.600104460, 0.444049959, 0.518093762, 0.616213737, 0.674839602, 0.535144087, 0.526260998, 0.463163914, 0.482726493, 0.460620798, 0.634715728, 0.676769679, 0.627133255, 0.507020514, 0.610770290, 0.532994049, 0.451198382, 0.542620243, 0.499428399, 0.429161177, 0.566230087, 0.678148969, 0.496447356, 0.558217776, 0.463545066, 0.487483001, 0.490059157, 0.431736489, 0.556338926, 0.455109444, 0.513704397, 0.573809102, 0.612380315, 0.503807651, 0.553517819, 0.576927711, 0.615872495, 0.531366945, 0.656660823, 0.517993343, 0.572913412, 0.569664360, 0.523645805, 0.490471201, 0.387093740, 0.564115440, 0.558273802, 0.598239938, 0.419955486,
                  0.465388602, 0.507796791, 0.506115556, 0.622283883, 0.596742526, 0.520855930, 0.644617222, 0.448209817, 0.564246989, 0.459447558, 0.715872399, 0.485503115, 0.569842986, 0.553621077, 0.451906806, 0.451427601, 0.540991056, 0.520360361, 0.450443033, 0.581866440, 0.560943492, 0.597019058, 0.494960963, 0.517031056, 0.435453039, 0.534349993, 0.631871756, 0.401181743, 0.597606115, 0.463709582, 0.584207932, 0.578141132, 0.464073722, 0.560488250, 0.542096705, 0.416232294, 0.590416817, 0.515450313, 0.545576702, 0.376863244, 0.480802909, 0.540922995, 0.653557885, 0.669806192, 0.534690873, 0.411004986, 0.578063132, 0.560783860, 0.571479896, 0.512483132, 0.523661488, 0.557963010, 0.445497341, 0.586293496, 0.440482669, 0.417545555, 0.548913084, 0.550121545, 0.368974569, 0.615313747, 0.531380568, 0.501810588, 0.400781748, 0.498819399, 0.543734006, 0.609199732, 0.576704893, 0.604352164, 0.627460052, 0.560995623, 0.603813764, 0.595195256, 0.635549955, 0.500937607, 0.564012122, 0.515636906, 0.635622134, 0.537348045, 0.512691695, 0.511057536, 0.615937193, 0.510478444, 0.518828953, 0.571380267, 0.580241326, 0.537779208, 0.593899836, 0.517439804, 0.589540384, 0.566012500, 0.548740539, 0.502564261, 0.511657997, 0.409964475, 0.589915535, 0.652057794, 0.634579542, 0.496301701, 0.535769343, 0.676293472, 0.607051859, 0.659077347, 0.602118707, 0.550680479, 0.563329950, 0.511840194, 0.577850813, 0.471617247, 0.414955147, 0.563989678, 0.463254931, 0.479894191, 0.623420693, 0.593593868, 0.458635132, 0.613803756, 0.488046496, 0.542319978, 0.350973957, 0.412569564, 0.490260699, 0.700491440, 0.428683103, 0.610299924, 0.524726774, 0.317358994, 0.524104380, 0.490904473, 0.582942177, 0.511242949, 0.589722146, 0.461090940, 0.563778935, 0.509113728, 0.606855462, 0.536871498, 0.535835864, 0.311305684, 0.519460682, 0.617250309, 0.459249686, 0.613208421, 0.689944309, 0.600880392, 0.470012487, 0.473908584, 0.618506078, 0.463854332, 0.424564259, 0.609790770, 0.619358325, 0.566629982, 0.558465168, 0.367649118, 0.590299657, 0.567348639, 0.672643300, 0.537803918, 0.333977141, 0.584732617, 0.648302831, 0.454857335, 0.623665038, 0.462490043, 0.634790342, 0.477715737, 0.547378369, 0.543000665, 0.565847084, 0.661123797, 0.553120335, 0.485868839, 0.502218315, 0.477975844, 0.497536727, 0.627151462, 0.532951470, 0.589626479, 0.543310420, 0.578503587, 0.547612194, 0.670302172, 0.515456325, 0.538013972, 0.454596159, 0.552985860, 0.702189700, 0.574203991, 0.469594424, 0.581663990, 0.440378605, 0.445220423, 0.565606288, 0.469661635, 0.578705416, 0.450488617, 0.667395060, 0.484036907, 0.644102750, 0.519522226, 0.402077245, 0.463575413, 0.552887803, 0.512808224, 0.447670073, 0.591463960, 0.512150833, 0.559739620, 0.578457682, 0.497693480, 0.602815427, 0.541223208, 0.500136941, 0.574870749, 0.522447052, 0.659254938, 0.518345275, 0.581820859, 0.537628623, 0.469688518, 0.490970116, 0.539631057, 0.457655973, 0.570659774, 0.452771742, 0.598276557, 0.473113951, 0.645215405, 0.499805678, 0.538075991, 0.555687688, 0.651869368, 0.499626409, 0.406144900, 0.427681771, 0.457855260, 0.404348940, 0.567678710, 0.598015105, 0.371846343, 0.660219655, 0.496971782, 0.572141968, 0.502629015, 0.463091719, 0.535049004, 0.681186139, 0.492846017, 0.386504347, 0.656911448)
se_nonorth = c(0.0416942713, 0.0407183651, 0.0444523186, 0.0425346420, 0.0444558383, 0.0399894960, 0.0418382112, 0.0512202142, 0.0422534312, 0.0437289855, 0.0496170886, 0.0416615042, 0.0468264920, 0.0461997063, 0.0444825046, 0.0432499219, 0.0437510148, 0.0490838025, 0.0469682703, 0.0446521440, 0.0417557029, 0.0482750833, 0.0450491739, 0.0429404077, 0.0494601912, 0.0484775332, 0.0409040531, 0.0477823535, 0.0448376149, 0.0537685039, 0.0451218632, 0.0421525198, 0.0405617359, 0.0476656050, 0.0443286501, 0.0472993077, 0.0388136573, 0.0470112065, 0.0484876333, 0.0407014787, 0.0415448868, 0.0428025247, 0.0438924214, 0.0478182170, 0.0410469492, 0.0510127368, 0.0474686464, 0.0443057077, 0.0468339705, 0.0473232919, 0.0462538776, 0.0439858438, 0.0465037186, 0.0464214005, 0.0443683801, 0.0427980771, 0.0484656933, 0.0522435665, 0.0460452073, 0.0454639544, 0.0515455624, 0.0412344156, 0.0408156437, 0.0434971046, 0.0376215666, 0.0414815328, 0.0387734453, 0.0466417572, 0.0470888219, 0.0494321834, 0.0404736386, 0.0475966279, 0.0487751816, 0.0486634726, 0.0437035312, 0.0410891602, 0.0452614467, 0.0464142602, 0.0501091573, 0.0412405139, 0.0427498890, 0.0417762646, 0.0423550412, 0.0460234105, 0.0398641824, 0.0421414452, 0.0478292271, 0.0489479360, 0.0461427499, 0.0460249422, 0.0455823647, 0.0452108363, 0.0457211134, 0.0483323986, 0.0527181857, 0.0469950113, 0.0525710347, 0.0396720464, 0.0437818655, 0.0440221527, 0.0419406668, 0.0389232488, 0.0427301013, 0.0390849993, 0.0456962791, 0.0420672659, 0.0449914650, 0.0466148688, 0.0454478670, 0.0466533404, 0.0486936215, 0.0364006041, 0.0426142879, 0.0454636835, 0.0465283379, 0.0459340507, 0.0473761325, 0.0476661830, 0.0459159887, 0.0418073445, 0.0440123549, 0.0442796534, 0.0676434323, 0.0473605677, 0.0354092828, 0.0479795031, 0.0457478011, 0.0432144400, 0.0468389475, 0.0399661007, 0.0427871569, 0.0432939489, 0.0492717801, 0.0428361964, 0.0441044028, 0.0487274650, 0.0410106469, 0.0451210397, 0.0488886283, 0.0475810864, 0.0454722031, 0.0451376826, 0.0454999190, 0.0403121211, 0.0443778939, 0.0426164410, 0.0427421954, 0.0425622191, 0.0488372313, 0.0425927956, 0.0465584086, 0.0467233237, 0.0507913546, 0.0480643340, 0.0535318482, 0.0432534969, 0.0440594081, 0.0462619955, 0.0455910743, 0.0414613637, 0.0476070789, 0.0455846838, 0.0483576070, 0.0444985152, 0.0477921977, 0.0456495523, 0.0508897497, 0.0437550082, 0.0415551073, 0.0477370929, 0.0440603149, 0.0481728048, 0.0475273242, 0.0424167929, 0.0532847025, 0.0512992716, 0.0481748552, 0.0451459126, 0.0510471717, 0.0472198535, 0.0418179134, 0.0443819534, 0.0398429609, 0.0389292671, 0.0432117377, 0.0468339776, 0.0439764387, 0.0457969584, 0.0493033277, 0.0421968064, 0.0520255201, 0.0522945549, 0.0477131749, 0.0440483435, 0.0490376561, 0.0516126310, 0.0442248163, 0.0412546455, 0.0367354793, 0.0438534662, 0.0475180763, 0.0429398205, 0.0463706405, 0.0390414772, 0.0458774038, 0.0474482566, 0.0434896629, 0.0422358214, 0.0497988767, 0.0434132514, 0.0455985023, 0.0486931260, 0.0474450877, 0.0403084870, 0.0458375287, 0.0432554677, 0.0416824887, 0.0505585269, 0.0482389139, 0.0416516380, 0.0448090050, 0.0435162678, 0.0373855753, 0.0404456033, 0.0460920936, 0.0505343302, 0.0441023636, 0.0442842299, 0.0428609066, 0.0400794578, 0.0448480934, 0.0469449477, 0.0417936292, 0.0493436580, 0.0431128129, 0.0454712341, 0.0430130687, 0.0470833089, 0.0422605240, 0.0424348846, 0.0461216695, 0.0489060014, 0.0423069923, 0.0478447765, 0.0404220993, 0.0586981641, 0.0443232220, 0.0388575388, 0.0413215017, 0.0426211671,
               0.0471838924, 0.0388989423, 0.0455790426, 0.0438913234, 0.0383028275, 0.0468147265, 0.0431720131, 0.0482008522, 0.0543839804, 0.0422250358, 0.0464682066, 0.0498224018, 0.0432196416, 0.0432677344, 0.0468795800, 0.0438977953, 0.0461659516, 0.0497379706, 0.0476103774, 0.0442774275, 0.0500619746, 0.0458558863, 0.0397456154, 0.0412716802, 0.0497800508, 0.0440394081, 0.0396038858, 0.0564439287, 0.0555597922, 0.0420128405, 0.0472330029, 0.0496680684, 0.0395024756, 0.0432825606, 0.0469085318, 0.0491087369, 0.0442754952, 0.0409932732, 0.0403405130, 0.0426314318, 0.0389934958, 0.0422365158, 0.0522774036, 0.0475572037, 0.0417722370, 0.0444766319, 0.0463969372, 0.0513068203, 0.0493066368, 0.0416801613, 0.0421615069, 0.0436823115, 0.0430911503, 0.0426003370, 0.0411770611, 0.0473561144, 0.0547397784, 0.0464928763, 0.0455073663, 0.0401664048, 0.0436246303, 0.0461393917, 0.0424488331, 0.0439597172, 0.0509171080, 0.0482319344, 0.0483124905, 0.0364286638, 0.0448411210, 0.0447490233, 0.0555590871, 0.0428486167, 0.0417124416, 0.0474719537, 0.0458114554, 0.0479360604, 0.0363660927, 0.0518490611, 0.0485668638, 0.0497163548, 0.0453206328, 0.0455803082, 0.0479854657, 0.0459699134, 0.0468712259, 0.0449448234, 0.0511424957, 0.0471113059, 0.0433347419, 0.0391208352, 0.0408913894, 0.0470659488, 0.0399841820, 0.0406308572, 0.0542143584, 0.0450145498, 0.0467033471, 0.0516124686, 0.0456065530, 0.0435843876, 0.0499941746, 0.0506719959, 0.0508443416, 0.0495156494, 0.0395405138, 0.0410419238, 0.0514470700, 0.0488962113, 0.0487538055, 0.0414726009, 0.0368267934, 0.0473123550, 0.0485298852, 0.0456861398, 0.0437143319, 0.0428824935, 0.0384520731, 0.0445882610, 0.0463727393, 0.0436154414, 0.0455220525, 0.0415109848, 0.0433445991, 0.0405737652, 0.0456195515, 0.0469804624, 0.0402089500, 0.0369510343, 0.0445247896, 0.0441592102, 0.0468461274, 0.0490547903, 0.0432990337, 0.0465668271, 0.0497264371, 0.0441192165, 0.0431313364, 0.0482525086, 0.0439745154, 0.0436839465, 0.0470566984, 0.0488376254, 0.0461766734, 0.0462701814, 0.0533789686, 0.0385214032, 0.0470878503, 0.0458131715, 0.0441274138, 0.0623588736, 0.0558354639, 0.0507552647, 0.0361639478, 0.0466204676, 0.0388749604, 0.0492020032, 0.0404862240, 0.0458497881, 0.0466700119, 0.0420892063, 0.0440183150, 0.0506405688, 0.0491806559, 0.0442083848, 0.0441417694, 0.0456755901, 0.0551192413, 0.0409182169, 0.0436943445, 0.0424569610, 0.0418949597, 0.0450919899, 0.0440379844, 0.0394901321, 0.0372667880, 0.0449608934, 0.0467084684, 0.0459461881, 0.0505850160, 0.0392913702, 0.0454423262, 0.0455367197, 0.0511507111, 0.0445989706, 0.0432381412, 0.0454507054, 0.0474978923, 0.0455950894, 0.0460462368, 0.0444929558, 0.0431117647, 0.0424168741, 0.0470416143, 0.0419458258, 0.0428595772, 0.0462222860, 0.0403097898, 0.0417097778, 0.0404122960, 0.0500143386, 0.0462261921, 0.0427382211, 0.0523602976, 0.0466083519, 0.0429828128, 0.0419430749, 0.0416151695, 0.0520834213, 0.0385143472, 0.0491620897, 0.0441673021, 0.0468161058, 0.0521244105, 0.0432531652, 0.0431773782, 0.0482408085, 0.0460797071, 0.0475796039, 0.0441044884, 0.0390626583, 0.0480827456, 0.0432076181, 0.0411163678, 0.0398631080, 0.0451781089, 0.0506179206, 0.0483444849, 0.0493423400, 0.0449097787, 0.0451427591, 0.0416698630, 0.0523988996, 0.0414144081, 0.0410177862, 0.0421860966, 0.0457489231, 0.0472401395, 0.0461553633, 0.0506701534, 0.0447794311, 0.0479170684, 0.0432160823, 0.0406424202, 0.0432600513, 0.0489419005, 0.0473253697, 0.0416913096, 0.0493886111, 0.0440630101, 0.0401957469,
               0.0438400485, 0.0469706961, 0.0379419954, 0.0498916208, 0.0421411392, 0.0404144925, 0.0467110555, 0.0439446736, 0.0463083553, 0.0497131722, 0.0484687136, 0.0505424229, 0.0479257700, 0.0474604174, 0.0435021261, 0.0475139088, 0.0386510772, 0.0407415152, 0.0415758675, 0.0457929174, 0.0445308164, 0.0399679240, 0.0479620843, 0.0436231597, 0.0442219275, 0.0422322599, 0.0494076074, 0.0475472135, 0.0438761612, 0.0422145844, 0.0395191281, 0.0420427008, 0.0508861560, 0.0483396730, 0.0398827945, 0.0501383066, 0.0540309624, 0.0409913626, 0.0412386320, 0.0435887472, 0.0443302167, 0.0443502175, 0.0481808945, 0.0473181803, 0.0488766269, 0.0529367635, 0.0428916178, 0.0447638538, 0.0458472612, 0.0404790119, 0.0399257227, 0.0377888836, 0.0386492614, 0.0446937626, 0.0502840660, 0.0437966863, 0.0465801076, 0.0496721460, 0.0489452659, 0.0464502063, 0.0437991473, 0.0494891160, 0.0503485209, 0.0473798105, 0.0458485017, 0.0413926382, 0.0447822677, 0.0441246584, 0.0484195496, 0.0430158347, 0.0454672105, 0.0437217941, 0.0416578277, 0.0456674215, 0.0430853669, 0.0489013653, 0.0472174986, 0.0446444115, 0.0419116187, 0.0449237332, 0.0436448839, 0.0430536200, 0.0438416684, 0.0496886557, 0.0483889357, 0.0436115925, 0.0473577009, 0.0513557121, 0.0492885243, 0.0487500719, 0.0436059358, 0.0492746868, 0.0388168102, 0.0508673325, 0.0451668028, 0.0412011276, 0.0548782211, 0.0479393631, 0.0442228499, 0.0433162070, 0.0443213114, 0.0443725770, 0.0493525004, 0.0405233001, 0.0442736712, 0.0408752068, 0.0417812872, 0.0520464905, 0.0436899010, 0.0415405681, 0.0490416480, 0.0499029777, 0.0445336837, 0.0416151062, 0.0408112066, 0.0428046438, 0.0450605378, 0.0532768714, 0.0396644557, 0.0444696943, 0.0504156986, 0.0443956988, 0.0528172902, 0.0390398316, 0.0466802712, 0.0462500025, 0.0473485596, 0.0460854911, 0.0412017954, 0.0440077856, 0.0415717449, 0.0487651621, 0.0480823967, 0.0455474796, 0.0474422098, 0.0372996608, 0.0539488638, 0.0472896522, 0.0486949128, 0.0432878967, 0.0467050944, 0.0468515101, 0.0469311873, 0.0494697275, 0.0417226496, 0.0448879556, 0.0449673198, 0.0430951188, 0.0622614825, 0.0425694862, 0.0443975843, 0.0455196655, 0.0465424642, 0.0410751939, 0.0469711908, 0.0450505494, 0.0414393933, 0.0496273343, 0.0429266249, 0.0415579401, 0.0506347047, 0.0441589079, 0.0430085648, 0.0391062482, 0.0493892022, 0.0475849965, 0.0430335663, 0.0388700253, 0.0486225382, 0.0386786601, 0.0521838145, 0.0424971130, 0.0476506097, 0.0444575042, 0.0421267772, 0.0406615732, 0.0501312064, 0.0452361956, 0.0406248912, 0.0408469612, 0.0392444290, 0.0455309395, 0.0476790281, 0.0464622391, 0.0425475893, 0.0445142131, 0.0446443886, 0.0436690511, 0.0467629886, 0.0390306459, 0.0447922159, 0.0420200127, 0.0460367286, 0.0495337585, 0.0443241229, 0.0410023677, 0.0413692134, 0.0423467020, 0.0410082263, 0.0451696943, 0.0493794927, 0.0403973911, 0.0488905545, 0.0472538337, 0.0425203525, 0.0413610982, 0.0365841273, 0.0438075830, 0.0454242611, 0.0414027566, 0.0490544717, 0.0422271786, 0.0460426506, 0.0418820975, 0.0479000468, 0.0407397797, 0.0396700663, 0.0416426682, 0.0439507791, 0.0473532784, 0.0467900357, 0.0436291674, 0.0480063679, 0.0429754876, 0.0449870427, 0.0434355341, 0.0431861184, 0.0464974683, 0.0419407774, 0.0491435513, 0.0470466006, 0.0509939175, 0.0453228328, 0.0494626877, 0.0492348281, 0.0455664378, 0.0436146932, 0.0504675435, 0.0466653769, 0.0418666473, 0.0503067258, 0.0383718571, 0.0522584215, 0.0431252691, 0.0400283783, 0.0450449964, 0.0475258218, 0.0400685390, 0.0357934857, 0.0486042528,
               0.0370261877, 0.0393641427, 0.0427189381, 0.0499489653, 0.0400037362, 0.0488202329, 0.0429777500, 0.0448634724, 0.0406805124, 0.0446702644, 0.0481321945, 0.0424083009, 0.0472734733, 0.0475518183, 0.0474519988, 0.0507773212, 0.0448938420, 0.0439749001, 0.0519301415, 0.0462917291, 0.0467769251, 0.0431394745, 0.0511398877, 0.0468973616, 0.0457477577, 0.0453645425, 0.0473912954, 0.0503678343, 0.0431073378, 0.0379354863, 0.0448704311, 0.0390333493, 0.0446870021, 0.0356292568, 0.0519402829, 0.0479014381, 0.0474969074, 0.0485018059, 0.0471529881, 0.0457874882, 0.0514035445, 0.0464573276, 0.0436958739, 0.0471457232, 0.0432730238, 0.0420443922, 0.0425626359, 0.0400757175, 0.0428709057, 0.0523370930, 0.0457095456, 0.0387461239, 0.0454164368, 0.0474067583, 0.0422056453, 0.0423306811, 0.0458742009, 0.0418851150, 0.0375060607, 0.0476444692, 0.0473158918, 0.0437627534, 0.0489777285, 0.0459813410, 0.0485886882, 0.0473717508, 0.0406818520, 0.0462999317, 0.0363856680, 0.0450027066, 0.0492219529, 0.0390316111, 0.0461459314, 0.0509053393, 0.0460205187, 0.0428744223, 0.0421943189, 0.0403611049, 0.0441886496, 0.0496008183, 0.0422805921, 0.0532239884, 0.0416174164, 0.0459029114, 0.0398305637, 0.0467203692, 0.0451460843, 0.0544602119, 0.0420129382, 0.0461996776, 0.0444963448, 0.0491157891, 0.0470482264, 0.0367606777, 0.0444011869, 0.0476917130, 0.0387451532, 0.0484612156, 0.0520540431, 0.0426581207, 0.0530953686, 0.0488003880, 0.0452046344, 0.0456663570, 0.0504463665, 0.0395335748, 0.0418899004, 0.0404035187, 0.0448713245, 0.0476916901, 0.0461400539, 0.0403482903, 0.0420793960, 0.0469157779, 0.0426540095, 0.0411240546, 0.0475006544, 0.0442164510, 0.0427828038, 0.0493846273, 0.0438576577, 0.0406313613, 0.0465298653, 0.0445994443, 0.0463059937, 0.0438992617, 0.0468660278, 0.0411646643, 0.0516189392, 0.0417182243, 0.0447124494, 0.0460886082, 0.0503461423, 0.0495413210, 0.0418845428, 0.0470049760, 0.0398121373, 0.0485289895, 0.0503722920, 0.0435886254, 0.0489487204, 0.0494519494, 0.0438545065, 0.0397148739, 0.0520638856, 0.0406954281, 0.0474046990, 0.0460098363, 0.0407100521, 0.0434347753, 0.0377814424, 0.0450191260, 0.0532696689, 0.0428635977, 0.0462511433, 0.0451252219, 0.0595109881, 0.0415188135, 0.0462933305, 0.0399142707, 0.0457308366, 0.0458449235, 0.0466075330, 0.0459267034, 0.0452804927, 0.0450031724, 0.0405805835, 0.0481327093, 0.0446886594, 0.0407773776, 0.0428498566, 0.0418913126, 0.0416114384, 0.0482691372, 0.0468687012, 0.0475622762, 0.0451409043, 0.0440544641, 0.0466109319, 0.0444994155, 0.0395735845, 0.0489770988, 0.0513474350, 0.0476471824, 0.0474166294, 0.0422779747, 0.0483946630, 0.0460189236, 0.0433891859, 0.0480850303, 0.0505456668, 0.0461110607, 0.0392525139, 0.0440482730, 0.0510736230, 0.0430907766, 0.0513039372, 0.0437664660, 0.0478224785, 0.0387364981, 0.0391934132, 0.0443478705, 0.0468773935, 0.0450421815, 0.0494911337, 0.0413486799, 0.0422647277, 0.0385349835, 0.0561999522, 0.0380104667, 0.0524001385, 0.0497509208, 0.0494165088, 0.0506288203, 0.0499250336, 0.0483102620, 0.0444882253, 0.0432652527, 0.0489046969, 0.0570060453, 0.0359903313, 0.0503936218, 0.0444652977, 0.0449598097, 0.0525180496, 0.0383749194, 0.0522110450, 0.0430210793, 0.0405819589, 0.0393943644, 0.0488834320, 0.0437871919, 0.0419881386, 0.0502366835, 0.0483239506, 0.0454876973, 0.0393104070, 0.0387805425, 0.0507050119, 0.0417782241, 0.0455323571, 0.0439461195, 0.0398420253, 0.0418836739, 0.0478967241, 0.0437425739, 0.0448702453, 0.0396011810, 0.0437846518, 0.0474342375)




# to speed up the illustration we hard-code the simulation results
theta_orth_po_nosplit = c(0.424894688, 0.415979258, 0.358214049, 0.401787264, 0.352802605, 0.374900867, 0.485234930, 0.401148984, 0.369991876, 0.475517512, 0.445076802, 0.373960370, 0.387824181, 0.342148215, 0.402114616, 0.351833721, 0.381125616, 0.461414960, 0.427616126, 0.418759210, 0.358268211, 0.401264980, 0.407889106, 0.393857741, 0.426785803, 0.368804415, 0.416975212, 0.484760806, 0.425441264, 0.390564373, 0.429884259, 0.403958684, 0.507137102, 0.439465474, 0.388448386, 0.383863300, 0.430680807, 0.442740900, 0.395929332, 0.438879887, 0.416105186, 0.463420783, 0.304417989, 0.467550408, 0.484586052, 0.470996524, 0.460477341, 0.401223146, 0.411119154, 0.383637282, 0.425053123, 0.466271156, 0.469006334, 0.363616413, 0.417576737, 0.513733653, 0.418133692, 0.348599183, 0.394726181, 0.384581212, 0.392746793, 0.365197270, 0.428143024, 0.404918669, 0.440169667, 0.394103063, 0.378160715, 0.395855561, 0.480792301, 0.382743709, 0.451031703, 0.455251318, 0.381408527, 0.381300737, 0.410594718, 0.417900354, 0.431650650, 0.427987923, 0.388522594, 0.404514383, 0.383377328, 0.407637457, 0.422540318, 0.396505143, 0.417604299, 0.433979261, 0.398505303, 0.438577405, 0.386354014, 0.496864697, 0.470265900, 0.398362215, 0.378489890, 0.397782706, 0.352943887, 0.458299569, 0.405409413, 0.411557225, 0.452976954, 0.399677608, 0.383131470, 0.359409202, 0.386673278, 0.403451635, 0.402101397, 0.345926992, 0.425853359, 0.414767703, 0.413546600, 0.425961817, 0.393060787, 0.423209103, 0.382419733, 0.439528814, 0.346969958, 0.406054155, 0.434916933, 0.413842955, 0.420869241, 0.396018540, 0.440530908, 0.463801605, 0.441943536, 0.392670005, 0.412549373, 0.418128097, 0.370135392, 0.433372541, 0.413511986, 0.417984837, 0.433422575, 0.395192998, 0.355008154, 0.481853182, 0.395635319, 0.415828051, 0.465411478, 0.377717947, 0.393839458, 0.416500090, 0.397860190, 0.365627420, 0.454536636, 0.375311328, 0.430895740, 0.381281709, 0.383331630, 0.459377553, 0.452957283, 0.435474077, 0.475775653, 0.418168929, 0.491069389, 0.367996790, 0.512591597, 0.413127082, 0.347189024, 0.371585245, 0.452311983, 0.387491017, 0.502240559, 0.420601769, 0.427401406, 0.392831214, 0.468965141, 0.415459641, 0.470943789, 0.433053303, 0.434626699, 0.492090441, 0.419246226, 0.418893912, 0.393065697, 0.388770405, 0.441625509, 0.412995748, 0.371077872, 0.429367874, 0.377048620, 0.372883541, 0.373757424, 0.370734880, 0.440019202, 0.446060065, 0.368311775, 0.358840911, 0.410658460, 0.434416070, 0.357136936, 0.405721983, 0.426689088, 0.461247188, 0.404427560, 0.486848662, 0.421560795, 0.448725346, 0.395054774, 0.416209154, 0.348607332, 0.366021039, 0.394709281, 0.430889800, 0.344462363, 0.477618944, 0.459546440, 0.339655440, 0.379558250, 0.474168015, 0.442126248, 0.434445686, 0.384672615, 0.434607996, 0.428411546, 0.379106440, 0.429089990, 0.441497373, 0.472405799, 0.420758530, 0.343717385, 0.366743818, 0.428770078, 0.455448048, 0.393978437, 0.346644741, 0.413489758, 0.465933477, 0.410372147, 0.380400118, 0.389768437, 0.433616164, 0.415860347, 0.397688077, 0.403562635, 0.333999464, 0.400165296, 0.418106933, 0.438916985, 0.348258431, 0.393831547, 0.376630297, 0.361524823, 0.446085218, 0.437275242, 0.418582123, 0.402979134, 0.379250484, 0.385105923, 0.490360011, 0.408958240, 0.432456309,
                          0.351920445, 0.447363475, 0.422481090, 0.430591197, 0.392504110, 0.418217743, 0.335004556, 0.372325037, 0.394052607, 0.323269074, 0.450976993, 0.414753060, 0.377835580, 0.393009569, 0.430968945, 0.408493740, 0.400109532, 0.343548576, 0.432738866, 0.385312627, 0.417914016, 0.445751407, 0.456904998, 0.427402045, 0.428451693, 0.432616192, 0.397268553, 0.384487737, 0.454374367, 0.410259806, 0.394052351, 0.386824902, 0.449221702, 0.387562801, 0.419401117, 0.452489229, 0.411449728, 0.370941031, 0.485727233, 0.432207428, 0.446356136, 0.428725027, 0.408534909, 0.463849885, 0.383363434, 0.397317715, 0.370839991, 0.422689252, 0.398367964, 0.399402307, 0.370772153, 0.388901162, 0.419421703, 0.421480883, 0.462461035, 0.402952908, 0.481567653, 0.380262787, 0.400084769, 0.410680051, 0.480213431, 0.422283869, 0.376365158, 0.385215532, 0.426120281, 0.410418090, 0.433670541, 0.377211515, 0.419357991, 0.415964247, 0.455015478, 0.317675157, 0.387075050, 0.408334191, 0.426357587, 0.439444693, 0.377670795, 0.464149481, 0.406615740, 0.454187707, 0.432317322, 0.421451013, 0.418353714, 0.444449725, 0.381350545, 0.387726995, 0.424795832, 0.440197280, 0.452127352, 0.416719835, 0.311493371, 0.422479433, 0.409537979, 0.414986548, 0.467710387, 0.420232182, 0.381676188, 0.388174915, 0.401078159, 0.447170278, 0.435258241, 0.338825490, 0.455670717, 0.461917584, 0.371304778, 0.376446660, 0.407706339, 0.422186563, 0.418115968, 0.416378061, 0.425279277, 0.428291259, 0.462693090, 0.418222657, 0.369201029, 0.420151461, 0.392211425, 0.431599930, 0.424963409, 0.342202797, 0.384637525, 0.380550985, 0.457112811, 0.393566169, 0.425138820, 0.415367175, 0.407742930, 0.401935672, 0.430092673, 0.397948321, 0.443193402, 0.459284304, 0.430411609, 0.405542103, 0.433985448, 0.427231711, 0.362992584, 0.401492971, 0.419008384, 0.348550839, 0.471964735, 0.446598128, 0.436886151, 0.368575038, 0.367530471, 0.401633597, 0.424980640, 0.454243346, 0.414387404, 0.416863374, 0.449528153, 0.503963861, 0.469473707, 0.441125251, 0.365749826, 0.434098011, 0.415426355, 0.417771687, 0.419604405, 0.367309353, 0.411200519, 0.430404379, 0.428630305, 0.455207160, 0.397395094, 0.317963341, 0.413866802, 0.373058861, 0.363022778, 0.433642126, 0.408401413, 0.402172901, 0.415956625, 0.426929765, 0.447624636, 0.407888648, 0.424093072, 0.403808267, 0.401864776, 0.404786678, 0.434549093, 0.421308095, 0.463228885, 0.381578411, 0.360937371, 0.430389043, 0.380815478, 0.425050042, 0.409222214, 0.449231897, 0.468960783, 0.403600201, 0.449153584, 0.393266075, 0.432475963, 0.470040732, 0.370270174, 0.411428716, 0.445065055, 0.465809180, 0.478426094, 0.482827469, 0.440886189, 0.342951435, 0.420371681, 0.431011999, 0.409995431, 0.364304974, 0.430555977, 0.469468645, 0.420829269, 0.401066443, 0.377822921, 0.324573196, 0.376868840, 0.417123950, 0.419508274, 0.364629906, 0.424054805, 0.383711305, 0.382673810, 0.375404460, 0.411889877, 0.417394647, 0.474884703, 0.420248148, 0.359983139, 0.430039395, 0.362279964, 0.352218095, 0.467685621, 0.391297314, 0.422716169, 0.432300645, 0.423483352, 0.413034621, 0.381545204, 0.443612460, 0.449914879, 0.370031098, 0.394246127, 0.418733550, 0.469678298, 0.407178606, 0.432198930, 0.414867318, 0.408681708, 0.434265691, 0.467060193, 0.391013760,
                          0.370400490, 0.332203204, 0.363481637, 0.429850822, 0.450047054, 0.431698023, 0.466034941, 0.400121872, 0.503031211, 0.446934294, 0.460041072, 0.431456780, 0.457649668, 0.422576622, 0.332316868, 0.472845396, 0.455770826, 0.397403289, 0.441297765, 0.433151706, 0.395843096, 0.371432785, 0.382138596, 0.423748251, 0.402355421, 0.472308119, 0.352218499, 0.416618010, 0.356814570, 0.431636611, 0.394538337, 0.373993666, 0.409556738, 0.428374106, 0.410665007, 0.453274019, 0.380463333, 0.365077040, 0.404261814, 0.436856490, 0.405327743, 0.417387191, 0.366897402, 0.383415388, 0.364644324, 0.474808617, 0.369956377, 0.443745943, 0.314597833, 0.435137100, 0.397470863, 0.366913406, 0.414212215, 0.458358528, 0.365783871, 0.389472053, 0.390800205, 0.426404960, 0.467304794, 0.422227455, 0.464829857, 0.408686483, 0.368035908, 0.423865983, 0.433479830, 0.451516349, 0.382986187, 0.360148917, 0.414429349, 0.372056454, 0.448279799, 0.396465210, 0.336651635, 0.415939450, 0.423274516, 0.441782734, 0.445279158, 0.457713399, 0.464028502, 0.417341788, 0.479052167, 0.364470659, 0.341975244, 0.450537833, 0.366797702, 0.401167599, 0.392824068, 0.371416939, 0.465633574, 0.394107951, 0.395270182, 0.384203394, 0.406193169, 0.458989859, 0.425523943, 0.403831818, 0.441603388, 0.463630643, 0.458745937, 0.383506306, 0.380828043, 0.324446665, 0.438192365, 0.432349193, 0.378082464, 0.423641862, 0.440539350, 0.421866949, 0.398939487, 0.360102156, 0.430645835, 0.406681322, 0.405615359, 0.457507748, 0.499485391, 0.445504548, 0.379768456, 0.366212804, 0.426411010, 0.442667618, 0.413089925, 0.356627005, 0.346204403, 0.414539759, 0.369000893, 0.410983419, 0.418884758, 0.436838293, 0.442840502, 0.372796312, 0.456826712, 0.439872488, 0.420979564, 0.458726471, 0.427222566, 0.414561165, 0.404129340, 0.437164782, 0.420125851, 0.444937697, 0.378823585, 0.344974252, 0.378473181, 0.326708387, 0.422673827, 0.411802218, 0.463528600, 0.480643262, 0.369553567, 0.539561102, 0.446754556, 0.443372240, 0.391506790, 0.420883675, 0.384909902, 0.428005736, 0.435572680, 0.380064121, 0.441688800, 0.427728771, 0.376879408, 0.386230389, 0.379297661, 0.391151078, 0.448742043, 0.426269009, 0.391016905, 0.361911038, 0.361260555, 0.375962888, 0.429031608, 0.453435995, 0.382849951, 0.418972156, 0.411782379, 0.409748513, 0.417185266, 0.474186128, 0.408962890, 0.423095877, 0.403080294, 0.407192386, 0.411146072, 0.371414033, 0.434524192, 0.458307494, 0.459465643, 0.383470468, 0.393895199, 0.441245225, 0.385601119, 0.457798268, 0.333568766, 0.392325004, 0.389500615, 0.419601265, 0.342127805, 0.410058017, 0.386873477, 0.419857392, 0.416583760, 0.413571437, 0.348420129, 0.306958517, 0.415446113, 0.433828085, 0.362749830, 0.439709459, 0.373498153, 0.408862604, 0.367324240, 0.410599367, 0.462074177, 0.417798870, 0.403447345, 0.486268512, 0.436681939, 0.353226945, 0.375727800, 0.400238336, 0.387701863, 0.434732159, 0.470295878, 0.388492069, 0.450566244, 0.375847217, 0.452672717, 0.410252985, 0.370101076, 0.401929643, 0.396687160, 0.409564069, 0.422040540, 0.470611612, 0.405628552, 0.412845597, 0.410790548, 0.406955232, 0.406718944, 0.448502718, 0.394616540, 0.397300376, 0.434718696, 0.378026061, 0.429331337, 0.394758391, 0.446681929, 0.416128251, 0.486614601, 0.338719225,
                          0.379557811, 0.416149459, 0.438549694, 0.408487185, 0.394909023, 0.471054009, 0.385801377, 0.398903948, 0.426567805, 0.388798764, 0.473609202, 0.381982662, 0.398691822, 0.387011715, 0.441720158, 0.384760231, 0.429064300, 0.446734393, 0.418929618, 0.425831265, 0.431901906, 0.398304481, 0.325154177, 0.449176834, 0.426711411, 0.462732600, 0.450886972, 0.369002936, 0.473904836, 0.409876993, 0.391839838, 0.414163386, 0.390136760, 0.419732527, 0.418566659, 0.354634774, 0.450677909, 0.414044049, 0.455101914, 0.377457834, 0.407166551, 0.463989578, 0.443941774, 0.464190729, 0.399992176, 0.365743954, 0.494537290, 0.389166628, 0.461950897, 0.384885929, 0.425542300, 0.392324863, 0.369717572, 0.411383107, 0.360734874, 0.412082713, 0.413211097, 0.460642582, 0.340431259, 0.447807429, 0.413854492, 0.363850727, 0.377037754, 0.373448238, 0.411695258, 0.434247387, 0.437846402, 0.420436823, 0.451136645, 0.459976008, 0.457703156, 0.410214227, 0.439866327, 0.408595226, 0.311587984, 0.389788276, 0.434837426, 0.393205506, 0.397440704, 0.429051957, 0.409268771, 0.441501688, 0.376344016, 0.456800297, 0.443762504, 0.485934342, 0.411445200, 0.415473004, 0.457860135, 0.428509101, 0.348680514, 0.382412030, 0.384236468, 0.336588701, 0.395033981, 0.470638735, 0.456460635, 0.374916181, 0.409757001, 0.446347336, 0.386195523, 0.437997392, 0.416817515, 0.401767758, 0.417448024, 0.383419763, 0.437394936, 0.390106036, 0.438424137, 0.415366444, 0.416113141, 0.397503991, 0.407284043, 0.419731523, 0.415320508, 0.374656927, 0.448380205, 0.434587373, 0.334040203, 0.381187524, 0.430973164, 0.462871380, 0.374971316, 0.434664582, 0.423872408, 0.353548703, 0.408951814, 0.386961873, 0.374368242, 0.365238833, 0.410072260, 0.374385573, 0.413393750, 0.430356486, 0.457390487, 0.437869531, 0.417503051, 0.417142259, 0.419814555, 0.494517700, 0.435496761, 0.494769645, 0.432470989, 0.430374049, 0.353567354, 0.354965171, 0.438851283, 0.420323761, 0.393051108, 0.479738224, 0.478709592, 0.457409926, 0.382295768, 0.432279881, 0.406922783, 0.370337217, 0.486575672, 0.433604426, 0.328854098, 0.442303787, 0.455974644, 0.379021371, 0.483716293, 0.361257180, 0.441799533, 0.461619525, 0.436204304, 0.400482903, 0.416440613, 0.422738340, 0.398063077, 0.420496873, 0.353993836, 0.382452566, 0.371148390, 0.428635151, 0.360623312, 0.435017107, 0.486246068, 0.403706028, 0.409318512, 0.475617780, 0.449477163, 0.443347279, 0.334113010, 0.404588645, 0.444905156, 0.443339740, 0.436970173, 0.383174883, 0.401506449, 0.422593340, 0.395204934, 0.327544686, 0.411575102, 0.407071333, 0.453808542, 0.426140167, 0.437071898, 0.447402657, 0.387552043, 0.356983603, 0.447273435, 0.444320809, 0.424265298, 0.450762016, 0.422511090, 0.425658227, 0.396261512, 0.454702873, 0.447998973, 0.357790158, 0.372444927, 0.375074800, 0.412820238, 0.386209275, 0.417595949, 0.447094826, 0.431459703, 0.422612480, 0.403658719, 0.412560423, 0.408525948, 0.419478656, 0.406359697, 0.445193045, 0.403698609, 0.468360722, 0.436780315, 0.424582248, 0.435778912, 0.421655511, 0.419587375, 0.363362782, 0.314487440, 0.413161689, 0.375812452, 0.409232797, 0.431542093, 0.381663699, 0.459229785, 0.405715553, 0.450246648, 0.385156654, 0.399908611, 0.495611859, 0.438489055, 0.434156073, 0.336363317, 0.462242061)
se_orth_po_nosplit = c(0.0369249937, 0.0366232166, 0.0352132615, 0.0357962562, 0.0345049556, 0.0361262917, 0.0385463535, 0.0368034228, 0.0354351281, 0.0333831231, 0.0402495762, 0.0335314336, 0.0343515619, 0.0365670189, 0.0337228740, 0.0333227216, 0.0426300264, 0.0440211182, 0.0382558092, 0.0336980296, 0.0382198398, 0.0392737882, 0.0358866245, 0.0371949430, 0.0334161164, 0.0386112083, 0.0367611265, 0.0367412759, 0.0379716336, 0.0411895083, 0.0381076337, 0.0386184276, 0.0398358082, 0.0387196574, 0.0388327060, 0.0364272833, 0.0339169542, 0.0380975564, 0.0362605086, 0.0404485292, 0.0339254053, 0.0358481896, 0.0398973515, 0.0418559718, 0.0322929223, 0.0391445722, 0.0352535863, 0.0407457193, 0.0381563624, 0.0324255617, 0.0405592833, 0.0369996847, 0.0345523241, 0.0387905589, 0.0386349948, 0.0365253978, 0.0433434719, 0.0398188984, 0.0362117055, 0.0342701997, 0.0400886743, 0.0379609911, 0.0333977515, 0.0393487648, 0.0369779531, 0.0375621374, 0.0325041742, 0.0387477077, 0.0380749138, 0.0373413643, 0.0379796819, 0.0373226004, 0.0376677267, 0.0349157821, 0.0346622644, 0.0355238235, 0.0381691113, 0.0349897123, 0.0378986526, 0.0350406392, 0.0333717668, 0.0365995511, 0.0358975624, 0.0394310793, 0.0360894113, 0.0348494460, 0.0350188627, 0.0379314350, 0.0395471213, 0.0348427081, 0.0352419296, 0.0356833101, 0.0317318338, 0.0388212687, 0.0389492142, 0.0363170519, 0.0379470806, 0.0368118802, 0.0343779606, 0.0367881789, 0.0342973037, 0.0377790637, 0.0326271478, 0.0359853488, 0.0373458914, 0.0358605895, 0.0327402839, 0.0380161151, 0.0379797917, 0.0340346274, 0.0393887944, 0.0353565289, 0.0366771994, 0.0357489017, 0.0357177390, 0.0392098998, 0.0415141917, 0.0386790734, 0.0340422201, 0.0352620909, 0.0352257514, 0.0365514568, 0.0422526465, 0.0378846512, 0.0349287423, 0.0342852895, 0.0377285062, 0.0395522624, 0.0366243053, 0.0356420055, 0.0337987406, 0.0351550723, 0.0403973846, 0.0343271190, 0.0371690023, 0.0402125590, 0.0379987646, 0.0371561830, 0.0377747611, 0.0387412979, 0.0342890640, 0.0362439912, 0.0399781737, 0.0354668345, 0.0355798503, 0.0378158282, 0.0373887839, 0.0367890081, 0.0364132958, 0.0316696876, 0.0366735911, 0.0375554456, 0.0351768749, 0.0402093755, 0.0388770688, 0.0350375306, 0.0362373368, 0.0368829639, 0.0374174714, 0.0376122238, 0.0396791162, 0.0377645583, 0.0344713625, 0.0344121739, 0.0384872790, 0.0349841773, 0.0367329137, 0.0415318771, 0.0380704513, 0.0366988115, 0.0354045825, 0.0362387461, 0.0338391083, 0.0348513246, 0.0391287468, 0.0398345559, 0.0370238403, 0.0376002404, 0.0373263167, 0.0403515262, 0.0382045983, 0.0358038382, 0.0379768912, 0.0404881572, 0.0329837069, 0.0366323084, 0.0373143173, 0.0367056216, 0.0394424637, 0.0338721006, 0.0363571591, 0.0358660136, 0.0354478615, 0.0371378037, 0.0371951176, 0.0397721191, 0.0377044514, 0.0365577228, 0.0348615115, 0.0396726795, 0.0365713485, 0.0359730608, 0.0395486556, 0.0340883207, 0.0365270000, 0.0375245803, 0.0362486326, 0.0351907161, 0.0352683426, 0.0371649834, 0.0408355838, 0.0433708840, 0.0384014082, 0.0364107251, 0.0396378805, 0.0375877073, 0.0369852690, 0.0391400903, 0.0377302961, 0.0355080999, 0.0387590883, 0.0390154314, 0.0376327689, 0.0371729544, 0.0362131718, 0.0394311839, 0.0397455758, 0.0338254334, 0.0339592893, 0.0350270473, 0.0365871407, 0.0348248381, 0.0397966778, 0.0352881053, 0.0343784640, 0.0349831541, 0.0348252297, 0.0355288461, 0.0347750894, 0.0359251796, 0.0377969821, 0.0344496764, 0.0364498354, 0.0407896156, 0.0302891372, 0.0367511518, 0.0362461083, 0.0338413879, 0.0376009260, 0.0416784692,
                       0.0355676088, 0.0354810273, 0.0347563980, 0.0390815703, 0.0365781628, 0.0356438064, 0.0370253095, 0.0346080207, 0.0366758485, 0.0365856649, 0.0357777501, 0.0333222235, 0.0384474677, 0.0372652799, 0.0340667506, 0.0392409054, 0.0358411180, 0.0354550356, 0.0392816686, 0.0378646966, 0.0364721933, 0.0403215102, 0.0348425990, 0.0351672287, 0.0362464031, 0.0358741667, 0.0380285793, 0.0392726268, 0.0385350072, 0.0319476245, 0.0338427123, 0.0348540533, 0.0369521168, 0.0398366717, 0.0389639752, 0.0370317966, 0.0371140538, 0.0355371713, 0.0363329517, 0.0374690989, 0.0390756382, 0.0326706498, 0.0439476087, 0.0359901097, 0.0382919101, 0.0376204892, 0.0376587002, 0.0365372987, 0.0381686041, 0.0390329021, 0.0333172334, 0.0374771801, 0.0370162654, 0.0365934335, 0.0345133055, 0.0377695837, 0.0383205767, 0.0342981905, 0.0360441143, 0.0350886870, 0.0364055532, 0.0350689849, 0.0351638326, 0.0389041461, 0.0393064094, 0.0383452294, 0.0405354213, 0.0324294873, 0.0372726981, 0.0347757225, 0.0354444328, 0.0385655046, 0.0361342930, 0.0368683660, 0.0364370618, 0.0362055159, 0.0356479739, 0.0370198029, 0.0389147441, 0.0381533923, 0.0378841099, 0.0375338872, 0.0397564525, 0.0383997468, 0.0372784222, 0.0355349409, 0.0382286022, 0.0370193756, 0.0335471387, 0.0361635481, 0.0364180793, 0.0347234531, 0.0344764278, 0.0338724454, 0.0382032583, 0.0371174726, 0.0403042829, 0.0389863381, 0.0357583539, 0.0346608756, 0.0371734722, 0.0410630651, 0.0383511631, 0.0353802392, 0.0357127875, 0.0362375087, 0.0430681387, 0.0401093829, 0.0358399973, 0.0382847912, 0.0307255113, 0.0342237485, 0.0428171846, 0.0372517454, 0.0386076704, 0.0378034563, 0.0360672409, 0.0357859946, 0.0385656925, 0.0373509222, 0.0368877062, 0.0359272464, 0.0336546963, 0.0335879692, 0.0368621306, 0.0383153424, 0.0386184533, 0.0363456546, 0.0399388852, 0.0365243547, 0.0411256024, 0.0364633097, 0.0316391551, 0.0344368511, 0.0377815592, 0.0369273729, 0.0402271924, 0.0383658713, 0.0343101963, 0.0355220437, 0.0351253139, 0.0374152945, 0.0349770422, 0.0364736648, 0.0374523052, 0.0373063848, 0.0362776648, 0.0359394270, 0.0354230225, 0.0402450722, 0.0403374147, 0.0362700810, 0.0341783098, 0.0352790805, 0.0362478930, 0.0422737100, 0.0397633564, 0.0342151953, 0.0349775972, 0.0383469899, 0.0326468495, 0.0376559285, 0.0360585156, 0.0358415977, 0.0339164796, 0.0391971651, 0.0379741386, 0.0328984950, 0.0333478044, 0.0339087152, 0.0392270743, 0.0369140592, 0.0356481616, 0.0335338925, 0.0358359237, 0.0359519495, 0.0383729767, 0.0380200474, 0.0392320072, 0.0349795492, 0.0385933769, 0.0385337152, 0.0339949367, 0.0368081394, 0.0364832561, 0.0369027300, 0.0348527406, 0.0353266428, 0.0409249736, 0.0349847219, 0.0373107503, 0.0362845900, 0.0357049963, 0.0374549170, 0.0328355998, 0.0352186631, 0.0360181482, 0.0339079916, 0.0356234022, 0.0368818532, 0.0377727168, 0.0404549723, 0.0378194702, 0.0339986616, 0.0347353022, 0.0341101278, 0.0363994038, 0.0454005713, 0.0364765251, 0.0381052499, 0.0354623023, 0.0416077888, 0.0385198360, 0.0371301870, 0.0340609225, 0.0381526038, 0.0398425724, 0.0395502167, 0.0347530350, 0.0360908058, 0.0362714648, 0.0377928170, 0.0367091680, 0.0347300577, 0.0383511940, 0.0455298064, 0.0345029973, 0.0358853526, 0.0366139751, 0.0371735171, 0.0369081979, 0.0388371790, 0.0363142955, 0.0361592014, 0.0336743480, 0.0398775837, 0.0371858894, 0.0369441537, 0.0342515133, 0.0330603885, 0.0366774175, 0.0372780305, 0.0384357725, 0.0327281233, 0.0398455960, 0.0349781592, 0.0332261588, 0.0335007409, 0.0343487372, 0.0344446637,
                       0.0373896634, 0.0360469614, 0.0384601466, 0.0379069720, 0.0344681226, 0.0321005301, 0.0372949422, 0.0376218266, 0.0384834302, 0.0415069849, 0.0361675933, 0.0411957439, 0.0352347018, 0.0370950773, 0.0363468156, 0.0391674776, 0.0359043016, 0.0343064231, 0.0381767329, 0.0381724977, 0.0376863880, 0.0362853697, 0.0473642657, 0.0321476669, 0.0337037424, 0.0361915748, 0.0399475564, 0.0438185360, 0.0343215024, 0.0394374795, 0.0328045276, 0.0363354500, 0.0390130052, 0.0402113042, 0.0331546111, 0.0399187023, 0.0385610432, 0.0335671335, 0.0388047857, 0.0382630539, 0.0352719847, 0.0356151542, 0.0334228344, 0.0368779390, 0.0399147580, 0.0372539437, 0.0376295519, 0.0342599493, 0.0355239098, 0.0348426572, 0.0340256326, 0.0343128218, 0.0372396122, 0.0369769539, 0.0394337923, 0.0339594669, 0.0356773800, 0.0365046239, 0.0410308833, 0.0338451879, 0.0337491141, 0.0399865890, 0.0338668098, 0.0388658337, 0.0374178512, 0.0370322112, 0.0434228447, 0.0392062958, 0.0379827098, 0.0379192708, 0.0334753337, 0.0387883328, 0.0368278599, 0.0354812858, 0.0353263303, 0.0387281325, 0.0392107061, 0.0366563188, 0.0348989677, 0.0349570814, 0.0365983319, 0.0390011130, 0.0389533555, 0.0352820147, 0.0451128067, 0.0358390871, 0.0382993401, 0.0381725299, 0.0374396881, 0.0361240319, 0.0375975481, 0.0429443388, 0.0377616709, 0.0394815698, 0.0379874691, 0.0348771133, 0.0353325382, 0.0399458594, 0.0357562535, 0.0354703396, 0.0371421311, 0.0349452848, 0.0335497368, 0.0360487611, 0.0381963919, 0.0368377269, 0.0387121263, 0.0399682368, 0.0326218785, 0.0397446149, 0.0361055492, 0.0377749879, 0.0371968263, 0.0353627786, 0.0353910346, 0.0343485802, 0.0367565148, 0.0413084443, 0.0367265558, 0.0354179943, 0.0382604067, 0.0365711243, 0.0405838474, 0.0382653708, 0.0339588753, 0.0347804883, 0.0350120577, 0.0359922676, 0.0369672072, 0.0351613400, 0.0403676382, 0.0342321575, 0.0383123398, 0.0373524826, 0.0367792678, 0.0381369283, 0.0392099553, 0.0352038618, 0.0411622304, 0.0389699820, 0.0343076621, 0.0405775834, 0.0411801748, 0.0356677802, 0.0366416736, 0.0405571097, 0.0364058481, 0.0346285443, 0.0414215902, 0.0339456792, 0.0389323963, 0.0368766661, 0.0364887226, 0.0355923593, 0.0385476311, 0.0361379482, 0.0347195865, 0.0364422042, 0.0364172493, 0.0330822207, 0.0397386702, 0.0370599053, 0.0361456332, 0.0353346394, 0.0382634901, 0.0328174827, 0.0364344161, 0.0352058716, 0.0359885506, 0.0360347605, 0.0407330211, 0.0397713058, 0.0363578603, 0.0360970823, 0.0336726056, 0.0360769004, 0.0361774017, 0.0375372853, 0.0342849274, 0.0377435977, 0.0331884339, 0.0357310450, 0.0384191739, 0.0419794197, 0.0352883571, 0.0353893693, 0.0349984920, 0.0350303481, 0.0373690518, 0.0323551856, 0.0370063562, 0.0354295781, 0.0407199139, 0.0358561220, 0.0385965794, 0.0350956698, 0.0385640688, 0.0320200370, 0.0355708851, 0.0367567424, 0.0398889105, 0.0337766114, 0.0420417317, 0.0366275042, 0.0375734840, 0.0373726871, 0.0326122782, 0.0365790073, 0.0344297953, 0.0387711616, 0.0374603423, 0.0372834867, 0.0366211848, 0.0347407690, 0.0363108899, 0.0350238267, 0.0317626286, 0.0331506020, 0.0408579454, 0.0389398819, 0.0399149633, 0.0376256461, 0.0350371339, 0.0386344787, 0.0382209044, 0.0358302799, 0.0346141886, 0.0350192453, 0.0391874375, 0.0381368396, 0.0394854722, 0.0362065382, 0.0342822668, 0.0362374841, 0.0378217639, 0.0398215542, 0.0365463994, 0.0413244552, 0.0397431888, 0.0355421117, 0.0394554041, 0.0327252997, 0.0368132145, 0.0367869076, 0.0368758911, 0.0411303623, 0.0362732663, 0.0390759891, 0.0340982866, 0.0403384514,
                       0.0318183239, 0.0361099221, 0.0402409129, 0.0384354063, 0.0343115790, 0.0368494662, 0.0402420624, 0.0353061786, 0.0338574691, 0.0371088912, 0.0391739661, 0.0370644997, 0.0391891831, 0.0380362254, 0.0404687271, 0.0404906474, 0.0352339228, 0.0383117640, 0.0396372971, 0.0339371955, 0.0356753996, 0.0339298625, 0.0330988736, 0.0376727491, 0.0367847135, 0.0381433694, 0.0326747712, 0.0391429991, 0.0376406387, 0.0352639365, 0.0370389503, 0.0338770548, 0.0358137198, 0.0338629149, 0.0363082160, 0.0354460648, 0.0343265756, 0.0381136419, 0.0356454636, 0.0371229587, 0.0389978427, 0.0402244046, 0.0382496773, 0.0394424714, 0.0353786233, 0.0380071075, 0.0382076460, 0.0395020689, 0.0385407280, 0.0369531474, 0.0357005596, 0.0374634732, 0.0379451792, 0.0401219270, 0.0347805074, 0.0361252182, 0.0352261792, 0.0352649148, 0.0384631887, 0.0370160547, 0.0385053752, 0.0350962715, 0.0387306736, 0.0369875480, 0.0404257489, 0.0461123938, 0.0366037343, 0.0351987497, 0.0361276201, 0.0365775610, 0.0388976575, 0.0380851196, 0.0345951130, 0.0370417913, 0.0364155305, 0.0366196088, 0.0368103509, 0.0361618694, 0.0380338390, 0.0396245699, 0.0346361865, 0.0405216381, 0.0372940104, 0.0363723035, 0.0356640541, 0.0385326683, 0.0362931946, 0.0421462758, 0.0338109984, 0.0357543058, 0.0374628359, 0.0362797844, 0.0368728312, 0.0364604038, 0.0385642164, 0.0399893332, 0.0336799753, 0.0395206713, 0.0388872471, 0.0382730401, 0.0353623359, 0.0352444078, 0.0382368267, 0.0381393840, 0.0343350981, 0.0337197178, 0.0369189299, 0.0349719620, 0.0333890391, 0.0396441517, 0.0361873774, 0.0378307358, 0.0365695005, 0.0396327142, 0.0331171659, 0.0432410971, 0.0380011748, 0.0369813756, 0.0396292617, 0.0367488363, 0.0348375991, 0.0363480151, 0.0347260403, 0.0371735622, 0.0399512827, 0.0382587505, 0.0362809042, 0.0344871085, 0.0394235255, 0.0353605375, 0.0344596148, 0.0382193516, 0.0372817520, 0.0362770657, 0.0362057784, 0.0368400217, 0.0361431971, 0.0397821566, 0.0391969913, 0.0380037971, 0.0399016978, 0.0373176775, 0.0389868924, 0.0354224897, 0.0377122574, 0.0395566809, 0.0386080910, 0.0371366835, 0.0343289156, 0.0332663013, 0.0330794474, 0.0388330658, 0.0397220703, 0.0388879765, 0.0384766482, 0.0409410321, 0.0414657279, 0.0375928777, 0.0386564545, 0.0377466918, 0.0354752347, 0.0345848544, 0.0346798247, 0.0387448445, 0.0394138765, 0.0353539490, 0.0299221885, 0.0366166852, 0.0372525184, 0.0372967391, 0.0339701181, 0.0366998335, 0.0384988327, 0.0378874575, 0.0420594119, 0.0363607648, 0.0360699822, 0.0317958512, 0.0404294042, 0.0352864907, 0.0405165125, 0.0399594364, 0.0361487076, 0.0374133456, 0.0374805363, 0.0355464495, 0.0392695227, 0.0337534926, 0.0384322112, 0.0391902532, 0.0375980277, 0.0375924745, 0.0352334383, 0.0370078136, 0.0399579600, 0.0360427313, 0.0382787029, 0.0350579378, 0.0401883559, 0.0319766776, 0.0370449943, 0.0404588657, 0.0407541195, 0.0344746390, 0.0412191332, 0.0358989477, 0.0366126875, 0.0370809996, 0.0399497678, 0.0355534343, 0.0393131128, 0.0370407940, 0.0363187432, 0.0389475031, 0.0378005386, 0.0377157383, 0.0353959562, 0.0385682187, 0.0377720111, 0.0388690038, 0.0391966137, 0.0405436846, 0.0384275227, 0.0342578823, 0.0422762326, 0.0332816830, 0.0386548470, 0.0369299494, 0.0351850600, 0.0363734045, 0.0362109816, 0.0364759838, 0.0368868785, 0.0367005653, 0.0383874488, 0.0342395609, 0.0347803973, 0.0392387853, 0.0402901017, 0.0349486732, 0.0388709549, 0.0385755033, 0.0325223829, 0.0366812686, 0.0342228295, 0.0356556147, 0.0380793542, 0.0375113139, 0.0381656074, 0.0383364452)




# to speed up the illustration we hard-code the simulation results
theta_dml_po = c(0.528929305, 0.524166106, 0.451625400, 0.481825448, 0.437547797, 0.478983941, 0.595735437, 0.504146789, 0.477701836, 0.555757361, 0.509946294, 0.482621495, 0.484000068, 0.435829918, 0.472128822, 0.437704381, 0.492793231, 0.549994506, 0.501524331, 0.500380684, 0.404144531, 0.464623937, 0.507083497, 0.452636998, 0.511753393, 0.454828747, 0.470530138, 0.573594266, 0.500503122, 0.486072954, 0.490245595, 0.435874202, 0.655562845, 0.564458817, 0.456068556, 0.481776445, 0.521628576, 0.528145239, 0.435524326, 0.541558276, 0.520581239, 0.548347798, 0.410600001, 0.548111626, 0.561417232, 0.565057590, 0.569559383, 0.534560415, 0.489788915, 0.462890711, 0.487090830, 0.530282207, 0.603032550, 0.470690285, 0.497606122, 0.622735251, 0.501934927, 0.448152643, 0.476624907, 0.445380734, 0.481506092, 0.448385435, 0.545291003, 0.502574048, 0.504246410, 0.464174968, 0.468343480, 0.461442733, 0.545334139, 0.474707557, 0.542118443, 0.524144042, 0.423730692, 0.436341238, 0.513615913, 0.500882990, 0.521748352, 0.538908355, 0.447217526, 0.493472118, 0.424747680, 0.497873343, 0.508668557, 0.508476976, 0.508078831, 0.489466840, 0.485841133, 0.467494506, 0.492297379, 0.591710996, 0.589443587, 0.474464990, 0.456152648, 0.530132841, 0.402934007, 0.559060278, 0.452289153, 0.531651817, 0.557275666, 0.493257933, 0.450157556, 0.418314553, 0.494901444, 0.510357009, 0.483434818, 0.421694596, 0.516056398, 0.506513906, 0.494035742, 0.502110446, 0.486391123, 0.502495550, 0.467286445, 0.488338097, 0.438663036, 0.497291466, 0.493119600, 0.501582001, 0.510332906, 0.495763180, 0.538677334, 0.546065989, 0.515238558, 0.498520612, 0.470267041, 0.502284214, 0.480202263, 0.507158599, 0.497926448, 0.527142789, 0.528020269, 0.483060947, 0.446734351, 0.580134490, 0.524634633, 0.478397358, 0.583881918, 0.482283220, 0.473529221, 0.523149540, 0.503318183, 0.434520261, 0.565038698, 0.494658140, 0.482419660, 0.474924711, 0.445798775, 0.539232232, 0.526370036, 0.520267696, 0.582505676, 0.501827939, 0.578082546, 0.460174208, 0.628940531, 0.497760092, 0.416803557, 0.451989307, 0.541747005, 0.477475822, 0.599009515, 0.490841213, 0.498024328, 0.466645921, 0.596155475, 0.514117685, 0.616173672, 0.478501201, 0.508374826, 0.577131397, 0.467610894, 0.488153770, 0.514340586, 0.480234482, 0.544403625, 0.490047059, 0.492203817, 0.503426265, 0.475708594, 0.467758104, 0.445317360, 0.426501477, 0.559152043, 0.518667020, 0.460217643, 0.424770041, 0.532601186, 0.518290351, 0.415608392, 0.496448300, 0.491461821, 0.574624682, 0.497096595, 0.572225217, 0.563645297, 0.565865550, 0.459524026, 0.467229524, 0.408708517, 0.460688550, 0.492079054, 0.520314870, 0.454612210, 0.566993376, 0.564688339, 0.405875504, 0.444422298, 0.567882347, 0.523173348, 0.532446921, 0.447302094, 0.547230142, 0.523344293, 0.425544984, 0.536317105, 0.553970107, 0.596946705, 0.512206456, 0.420470208, 0.443051243, 0.528253209, 0.530685357, 0.466369447, 0.406971502, 0.510648658, 0.573694992, 0.465244936, 0.454228624, 0.476045386, 0.552822940, 0.514711997, 0.480833510, 0.495754520, 0.444803423, 0.483793405, 0.468678545, 0.519521156, 0.439401937, 0.460177593, 0.466097332, 0.443843088, 0.529619820, 0.518480317, 0.526510426, 0.500424064, 0.453144914, 0.460236105, 0.562048290, 0.516089696, 0.528869392,
                 0.418437552, 0.535357378, 0.512321914, 0.506201866, 0.454603631, 0.499333855, 0.408035186, 0.430295475, 0.457574546, 0.415501972, 0.537784196, 0.506507161, 0.455958374, 0.482664686, 0.558281390, 0.502988823, 0.472407229, 0.411700675, 0.524268092, 0.495372505, 0.514738408, 0.507391273, 0.545098256, 0.510787741, 0.524056562, 0.527604408, 0.513238451, 0.490536319, 0.501284277, 0.515363859, 0.464154660, 0.450451836, 0.570862346, 0.450713013, 0.487943518, 0.536914644, 0.508686757, 0.440262065, 0.568978485, 0.527752092, 0.535192893, 0.483637201, 0.464594624, 0.564906577, 0.457075076, 0.484845400, 0.438608719, 0.506351695, 0.505222865, 0.461529985, 0.452937460, 0.508888146, 0.517469669, 0.507455485, 0.556022584, 0.458070609, 0.567509738, 0.476227231, 0.494220742, 0.507646043, 0.606399836, 0.512885919, 0.457287016, 0.517578558, 0.482191072, 0.478660253, 0.494519169, 0.455926332, 0.483201417, 0.520567478, 0.553893483, 0.406281301, 0.475029231, 0.502872047, 0.512367384, 0.531066521, 0.493544326, 0.566572815, 0.456218183, 0.533881334, 0.517587797, 0.491538264, 0.452080383, 0.549326160, 0.451892980, 0.470967517, 0.485753423, 0.555439924, 0.564934584, 0.504503725, 0.365120359, 0.536268511, 0.505501217, 0.547301769, 0.521837539, 0.494415220, 0.480677107, 0.464160744, 0.484564227, 0.506030300, 0.544895280, 0.420921023, 0.554332303, 0.571402548, 0.469410674, 0.432813715, 0.497178890, 0.508195316, 0.486224241, 0.504062393, 0.528757658, 0.544182477, 0.572767929, 0.493720099, 0.434814509, 0.537327702, 0.490471332, 0.525268381, 0.500631408, 0.425750435, 0.454183309, 0.460271501, 0.552740571, 0.488877753, 0.503887023, 0.493697484, 0.496833562, 0.468960171, 0.483951803, 0.477611961, 0.542478840, 0.530739222, 0.508113262, 0.474719439, 0.518617794, 0.492387350, 0.377194163, 0.506034774, 0.528514850, 0.405646062, 0.574553812, 0.547711082, 0.528261529, 0.458456690, 0.428018314, 0.479989366, 0.533742084, 0.533160176, 0.500305198, 0.520568712, 0.517599360, 0.577852125, 0.544738741, 0.512469742, 0.432961531, 0.513438167, 0.512180912, 0.439384489, 0.464477951, 0.454436213, 0.503965204, 0.558667400, 0.541939875, 0.565303117, 0.464630046, 0.380983931, 0.485112517, 0.448974635, 0.421620451, 0.493160149, 0.521991278, 0.513966346, 0.508762669, 0.513260701, 0.541730726, 0.509173393, 0.529478794, 0.458218020, 0.476249455, 0.515037563, 0.526951572, 0.497130545, 0.526400104, 0.514678756, 0.468804650, 0.516883882, 0.449256945, 0.484194763, 0.498747909, 0.543203598, 0.544696641, 0.492034217, 0.534088707, 0.489315917, 0.501940483, 0.536539996, 0.471765757, 0.498238686, 0.552811905, 0.551689267, 0.546496425, 0.537478422, 0.505512759, 0.391897221, 0.461451904, 0.528794878, 0.480367495, 0.417003519, 0.537443049, 0.532941478, 0.537021748, 0.476978136, 0.447385292, 0.401122385, 0.437789407, 0.503712921, 0.479222512, 0.444176717, 0.494162728, 0.463978465, 0.447420587, 0.453548182, 0.538136577, 0.488698559, 0.539731223, 0.561827143, 0.425556372, 0.539425872, 0.421379433, 0.410573090, 0.548288926, 0.492213770, 0.516577250, 0.496622223, 0.531138281, 0.485743737, 0.448609846, 0.572971670, 0.571438541, 0.444549066, 0.451317073, 0.507861445, 0.598311645, 0.508099212, 0.523695419, 0.539862417, 0.465409989, 0.561214516, 0.564621151, 0.465419592,
                 0.455939621, 0.403848844, 0.435280621, 0.465540249, 0.545743051, 0.504983437, 0.580164476, 0.494241622, 0.585880925, 0.534909533, 0.572404567, 0.516370584, 0.521469069, 0.501596610, 0.406415221, 0.593218158, 0.545166460, 0.494873537, 0.531479024, 0.533431139, 0.478524003, 0.417494355, 0.495220613, 0.465151337, 0.490336254, 0.574956485, 0.443825985, 0.498799585, 0.406600953, 0.568582680, 0.465388530, 0.483330202, 0.511320398, 0.504536921, 0.466345025, 0.544028013, 0.415498708, 0.459631120, 0.510267551, 0.546867942, 0.508822005, 0.497838777, 0.452140218, 0.470697845, 0.417154413, 0.577092790, 0.434763604, 0.516837107, 0.380979385, 0.529535198, 0.476851052, 0.448921689, 0.496390884, 0.574518645, 0.463937364, 0.438976157, 0.488609802, 0.497765937, 0.545086164, 0.504355476, 0.502997232, 0.508712805, 0.404144513, 0.516200801, 0.524881095, 0.558208561, 0.487446747, 0.427403542, 0.484338504, 0.426593367, 0.509215104, 0.450850809, 0.442370837, 0.481226278, 0.515255009, 0.528548896, 0.513263839, 0.521514461, 0.567346143, 0.455509858, 0.568724669, 0.439245664, 0.436353272, 0.514302705, 0.495105085, 0.465458954, 0.515925392, 0.452107595, 0.558880453, 0.527058894, 0.476759303, 0.517560886, 0.476597742, 0.549837559, 0.543764932, 0.502258369, 0.532912989, 0.534555371, 0.568238944, 0.483064595, 0.483481744, 0.404644749, 0.531771908, 0.508334834, 0.439653788, 0.500064559, 0.528640373, 0.537956379, 0.506765854, 0.454736266, 0.539377259, 0.478914934, 0.486476661, 0.525669718, 0.586420464, 0.541457390, 0.458113804, 0.429515552, 0.526501629, 0.505727664, 0.496538987, 0.429521939, 0.400408186, 0.485172824, 0.482264230, 0.474051602, 0.562544665, 0.553739537, 0.537816620, 0.455008673, 0.554563567, 0.511488473, 0.487183325, 0.574268906, 0.564911221, 0.506017820, 0.507124508, 0.522633173, 0.515863162, 0.501386527, 0.432263205, 0.387493025, 0.448437904, 0.426409789, 0.480796794, 0.567443932, 0.532509768, 0.599172214, 0.449388683, 0.634234708, 0.520986895, 0.508651246, 0.479610754, 0.473403781, 0.458828900, 0.506731868, 0.536052013, 0.465428520, 0.551930519, 0.497322512, 0.470429398, 0.445696484, 0.477245066, 0.436917882, 0.524591515, 0.458308052, 0.485223737, 0.416827228, 0.441832926, 0.456295792, 0.532004238, 0.559007160, 0.471194374, 0.501534265, 0.458219060, 0.487549915, 0.477752947, 0.564057270, 0.505565864, 0.497217633, 0.487834546, 0.495366218, 0.499796246, 0.467260542, 0.538641992, 0.533807631, 0.542275689, 0.464704577, 0.497097152, 0.529170367, 0.426403827, 0.533977327, 0.420575152, 0.509743590, 0.446744046, 0.482897243, 0.425139318, 0.480555522, 0.470976897, 0.498329378, 0.534134219, 0.509050733, 0.450644947, 0.365292264, 0.509720234, 0.538041637, 0.425904081, 0.550900039, 0.472855738, 0.470215245, 0.445077645, 0.508636762, 0.535701105, 0.533032467, 0.479446481, 0.595612040, 0.514476241, 0.406871216, 0.489761646, 0.478245691, 0.496722778, 0.500625716, 0.568127960, 0.473315875, 0.552671656, 0.467567138, 0.587156656, 0.450638599, 0.438651604, 0.465896459, 0.491022085, 0.466253967, 0.503212924, 0.615191650, 0.490351498, 0.534819707, 0.511891628, 0.483192380, 0.498922525, 0.542704320, 0.509884810, 0.497219140, 0.556189513, 0.467267138, 0.521387563, 0.466023855, 0.524534075, 0.484491717, 0.577928273, 0.392238766,
                 0.447760594, 0.515876611, 0.521457709, 0.535130199, 0.449875495, 0.569663935, 0.489929639, 0.502838804, 0.482240555, 0.404236270, 0.622196761, 0.437934512, 0.539712253, 0.466186985, 0.526261755, 0.441862687, 0.556668161, 0.507139530, 0.542354257, 0.523498216, 0.517362249, 0.508913948, 0.360408364, 0.553102019, 0.516707472, 0.586485176, 0.544416128, 0.442992140, 0.588645180, 0.450134448, 0.465455377, 0.522119316, 0.431973515, 0.532048952, 0.489536096, 0.423843057, 0.583538003, 0.520633738, 0.549802107, 0.474114508, 0.460593713, 0.534870192, 0.509058585, 0.534005415, 0.494864065, 0.438132303, 0.574057621, 0.457239509, 0.572997314, 0.451684179, 0.512620158, 0.480317135, 0.464953113, 0.484426014, 0.389955989, 0.489917453, 0.480510603, 0.555692617, 0.390583739, 0.583645148, 0.472470716, 0.432870458, 0.470675549, 0.459518292, 0.473306963, 0.532231412, 0.541247157, 0.477481994, 0.574164057, 0.544111833, 0.550865276, 0.488049715, 0.525875430, 0.524719681, 0.368912909, 0.479004953, 0.508917726, 0.506315587, 0.490350589, 0.531897691, 0.501459857, 0.516702796, 0.466695809, 0.557933288, 0.500560049, 0.564251106, 0.484549438, 0.469584003, 0.559953533, 0.505203148, 0.468927366, 0.422932316, 0.472981376, 0.397713686, 0.517644221, 0.552023074, 0.559983289, 0.431046169, 0.502767665, 0.533157597, 0.430680084, 0.532961326, 0.496362776, 0.460114821, 0.537888346, 0.460190182, 0.534114793, 0.463453521, 0.529167975, 0.467139855, 0.467910335, 0.493771269, 0.523022691, 0.488449544, 0.489227985, 0.453106871, 0.517816272, 0.518105243, 0.424183904, 0.469225056, 0.560032874, 0.539904458, 0.491118132, 0.534246626, 0.481190063, 0.444659882, 0.511358131, 0.451980036, 0.449700371, 0.443902852, 0.470174192, 0.477342614, 0.477623402, 0.529911544, 0.522015113, 0.530149883, 0.500039447, 0.514468281, 0.495545188, 0.594648734, 0.527704224, 0.585460912, 0.487121505, 0.560804832, 0.423674171, 0.438511119, 0.516919838, 0.506782894, 0.487018065, 0.594321865, 0.581561105, 0.554268212, 0.456258768, 0.513765089, 0.435707789, 0.451094845, 0.535435227, 0.536789205, 0.393461792, 0.510646553, 0.538077749, 0.447653667, 0.571659506, 0.429907613, 0.517797520, 0.566446391, 0.523661725, 0.492847472, 0.482555825, 0.503280026, 0.458652571, 0.517001714, 0.405166603, 0.485645385, 0.436924651, 0.544409558, 0.435555372, 0.545304122, 0.590598741, 0.484680937, 0.521124571, 0.614254920, 0.499266081, 0.555696194, 0.394091745, 0.498249879, 0.517679647, 0.495328847, 0.532118898, 0.454934071, 0.508498181, 0.529632228, 0.500706673, 0.412100845, 0.478146278, 0.474480335, 0.557436153, 0.479228012, 0.534619489, 0.557454300, 0.482464669, 0.440860839, 0.538459425, 0.513226869, 0.482503590, 0.545393707, 0.526546108, 0.512945438, 0.485965220, 0.574223433, 0.548750002, 0.450586928, 0.472396545, 0.424789369, 0.531055828, 0.516712013, 0.470623965, 0.553653603, 0.510583001, 0.519733930, 0.487737727, 0.479564120, 0.479129236, 0.528968158, 0.500992879, 0.567073632, 0.508843441, 0.545296924, 0.523066881, 0.546063299, 0.492532284, 0.516297567, 0.520810095, 0.428744294, 0.392715751, 0.474486933, 0.448466029, 0.526251752, 0.483369713, 0.469783888, 0.551264104, 0.478410929, 0.550488733, 0.425831624, 0.469105405, 0.568043007, 0.566561822, 0.476783584, 0.378936224, 0.539095122)
se_dml_po = c(0.0434856354, 0.0449909751, 0.0412343665, 0.0434867351, 0.0426816854, 0.0432660004, 0.0442063422, 0.0453752608, 0.0414156667, 0.0414029206, 0.0445706914, 0.0425871629, 0.0414589846, 0.0463883773, 0.0411063437, 0.0418296094, 0.0511347959, 0.0527985875, 0.0492336263, 0.0419605951, 0.0482329884, 0.0498052989, 0.0443665271, 0.0470984864, 0.0394081305, 0.0469836291, 0.0420282554, 0.0399614915, 0.0486114165, 0.0509329919, 0.0459762972, 0.0448620748, 0.0486023058, 0.0458205509, 0.0448047044, 0.0462191872, 0.0444371989, 0.0444743463, 0.0421171024, 0.0487895452, 0.0406127084, 0.0457636971, 0.0475267157, 0.0487640046, 0.0422062330, 0.0463523571, 0.0451753137, 0.0482065676, 0.0458499831, 0.0408702810, 0.0453744969, 0.0434234081, 0.0430949278, 0.0453029415, 0.0442131297, 0.0432394035, 0.0489691509, 0.0478083232, 0.0441431520, 0.0427929451, 0.0460930288, 0.0465807446, 0.0403349042, 0.0495064451, 0.0452042571, 0.0427579659, 0.0409161182, 0.0440448573, 0.0462905949, 0.0444684437, 0.0453318423, 0.0470717385, 0.0453307020, 0.0422713105, 0.0420776466, 0.0434892083, 0.0468101265, 0.0431585181, 0.0449988018, 0.0413798561, 0.0416447852, 0.0448559043, 0.0432338473, 0.0460127919, 0.0434116159, 0.0415203445, 0.0448199866, 0.0443858745, 0.0487485566, 0.0424788253, 0.0455731127, 0.0407264273, 0.0384912302, 0.0481227030, 0.0458342231, 0.0439534882, 0.0468952813, 0.0487479684, 0.0407494005, 0.0421097667, 0.0418870801, 0.0475423237, 0.0433519860, 0.0409932986, 0.0447418249, 0.0424617557, 0.0394069040, 0.0455396441, 0.0487496125, 0.0403867470, 0.0471382272, 0.0441135633, 0.0441852350, 0.0470091490, 0.0454836636, 0.0501399372, 0.0508939225, 0.0478002474, 0.0451234033, 0.0422841304, 0.0431107971, 0.0412681351, 0.0514054697, 0.0438387351, 0.0413831691, 0.0411385136, 0.0456976291, 0.0455376742, 0.0432429042, 0.0411361405, 0.0416303015, 0.0426052946, 0.0482175520, 0.0436083145, 0.0444696641, 0.0476747004, 0.0463405465, 0.0454637469, 0.0438200622, 0.0456285769, 0.0434145510, 0.0460813786, 0.0467100729, 0.0439354602, 0.0429374752, 0.0441789444, 0.0445144290, 0.0445980516, 0.0411907280, 0.0368473727, 0.0450787722, 0.0459287480, 0.0439170947, 0.0476198818, 0.0461595801, 0.0429203701, 0.0422266981, 0.0456721624, 0.0465838054, 0.0447450270, 0.0461102696, 0.0462217515, 0.0420180132, 0.0437184292, 0.0479108225, 0.0422362293, 0.0448791372, 0.0491953066, 0.0454951483, 0.0446842495, 0.0428118511, 0.0454396102, 0.0414008334, 0.0399468156, 0.0482145172, 0.0500287650, 0.0456585799, 0.0449833963, 0.0439395726, 0.0473129220, 0.0455416759, 0.0442336820, 0.0476535156, 0.0474671550, 0.0405145506, 0.0415519146, 0.0459774231, 0.0434665188, 0.0458938227, 0.0422547492, 0.0414850642, 0.0427270875, 0.0419108763, 0.0448099944, 0.0442260892, 0.0501602753, 0.0457549328, 0.0437501768, 0.0394372550, 0.0472106346, 0.0440147704, 0.0446122733, 0.0465866484, 0.0443398786, 0.0434179595, 0.0483923585, 0.0429863119, 0.0412377004, 0.0418009834, 0.0441275774, 0.0480055115, 0.0498825501, 0.0478575157, 0.0438961855, 0.0499995224, 0.0472267518, 0.0447670701, 0.0496148872, 0.0452068083, 0.0448423575, 0.0459172174, 0.0428776568, 0.0452131546, 0.0461268658, 0.0426258772, 0.0475063278, 0.0472408578, 0.0446091081, 0.0424050961, 0.0429348126, 0.0421265704, 0.0434943698, 0.0484314165, 0.0448263246, 0.0426683986, 0.0416609484, 0.0414283404, 0.0446416272, 0.0409941394, 0.0427813831, 0.0465865821, 0.0408309112, 0.0422481350, 0.0496832768, 0.0388508163, 0.0453873677, 0.0434704930, 0.0411681517, 0.0445678422, 0.0499742376,
              0.0413415408, 0.0405909254, 0.0412803065, 0.0472132630, 0.0429350947, 0.0412087195, 0.0445017781, 0.0404800784, 0.0428572301, 0.0440868320, 0.0461360286, 0.0399657350, 0.0478429909, 0.0435296750, 0.0422636758, 0.0472143690, 0.0430650222, 0.0435322482, 0.0494857201, 0.0448441559, 0.0435095479, 0.0485147238, 0.0433087563, 0.0418758639, 0.0432160545, 0.0426093750, 0.0468055316, 0.0498377108, 0.0447029357, 0.0387071772, 0.0415046424, 0.0419011681, 0.0433309910, 0.0489771778, 0.0471238235, 0.0448933562, 0.0455730112, 0.0448702380, 0.0446465477, 0.0484902345, 0.0438211722, 0.0430308925, 0.0528781979, 0.0425646564, 0.0469459098, 0.0463228838, 0.0450300856, 0.0445571775, 0.0470255902, 0.0477636233, 0.0409415842, 0.0455307911, 0.0448079103, 0.0458699373, 0.0422040790, 0.0443877184, 0.0468109275, 0.0437736342, 0.0423354317, 0.0416731283, 0.0447892588, 0.0404955840, 0.0436334738, 0.0460776884, 0.0482039603, 0.0477919804, 0.0481124622, 0.0402018874, 0.0455233868, 0.0443288648, 0.0426751552, 0.0496390455, 0.0473517180, 0.0447418236, 0.0436056848, 0.0420502829, 0.0463491445, 0.0446638988, 0.0456855124, 0.0444307768, 0.0449416962, 0.0444476963, 0.0480857999, 0.0478148051, 0.0465282276, 0.0452618401, 0.0440711934, 0.0466980643, 0.0435951511, 0.0433518012, 0.0425449486, 0.0432481811, 0.0397565890, 0.0407649939, 0.0436010886, 0.0455738060, 0.0485152262, 0.0472629741, 0.0418851590, 0.0406459007, 0.0474509995, 0.0473777758, 0.0460273071, 0.0442506799, 0.0438041830, 0.0467000229, 0.0514415720, 0.0483754742, 0.0437886700, 0.0483187198, 0.0373052682, 0.0445698720, 0.0510452850, 0.0436470731, 0.0479001296, 0.0449772839, 0.0460893323, 0.0438292383, 0.0453725071, 0.0456856788, 0.0458729545, 0.0442397847, 0.0433640501, 0.0418388918, 0.0456722641, 0.0460787284, 0.0491722426, 0.0424693267, 0.0471803551, 0.0424370461, 0.0511632678, 0.0443784440, 0.0388264415, 0.0409514299, 0.0465273995, 0.0440615791, 0.0472738255, 0.0479875406, 0.0433404245, 0.0416906202, 0.0429407121, 0.0440608042, 0.0411089879, 0.0467010836, 0.0438139132, 0.0420951654, 0.0425055626, 0.0449358517, 0.0424911705, 0.0479855071, 0.0483781602, 0.0418310159, 0.0408075505, 0.0414244205, 0.0424704839, 0.0523071082, 0.0469389464, 0.0432266704, 0.0416691932, 0.0460887041, 0.0399158320, 0.0500687829, 0.0447838513, 0.0428981624, 0.0421836673, 0.0499681949, 0.0461031638, 0.0401099439, 0.0432303420, 0.0430873634, 0.0468523422, 0.0456288766, 0.0452276482, 0.0413568677, 0.0427962657, 0.0434803923, 0.0433409998, 0.0451000046, 0.0469981892, 0.0441132982, 0.0457114078, 0.0447626731, 0.0430758420, 0.0462470219, 0.0438529372, 0.0457539172, 0.0424561156, 0.0427199333, 0.0477891889, 0.0415413890, 0.0461968884, 0.0470033829, 0.0434885994, 0.0446480400, 0.0401481201, 0.0422093507, 0.0412620941, 0.0421577207, 0.0422612862, 0.0485575153, 0.0445747930, 0.0488146456, 0.0476213798, 0.0421610382, 0.0420411033, 0.0444973529, 0.0465486256, 0.0551011182, 0.0432018882, 0.0423701302, 0.0470822009, 0.0538534845, 0.0473246156, 0.0435301544, 0.0392188189, 0.0483681613, 0.0468222575, 0.0466567013, 0.0442856212, 0.0458239374, 0.0445162744, 0.0449768586, 0.0441025538, 0.0435248418, 0.0475843151, 0.0548989934, 0.0415717507, 0.0421512496, 0.0450870675, 0.0460190655, 0.0432971267, 0.0473867559, 0.0442738990, 0.0424060562, 0.0431562852, 0.0479244266, 0.0447410510, 0.0415609464, 0.0402884865, 0.0394052713, 0.0452884362, 0.0440613073, 0.0453510394, 0.0423025688, 0.0457004378, 0.0436675315, 0.0407028459, 0.0417417396, 0.0403773389, 0.0431874617,
              0.0456131066, 0.0449160242, 0.0466727460, 0.0441052012, 0.0420092037, 0.0389294848, 0.0426533625, 0.0479740747, 0.0458802110, 0.0508785816, 0.0431055432, 0.0502861141, 0.0438003415, 0.0437357036, 0.0473404420, 0.0476560369, 0.0426601106, 0.0443346001, 0.0459871144, 0.0496979493, 0.0489142964, 0.0440756378, 0.0590243203, 0.0380476802, 0.0395445052, 0.0427711073, 0.0481489119, 0.0511804931, 0.0449385961, 0.0464974820, 0.0383614511, 0.0438017164, 0.0470291704, 0.0477054150, 0.0385464611, 0.0461889924, 0.0454904923, 0.0412832514, 0.0491546027, 0.0465012530, 0.0427468271, 0.0434424038, 0.0396650845, 0.0437837748, 0.0473686149, 0.0464770564, 0.0474161702, 0.0433348596, 0.0435340452, 0.0416355464, 0.0399296987, 0.0405482877, 0.0452315309, 0.0434306036, 0.0445313641, 0.0414634672, 0.0447603587, 0.0441881555, 0.0496823968, 0.0401616682, 0.0390309901, 0.0487170179, 0.0418218193, 0.0464374054, 0.0456174395, 0.0471081895, 0.0489421622, 0.0480249361, 0.0438261829, 0.0442537786, 0.0394098306, 0.0451999522, 0.0428574881, 0.0436186021, 0.0448292932, 0.0462847856, 0.0489734895, 0.0456698389, 0.0446195569, 0.0415688193, 0.0454536576, 0.0501086800, 0.0447656474, 0.0419716160, 0.0554928675, 0.0462486905, 0.0453146372, 0.0452515684, 0.0455292255, 0.0461085770, 0.0438255464, 0.0507731074, 0.0488969105, 0.0508566134, 0.0449762119, 0.0433199250, 0.0417114424, 0.0482790902, 0.0438539325, 0.0427013836, 0.0458171466, 0.0439974266, 0.0421534218, 0.0438755379, 0.0439615265, 0.0452697372, 0.0478322513, 0.0527052731, 0.0409655189, 0.0491207031, 0.0437395260, 0.0471055197, 0.0441370488, 0.0414063317, 0.0445095807, 0.0442424165, 0.0462612074, 0.0497244282, 0.0448463235, 0.0413426318, 0.0467569035, 0.0465486758, 0.0479196628, 0.0477680536, 0.0432553890, 0.0414034806, 0.0436614700, 0.0432208347, 0.0438852072, 0.0444143939, 0.0453850708, 0.0406107833, 0.0476053726, 0.0447981502, 0.0463369894, 0.0442927940, 0.0483712665, 0.0455567859, 0.0488471465, 0.0489840142, 0.0428974992, 0.0471797318, 0.0514890344, 0.0449970800, 0.0447408778, 0.0474807626, 0.0459181822, 0.0411115811, 0.0486283654, 0.0405510448, 0.0483306745, 0.0423022486, 0.0444765989, 0.0435894459, 0.0469704783, 0.0444066140, 0.0411926382, 0.0443122777, 0.0462195869, 0.0421971580, 0.0475577799, 0.0463075866, 0.0435392089, 0.0476292551, 0.0471666476, 0.0411768578, 0.0421767940, 0.0407479023, 0.0443738396, 0.0461646643, 0.0475327247, 0.0476775046, 0.0448512608, 0.0404672780, 0.0411392417, 0.0443537643, 0.0438445404, 0.0483220279, 0.0396712543, 0.0443395816, 0.0401185680, 0.0430710800, 0.0466624588, 0.0482823805, 0.0407783396, 0.0402079878, 0.0423194499, 0.0461672777, 0.0446457130, 0.0426731335, 0.0434590339, 0.0433561131, 0.0477376361, 0.0453379253, 0.0455635863, 0.0409024758, 0.0477686572, 0.0397436740, 0.0404306185, 0.0464088622, 0.0488128917, 0.0410203120, 0.0526721782, 0.0435263843, 0.0457518457, 0.0472539328, 0.0395472276, 0.0436933033, 0.0424613758, 0.0455806546, 0.0473136472, 0.0441805080, 0.0430473467, 0.0447567613, 0.0435356113, 0.0430805359, 0.0410747035, 0.0404922172, 0.0471826461, 0.0484327807, 0.0467886106, 0.0462083899, 0.0435329614, 0.0449860417, 0.0453074373, 0.0436403212, 0.0397468676, 0.0422695719, 0.0441124288, 0.0434291342, 0.0471951724, 0.0423960648, 0.0421673625, 0.0479337097, 0.0451183839, 0.0463349513, 0.0454243832, 0.0514400435, 0.0450966633, 0.0441135794, 0.0461859977, 0.0422128996, 0.0454937511, 0.0443757964, 0.0457996127, 0.0504139196, 0.0441336342, 0.0472618260, 0.0421523232, 0.0460213665,
              0.0386543627, 0.0422584317, 0.0488002239, 0.0471390755, 0.0410038451, 0.0472294441, 0.0505038797, 0.0424905412, 0.0409927496, 0.0438960690, 0.0485043916, 0.0417997851, 0.0487973102, 0.0459688575, 0.0510106004, 0.0504856979, 0.0447476893, 0.0436398134, 0.0495304954, 0.0425404563, 0.0475108158, 0.0416349129, 0.0413908256, 0.0469019918, 0.0411031105, 0.0450789301, 0.0377854724, 0.0460794384, 0.0449444228, 0.0430275639, 0.0447318265, 0.0419953334, 0.0430857842, 0.0419443045, 0.0433365396, 0.0431572086, 0.0417635679, 0.0470305565, 0.0435849574, 0.0481614807, 0.0452261553, 0.0483204329, 0.0485888835, 0.0455875083, 0.0433588049, 0.0438005658, 0.0438969435, 0.0482734521, 0.0463492788, 0.0460435499, 0.0450705988, 0.0454923769, 0.0436803165, 0.0503292800, 0.0433317977, 0.0437258496, 0.0436086760, 0.0426916864, 0.0451659917, 0.0441053995, 0.0517127171, 0.0408578739, 0.0454984346, 0.0430943450, 0.0473775473, 0.0515394538, 0.0424925868, 0.0416918462, 0.0418660785, 0.0441519549, 0.0471086420, 0.0430676066, 0.0427848501, 0.0453772610, 0.0465046820, 0.0439579923, 0.0461329240, 0.0430823972, 0.0469213391, 0.0469912486, 0.0429561100, 0.0494401770, 0.0454358831, 0.0468482347, 0.0437230006, 0.0483446000, 0.0439940125, 0.0499725374, 0.0430154120, 0.0426438029, 0.0460993897, 0.0437583859, 0.0442988951, 0.0457552342, 0.0446209589, 0.0471586672, 0.0392868449, 0.0502770985, 0.0452377461, 0.0471729341, 0.0405972353, 0.0409740741, 0.0458060199, 0.0478659993, 0.0412226983, 0.0388599723, 0.0446957081, 0.0453372567, 0.0400001508, 0.0502988012, 0.0425248390, 0.0454564635, 0.0435454323, 0.0475926090, 0.0406074050, 0.0481848105, 0.0437181777, 0.0432005213, 0.0480309900, 0.0463864127, 0.0422477331, 0.0446760512, 0.0439146553, 0.0441187997, 0.0478947711, 0.0468220080, 0.0454049423, 0.0431294048, 0.0484464709, 0.0436190538, 0.0425426021, 0.0465571932, 0.0450467035, 0.0455853658, 0.0447383176, 0.0450462899, 0.0419250380, 0.0478865756, 0.0466518813, 0.0426608461, 0.0491645809, 0.0460344679, 0.0455470251, 0.0431141321, 0.0468126628, 0.0513564846, 0.0473470901, 0.0462808302, 0.0403843821, 0.0398550053, 0.0388632134, 0.0468402390, 0.0513384981, 0.0492639840, 0.0443255962, 0.0474207998, 0.0490144741, 0.0463047285, 0.0480784879, 0.0449957310, 0.0419181286, 0.0416882269, 0.0435890412, 0.0488815392, 0.0475753668, 0.0445161408, 0.0394133790, 0.0437393726, 0.0460113217, 0.0444514485, 0.0403999343, 0.0445497813, 0.0464931812, 0.0498635036, 0.0499944664, 0.0457159647, 0.0435424658, 0.0394828243, 0.0453096252, 0.0424811131, 0.0511458419, 0.0466107591, 0.0423855219, 0.0447590622, 0.0463544572, 0.0417609318, 0.0477494435, 0.0404891174, 0.0447435978, 0.0437581953, 0.0473154519, 0.0449950388, 0.0423434069, 0.0452420125, 0.0452047757, 0.0449526138, 0.0466613490, 0.0409872320, 0.0484519214, 0.0352437017, 0.0430470758, 0.0475445400, 0.0454740377, 0.0423447527, 0.0496876593, 0.0439748868, 0.0427690644, 0.0468111097, 0.0494035213, 0.0425496477, 0.0465137448, 0.0447275277, 0.0484827693, 0.0458997490, 0.0464914386, 0.0433278287, 0.0445023944, 0.0466340547, 0.0441450072, 0.0474577431, 0.0480442403, 0.0471825641, 0.0468976085, 0.0421529837, 0.0496266909, 0.0392661148, 0.0482181540, 0.0436511829, 0.0413371341, 0.0429495849, 0.0420580993, 0.0449661668, 0.0472251303, 0.0461371903, 0.0474402788, 0.0438124402, 0.0414037459, 0.0491058290, 0.0500372334, 0.0450386547, 0.0463601996, 0.0461323055, 0.0416831353, 0.0445322971, 0.0426195463, 0.0432235284, 0.0460557804, 0.0431648518, 0.0468505390, 0.0467809093)





# plotting
g_all = ggplot(data.frame(t_nonorth=(theta_nonorth - alpha)/se_nonorth,
                          t_orth_nosplit=(theta_orth_po_nosplit - alpha)/se_orth_po_nosplit,
                          t_dml=(theta_dml_po - alpha)/se_dml_po)) +
  geom_histogram(aes(x = t_nonorth, y=after_stat(density), colour = "Non-orthogonal ML", fill="Non-orthogonal ML"),
                 bins = 30, alpha = 0.3) +
  geom_histogram(aes(x = t_orth_nosplit, y=after_stat(density), colour = "Double ML (no sample splitting)", fill="Double ML (no sample splitting)"),
                 bins = 30, alpha = 0.3) +
  geom_histogram(aes(x = t_dml, y=after_stat(density), colour = "Double ML with cross-fitting", fill="Double ML with cross-fitting"),
                 bins = 30, alpha = 0.3) +
  geom_vline(aes(xintercept = 0), col = "black") +
  suppressWarnings(geom_function(fun = dnorm, aes(colour = "N(0, 1)", fill="N(0, 1)"))) +
  scale_color_manual(name='',
                     breaks=c("Non-orthogonal ML", "Double ML (no sample splitting)", "Double ML with cross-fitting", "N(0, 1)"),
                     values=c("Non-orthogonal ML"="#005e73",
                              "Double ML (no sample splitting)"="#FF7E15",
                              "Double ML with cross-fitting"="#00C1D4",
                              "N(0, 1)"='black')) +
  scale_fill_manual(name='',
                    breaks=c("Non-orthogonal ML", "Double ML (no sample splitting)", "Double ML with cross-fitting", "N(0, 1)"),
                    values=c("Non-orthogonal ML"="#005e73",
                             "Double ML (no sample splitting)"="#FF7E15",
                             "Double ML with cross-fitting"="#00C1D4",
                             "N(0, 1)"=NA)) +
  xlim(c(-6.0, 6.0)) + xlab("") + ylab("") + theme_minimal() +
    theme(legend.position="bottom")
g_all

```


:::


::: {.column width="50%"}

```{r}
#| echo: true
#| eval: false


# simulating the data
library(DoubleML)
set.seed(1234)
n_rep = 1000 # number samples
n_obs = 500 # number of observations
n_vars = 20 # number of covariates
alpha = 0.5 # true treatment effect


data = list()
for (i_rep in seq_len(n_rep)) {
# command to simulate Y_i and T_i based on true non-linear nuisance functions m(x) and e(x)
  data[[i_rep]] = make_plr_CCDDHNR2018(alpha=alpha, n_obs=n_obs, dim_x=n_vars,
                                       return_type="data.frame")
}

# define custom (non-othogonal) score function
non_orth_score = function(y, d, l_hat, m_hat, g_hat, smpls) {
  u_hat = y - g_hat
  psi_a = -1*d*d
  psi_b = d*u_hat
  psis = list(psi_a = psi_a, psi_b = psi_b)
  return(psis)
}

library(mlr3)
library(mlr3learners)

# define the ml prediction models from the mlr3 package:
ml_l = lrn("regr.ranger", num.trees = 132, max.depth = 5, mtry = 12, min.node.size = 1) # learner for mu = E[Y|X]
ml_m = lrn("regr.ranger", num.trees = 378, max.depth = 3, mtry = 20, min.node.size = 6) # learner for e = E[T|X]


# run the simulation 
for (i_rep in seq_len(n_rep)) {
  df = data[[i_rep]]
  obj_dml_data = double_ml_data_from_data_frame(df, y_col = "y", d_cols = "d")
  # key function friom the DoubleML package
  obj_dml_plr_nonorth = DoubleMLPLR$new(obj_dml_data, # suppy data
                                        ml_l, ml_m, ml_g,# supply the machine learning methods
                                        n_folds=2, # no cross fitting at first
                                        score=non_orth_score, # supply custom score function
                                        # score='partialling out' # built-in orthogonal score function PLM
                                        apply_cross_fitting=TRUE) # no cross fitting at first
  # extract and store estimates for each sample
  obj_dml_plr_nonorth$fit()
  this_theta = obj_dml_plr_nonorth$coef
  this_se = obj_dml_plr_nonorth$se
  print(abs(theta_nonorth[i_rep] - this_theta))
  print(abs(se_nonorth[i_rep] - this_se))
  theta_nonorth[i_rep] = this_theta
  se_nonorth[i_rep] = this_se
}


```

:::



:::


# Double Machine Learning with Augmented Inverse Probability Weighting {data-stack-name="DML-AIPW"}

## Interactive Regression Model

- More general model that relaxes the homogeneous treatment assumption (binary $T_i$ is not additively separable anymore):
  $\begin{align}\begin{aligned}Y_i = g(T_i, \mathbf{X_i}) + \epsilon_{Y_i}, & &\mathbb{E}(\epsilon_{Y_i} | T_i,\mathbf{X_i}) = 0 \\T_i = m(\mathbf{X_i}) + \epsilon_{T_i}, & &\mathbb{E}(\epsilon_{T_i} | \mathbf{X_i}) = 0\end{aligned}\end{align}$

::: {.fragment}

- We can use the identification results from the Doubly Robust / AIPW estimator: 
  - Average potential outcome (APO):
    - $\mu_t^{\text{AIPW}} = \mathbb{E}[Y_i(t)] = \mathbb{E}\bigg[\mu(t, \mathbf{X_i}) + \frac{\mathbb{1}(T_i = t)(Y_i - \mu(t, \mathbf{X_i}))}{e_t(\mathbf{X_i})} \bigg] \\$
  - Average treatment effect (ATE):
    - $\tau_{\text{ATE}}^{\text{AIPW}} = \mathbb{E}[Y_i(1) - Y_i(0)] = \mathbb{E}\bigg[\mu(1, \mathbf{X_i}) - \mu(0, \mathbf{X_i}) + \frac{T_i(Y_i - \mu(1, \mathbf{X_i}))}{e_1(\mathbf{X_i})} - \frac{(1-T_i)(Y_i - \mu(0, \mathbf{X_i})}{e_0(\mathbf{X_i}))} \bigg]$
  
:::


## Double Machine Learning under AIPW {.smaller}



- [Chernozhukov et al. (2018)](https://doi.org/10.1111/ectj.12097) propose a three step procedure:

  1. Form prediction model for the treatment: $\hat{e}(\mathbf{X_i})$
  
  2. Form prediction model for the outcome: $\hat{\mu}(T_i, \mathbf{X_i})$
  
  3. a) Estimate the APO: 
    - $\mu_t^{\text{AIPW}} = \frac{1}{N}\sum_{i=1}^n \bigg(\hat{\mu}(t, \mathbf{X_i}) + \frac{\mathbb{1}(T_i = t)(Y_i - \hat{\mu}(t, \mathbf{X_i}))}{\hat{e}_t(\mathbf{X_i})} \bigg) \\$
    
  3. b) Estimate the ATE:
    - $\tau_{\text{ATE}}^{\text{AIPW}} = \frac{1}{N}\sum_{i=1}^n \bigg(\hat{\mu}(1, \mathbf{X_i}) - \hat{\mu}(0, \mathbf{X_i}) + \frac{T_i(Y_i - \hat{\mu}(1, \mathbf{X_i}))}{\hat{e}_1(\mathbf{X_i})} - \frac{(1-T_i)(Y_i - \hat{\mu}(0, \mathbf{X_i})}{\hat{e}_0(\mathbf{X_i}))} \bigg)$



::: {.fragment}

- To obtain a consistent, asymptotically normal and semi-parametrically efficient estimator that allows `standard (robust) inference`, we need the `same three key ingredients`:
  1. High-quality machine learning methods
  2. K-fold cross-validation
  3. `Neyman-orthogonal score function`: let's proof this!


:::



## DML-AIPW Score Function (1) {.smaller}

- As the score defining the ATE is just the difference between APOs, it inherits ist Neyman orthogonality. Hence let's focus on the AIPW score of the APO, which is:

$$\begin{align*}
&\mathbb{E}\bigg[ \underbrace{\mu(t, \mathbf{X_i}) + \frac{\mathbb{1}(T_i = t)(Y_i - \mu(t, \mathbf{X_i}))}{e_t(\mathbf{X_i})} - \mu_t^{\text{AIPW}}}_{\psi(Y_i, T_i, \mu(t, \mathbf{X_i}), e(\mathbf{X_i}))}\bigg] = 0 \\
\Rightarrow \mu_t^{\text{AIPW}} = & \mathbb{E}\bigg[\mu(t, \mathbf{X_i}) + \frac{\mathbb{1}(T_i = t)(Y_i - \mu(t, \mathbf{X_i}))}{e_t(\mathbf{X_i})} \bigg]
\end{align*}$$

- `Neyman-orthogonality of a score` $\psi$ means that the Gateaux derivative with respect to the nuisance parameters is zero in expectation at the true nuisance parameters (NP). This means:

$$\partial_r \mathbb{E}\left[\psi(Y_i, T_i, \mu + r(\tilde{\mu}-\mu), e + r(\tilde{e} - e)) \mid \mathbf{X_i = x}\right] |_{r=0} = 0$$

- where we suppress the dependencies of NPs and denote by, e.g., $\tilde{\mu}$ a value of the outcome nuisance that is different to the true value $\mu$. We can show this equation holds with the following four steps.



## DML-AIPW Score Function (2) {.smaller}

- (1) Add perturbations to the true nuisance parameters in the score:

$$
\begin{align*}
\psi&(Y_i, T_i, \mu + r(\tilde{\mu} - \mu), e + r(\tilde{e} - e)) \\ &= (\mu + r(\tilde{\mu} - \mu)) + \frac{ \mathbb{1}(T_i = t) Y_i}{e + r(\tilde{e} - e)} - \frac{\mathbb{1}(T_i = t) (\mu + r(\tilde{\mu} - \mu))}{e + r(\tilde{e} - e)} - \mu_t^{\text{AIPW}}
\end{align*}
$$


- (2) Take the conditional expectation:

$$
\begin{align*}
&\mathbb{E}\left[ \psi(Y_i, T_i, \mu + r(\tilde{\mu} - \mu), e + r(\tilde{e} - e)) \mid \mathbf{X_i = x} \right] \\ &= \mathbb{E}\left[ (\mu + r(\tilde{\mu} - \mu)) + \frac{ \mathbb{1}(T_i = t) Y_i}{e + r(\tilde{e} - e)} - \frac{\mathbb{1}(T_i = t) (\mu + r(\tilde{\mu} - \mu))}{e + r(\tilde{e} - e)} - \mu_t^{\text{AIPW}} \bigg| \mathbf{X_i = x} \right] \\ &= (\mu + r(\tilde{\mu} - \mu)) + \frac{ e\mu}{e + r(\tilde{e} - e)} - \frac{e (\mu + r(\tilde{\mu} - \mu))}{e + r(\tilde{e} - e)} - \mu_t^{\text{AIPW}}
\end{align*}
$$
- where we use that $\mathbb{E}[\mathbb{1}(T_i = t)Y_i \mid \mathbf{X_i = x}] \overset{(A3)}{=} \mathbb{E}[\mathbb{1}(T_i = t)Y_i(t) \mid \mathbf{X_i = x}] \overset{(A1)}{=} e\mu$ and $\mathbb{E}[\mathbb{1}(T_i = t) \mid \mathbf{X_i = x}] = e$.


## DML-AIPW Score Function (3) {.smaller}


- (3) Take the derivative with respect to $r$:

$$
\begin{align*}
\frac{\partial}{\partial r} &\mathbb{E}[\psi(Y_i, T_i, \mu + r(\tilde{\mu} - \mu), e + r(\tilde{e} - e)) \mid X_i = x] \\ 
&= (\tilde{\mu} - \mu) - \frac{e\mu(\tilde{e} - e)}{(e + r(\tilde{e} - e))^2} - \frac{e(\tilde{\mu} - \mu)(e+r(\tilde{e} - e)) - e(\mu + r(\tilde{\mu} - \mu))(\tilde{e} - e)}{(e + r(\tilde{e} - e))^2}
\end{align*}
$$

- (4) Evaluate at the true nuisance values, i.e. set $r = 0$:

$$
\begin{align*}
\frac{\partial}{\partial r} &\mathbb{E}[\psi(Y_i, T_i, \mu + r(\tilde{\mu} - \mu), e + r(\tilde{e} - e)) \mid X_i = x] |_{r=0} \\ 
&= (\tilde{\mu} - \mu) - \frac{e\mu(\tilde{e} - e)}{(e + 0(\tilde{e} - e))^2} - \frac{e(\tilde{\mu} - \mu)(e+r(\tilde{e} - e)) - e(\mu + 0(\tilde{\mu} - \mu))(\tilde{e} - e)}{(e + 0(\tilde{e} - e))^2} \\
&= (\tilde{\mu} - \mu) - \frac{e\mu(\tilde{e} - e)}{e^2} - \frac{e(\tilde{\mu} - \mu)e - e\mu(\tilde{e} - e)}{e^2} \\
&= (\tilde{\mu} - \mu) - \frac{e\mu(\tilde{e} - e)}{e^2} - \frac{e^2}{e^2}(\tilde{\mu} - \mu) + \frac{e\mu(\tilde{e} - e)}{e^2}\\
&= 0
\end{align*}
$$

## DML-AIPW: Example {.smaller}

- Assess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.


```{r}
#| echo: true

# Load required packages
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)

# suppress messages during fitting
lgr::get_logger("mlr3")$set_threshold("warn")

# load data as a data.table
data = fetch_401k(return_type = "data.table", instrument = TRUE)

# Set up basic model: Specify variables for data-backend
features_base = c("age", "inc", "educ", "fsize","marr", "twoearn", "db", "pira", "hown")

# Initialize DoubleMLData (data-backend of DoubleML)
data_dml_base = DoubleMLData$new(data,
                                 y_col = "net_tfa", # outcome variable
                                 d_cols = "e401", # treatment variable
                                 x_cols = features_base) # covariates

# Initialize Random Forrest Learner
randomForest = lrn("regr.ranger")
randomForest_class = lrn("classif.ranger")

# Random Forest
set.seed(123)
dml_irm_forest = DoubleMLIRM$new(data_dml_base,
                                 ml_g = randomForest,
                                 ml_m = randomForest_class,
                                 score = "ATE",
                                 trimming_threshold = 0.01,
                                 apply_cross_fitting = TRUE,
                                 n_folds = 5)

# Set nuisance-part specific parameters
dml_irm_forest$set_ml_nuisance_params(
    "ml_g0", "e401", list(max.depth = 6, mtry = 4, min.node.size = 7)) # learner for outcome 0
dml_irm_forest$set_ml_nuisance_params(
    "ml_g1", "e401", list(max.depth = 6, mtry = 3, min.node.size = 5)) # learner for outcome 1
dml_irm_forest$set_ml_nuisance_params( 
    "ml_m", "e401", list(max.depth = 6, mtry = 3, min.node.size = 6)) # learner for treatment

dml_irm_forest$fit()
dml_irm_forest$summary()
```



# General Recipe {data-stack-name="General Recipe"}

## Definitions

- Data and parameters;
  - $W$ is a set of `observed variables`; e.g., $W = \{Y, T, X\}$.
  - $\theta$ is the `target parameter`.
  - $\eta$ is a set of `nuisance parameters`; e.g., $\eta = \{\mu(X), e(X)\}$.


::: {.fragment}


- Score functions $\psi(W, \tilde{\theta}, \tilde{\eta})$ must satisfy two properties in Double ML:
  - $\mathbb{E}[\psi(W, \theta, \eta)] = 0$: i.e. `moment condition` with expectation zero if evaluated at true parameters.
  - $\partial_r\mathbb{E}[\psi(W, \theta, \eta + r(\hat{\eta} - \eta))]|_{r=0} = 0$: i.e. `Neyman-orthogonality`.

:::


## Examples 

- Moment condition of the residual-on-residual regression:
  - $\mathbb{E} \left[ (Y - \mu(X) - \tau (T - e(X))) (T - e(X)) \right] = 0$
  - $W = (T, X, Y), \quad \theta = \tau, \quad \eta = (\mu(X), e(X))$
  - with $\mu(X) := \mathbb{E}[Y \mid X]$ and $e(X) := \mathbb{E}[T \mid X]$


::: {.fragment}

- Moment condition of the AIPW-ATE:
  - $\mathbb{E} \left[ \mu(1, X) - \mu(0, X) + \frac{T(Y - \mu(1,X))}{e(X)} - \frac{(1 - T)(Y - \mu(0, X))}{1 - e(X)} - \tau_{ATE} \right] = 0$
  - $W = (T, X, Y), \quad \theta = \tau_{\text{ATE}}, \quad \eta = (\mu(1, X), \mu(0, X), e(X))$
  - with $\mu(t,X) := \mathbb{E}[Y \mid T = t, X]$ and $e(X) := \mathbb{E}[T=1 \mid X]$

:::


## Linear Score Functions 

- We will focus on linear score functions that can be represented as follows:
  - $\psi(W, \tilde{\theta}, \tilde{\eta}) = \tilde{\theta}\psi_a(W, \tilde{\eta}) + \psi_b(W, \tilde{\eta})$
- such that the moment condition can be written as:
  - $\mathbb{E}[\psi(W, \theta, \eta)] = \theta \mathbb{E}[\psi_a(W, \eta)] +  \mathbb{E}[\psi_b(W, \eta)] = 0$
- and the solution is:
  - $\theta = - \frac{\mathbb{E}[\psi_b(W, \eta)]}{\mathbb{E}[\psi_a(W, \eta)]}$




## Example Residual-on-residual Regression

- Moment condition:


$$
\begin{align*}
\mathbb{E} \left[ (Y - \mu(X) - \tau(T - e(X)))(T - e(X)) \right] &= 0 \\
\mathbb{E} \left[ (Y - \mu(X))(T - e(X)) - \tau(T - e(X))(T - e(X)) \right] &= 0 \\
\tau \mathbb{E} [ \underbrace{-1(T - e(X))^2}_{\psi_a} ] + \mathbb{E} [ \underbrace{(Y - \mu(X))(T - e(X))}_{\psi_b} ] &= 0 \\
\Rightarrow \tau = - \frac{\mathbb{E}[\psi_b(W; \eta)]}{\mathbb{E}[\psi_a(W; \eta)]} = \frac{\mathbb{E}[(Y - \mu(X))(T - e(X))]}{\mathbb{E}[(T - e(X))^2]}
\end{align*}
$$


## Example AIPW-ATE {.smaller}

- Moment condition:


$$
\begin{align*}
\mathbb{E} \left[ \mu(1, X) - \mu(0, X) + \frac{T(Y - \mu(1, X))}{e(X)} - \frac{(1 - T)(Y - \mu(0, X))}{1 - e(X)} - \tau_{\text{ATE}} \right] &= 0 \\
\tau_{\text{ATE}} \underbrace{(-1)}_{\psi_a} + \mathbb{E} \bigg[ \underbrace{\mu(1, X) - \mu(0, X) + \frac{T(Y - \mu(1, X))}{e(X)} - \frac{(1 - T)(Y - \mu(0, X))}{1 - e(X)}}_{\psi_b} \bigg] &= 0 \\
\Rightarrow \tau_{\text{ATE}} = -\frac{\mathbb{E}[\psi_b(W; \eta)]}{\mathbb{E}[\psi_a(W; \eta)]} = \mathbb{E} \left[ \mu(1, X) - \mu(0, X) + \frac{T(Y - \mu(1, X))}{e(X)} - \frac{(1 - T)(Y - \mu(0, X))}{1 - e(X)} \right]
\end{align*}
$$


## Double ML Recipe


1. Find `Neyman-orthogonal score` for your target parameter:
    - can be constructed ([see Chernozhukov et al. (2018), Section 2](https://doi.org/10.1111/ectj.12097))
2. `Predict nuisance parameters` $\hat{\eta}$ with cross-fitted high-quality ML.
3. `Solve empirical moment condition` to estimate the target parameter:
    - $\theta = - \frac{\mathbb{E}[\psi_b(W, \eta)]}{\mathbb{E}[\psi_a(W, \eta)]}$
4. `Calculate standard error`:
    - $\hat{\sigma}^2 = \frac{N^{-1} \sum_{i} \psi(W_i; \hat{\theta}, \hat{\eta}_i)^2}{[N^{-1} \sum_{i} \psi_a(W_i; \hat{\eta}_i)]^2} \quad \Rightarrow \quad \text{se}(\hat{\theta}) = \sqrt{\frac{\hat{\sigma}^2}{N}}$
    - To calculate t-values, confidence intervals, etc.
    - Can be motivated by the concept of `influence functions`.




## Standard Errors in DML {.smaller}

- `Influence functions`: 
  - $\Psi(W; \theta, \eta) := - \mathbb{E} \left[ \frac{\partial \psi}{\partial \theta} \right]^{-1} \psi(W; \theta, \eta) = - \mathbb{E}[\psi_a(W; \eta)]^{-1} \psi(W; \theta, \eta)$
  - `Scaled version of the score` with important characteristics:
    - $\Psi(W_i; \theta, \eta_i)$ measures the influence of an estimator $\theta$ to infinitesimal changes in the distribution, i.e. of each observation $W_i$
    - $\mathbb{E}[\Psi(W; \theta, \eta)] = \mathbb{E}[ -\mathbb{E}[\psi_a(W; \eta)]^{-1} \psi(W; \theta, \eta)] = -\mathbb{E}[\psi_a(W; \eta)]^{-1}  \underbrace{\mathbb{E}[\psi(W; \theta, \eta)]}_{=0} = 0$


::: {.fragment}

- Estimator distribution and influence function are closely linked:
  - $\sqrt{N}(\hat{\theta} - \theta) = \frac{1}{\sqrt{N}} \sum_{i} \psi(W_i; \theta, \eta_i) + o_p(1) \xrightarrow{d} N(0, \underbrace{\operatorname{Var}[\psi(W; \theta, \eta)]}_{\sigma^2})$
- Estimator variance (suppressing arguments for brevity):
  - $\sigma^2 = \text{Var}[\psi] = \mathbb{E}[\psi^2] - \underbrace{\mathbb{E}[\psi]^2}_{=0} = \mathbb{E}[\psi^2] = \mathbb{E}[(\mathbb{E}[\psi_a]^{-1} \psi)^2] = \mathbb{E}[\psi_a]^{-2} \mathbb{E}[\psi^2] = \frac{\mathbb{E}[\psi^2]}{\mathbb{E}[\psi_a]^2}$


:::

{{< include ../R/about.qmd >}}
