[
  {
    "objectID": "slides/02_graphs.html#graphs",
    "href": "slides/02_graphs.html#graphs",
    "title": "(2) Graphical Causal Models",
    "section": "Graphs",
    "text": "Graphs\n\n\nGraph theory provides a useful mathematical language to think about causality.\nA graph consists of vertices (or nodes) V and edges (or links) E. Vertices represent variables in the model and edges the connections between them.\nEdges can either be undirected or directed."
  },
  {
    "objectID": "slides/02_graphs.html#directed-graphs",
    "href": "slides/02_graphs.html#directed-graphs",
    "title": "(2) Graphical Causal Models",
    "section": "Directed Graphs",
    "text": "Directed Graphs\n\n\nCausal relationships are generally seen as asymmetric:\n\nIf ‘A causes B’ is true, then ‘B causes A’ must be false.\nTherefore we’ll work with directed graphs most of the times.\n\nWe’ll sometimes use terminology of kinship:\n\nA is parent of B.\nB is child of A.\nA is ancestor of D.\nD is descendant of A.\n\nA path is a sequence of edges connecting two vertices:\n\n\\(B \\gets A \\to C \\to D\\) is a path from B to D.\nA path can go either along or against arrowheads.\nA path along the arrows is called directed: \\(A \\to C \\to D\\)."
  },
  {
    "objectID": "slides/02_graphs.html#directed-acyclic-graphs-dags",
    "href": "slides/02_graphs.html#directed-acyclic-graphs-dags",
    "title": "(2) Graphical Causal Models",
    "section": "Directed Acyclic Graphs (DAGs)",
    "text": "Directed Acyclic Graphs (DAGs)\n\n\nA directed path from a node to itself is called directed cycle or feedback loop: \\(B \\to C \\to D \\to B\\).\nGraph with feedback loops is called cyclic, with no feedback loops acyclic.\nWe focus on directed acyclic graphs (DAGs) in this course:\n\nexclude variables that influence themselves.\nEconometricians speak of recursive models that can be given a causal interpretation."
  },
  {
    "objectID": "slides/02_graphs.html#bayesian-networks",
    "href": "slides/02_graphs.html#bayesian-networks",
    "title": "(2) Graphical Causal Models",
    "section": "Bayesian Networks",
    "text": "Bayesian Networks\n\nProbabilistic graphical models (not causal):\n\nModelling the joint data distribution by factorizing with the chain rule of probability: \\(P(x_1, x_2, \\ldots, x_n) = P(x_1) \\prod_{i} P(x_i \\mid x_{i-1}, \\ldots, x_1)\\)\nn = 4: \\(P(x_1, x_2, x_3, x_4) = P(x_1)P(x_2 \\mid x_1)P(x_3 \\mid x_2, x_1)P(x_4 \\mid x_3, x_2, x_1)\\)\n\\(P(x_4 \\mid x_3, x_2, x_1)\\) alone requires \\(2^3 - 1 = 8\\) parameters = &gt; Focus on local dependencies:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P_{joint} = P(x_1)P(x_2 \\mid x_1)P(x_3 \\mid x_2, x_1)P(x_4 \\mid x_3)\\)\n\n\n\n\n\n\n\n\n\n\n\\(P_{joint} = P(x_1)P(x_2)P(x_3 \\mid x_1)P(x_4 \\mid x_3)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#bayesian-networks-assumptions",
    "href": "slides/02_graphs.html#bayesian-networks-assumptions",
    "title": "(2) Graphical Causal Models",
    "section": "Bayesian Networks: Assumptions",
    "text": "Bayesian Networks: Assumptions\nGiven a probability distribution and a corresponding DAG, we can formalize the specification of local (in-) dependencies with:\n\n\n\nAssumption 2.1: “Local Markov Assumption”\n\n\nGiven its parents in the DAG, a node X is independent of all its non-descendants.\n\n\n\nIt follows:\n\n\n\nDefinition 2.1: “Bayesian Network Factorization”\n\n\nGiven a probability distribution \\(P\\) and a DAG \\(G\\), \\(P\\) factorizes according to \\(G\\) if:  \\(P(x_1, x_2, \\ldots, x_n) = \\prod_{i} P(x_i \\mid pa_i)\\)  with \\(pa_i\\) denoting the parents of node \\(i\\) in \\(G\\).\n\n\n\nThen \\(P\\) and \\(G\\) are called Markov compatible.\n\n\n\nAssumption 2.2: “Minimality Assumption”\n\n\n\nGiven its parents in the DAG, a node - is independent of all its non-descendants.\nAdjacent nodes in the DAG are dependent."
  },
  {
    "objectID": "slides/02_graphs.html#causal-graph-assumption",
    "href": "slides/02_graphs.html#causal-graph-assumption",
    "title": "(2) Graphical Causal Models",
    "section": "Causal Graph: Assumption",
    "text": "Causal Graph: Assumption\nWe need a further assumption to go from associations to causal relationships in a DAG:\n\n\n\nDefinition 2.2: “What is a cause?”\n\n\nA variable X is said to be a cause of a variable Y if Y can change in response to changes in X.\n\n\n\nAn outcome variable Y listens to X.\n\n\n\nAssumption 2.3: “(Strict) Causal Edge Assumption”\n\n\nIn a directed graph, every parent is a direct cause of all its children.\n\n\n\nThis assumption is “strict” in the sense that every edge is active, just like in DAGs that satisfy minimality."
  },
  {
    "objectID": "slides/02_graphs.html#graph-building-blocks-1",
    "href": "slides/02_graphs.html#graph-building-blocks-1",
    "title": "(2) Graphical Causal Models",
    "section": "Graph Building Blocks",
    "text": "Graph Building Blocks\n\nUnderstanding the flow of association and causation in DAGs based on minimal building blocks:\n\n\n\n\nTwo unconnected nodes: \\(P(x_1, x_2) = P(x_1) P(x_2)\\)\n\n\n\n\n\n\n\n\n\n\n\n\nTwo connected nodes: \\(P(x_1, x_2) = P(x_1) P(x_2 \\mid x_1)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain:\n\n\n\n\n\n\n\n\n\n\n\n\nFork:\n\n\n\n\n\n\n\n\n\n\n\n\nImmorality:"
  },
  {
    "objectID": "slides/02_graphs.html#chains",
    "href": "slides/02_graphs.html#chains",
    "title": "(2) Graphical Causal Models",
    "section": "Chains",
    "text": "Chains\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x_1\\) and \\(x_3\\) are associated through \\(x_2\\)\n\nflow of association is symmetric whereas the flow of causality is directed\n\n\"Local Markov Assumption\": we can block the associative path by conditioning on the parent \\(x_2\\)\n\n\\(x_1 \\perp\\!\\!\\!\\perp x_3 | x_2\\)\n=&gt; \\(P(x_1, x_3 | x_2) = P(x_1 | x_2) P(x_3 | x_2)\\)\nProof?"
  },
  {
    "objectID": "slides/02_graphs.html#chains-proof",
    "href": "slides/02_graphs.html#chains-proof",
    "title": "(2) Graphical Causal Models",
    "section": "Chains: Proof",
    "text": "Chains: Proof\n\n\"Bayesian network factorization\" of chains:\n\n\\(P(x_1, x_2, x_3) = P(x_1) P(x_2 | x_1) P(x_3 | x_2)\\)\n\n\"Bayes' rule\":\n\n\\(P(x_1, x_3 | x_2) = \\frac{P(x_1, x_2, x_3)}{P(x_2)}\\)\n\nSo that:\n\n\\(P(x_1, x_3 | x_2) = \\frac{P(x_1) P(x_2 | x_1) P(x_3 | x_2)}{P(x_2)}\\)\n\n\"Bayes' rule\" twice more:\n\n\\(P(x_2 | x_1) = \\frac{P(x_1, x_2)}{P(x_1)}\\) and \\(P(x_1 | x_2) = \\frac{P(x_1, x_2)}{P(x_2)}\\)\n\nSo that we finally obtain q.e.d.:\n\n\\(P(x_1, x_3 | x_2) = \\frac{P(x_1, x_2)}{P(x_2)} P(x_3 | x_2) = P(x_1 | x_2) P(x_3 | x_2)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#forks",
    "href": "slides/02_graphs.html#forks",
    "title": "(2) Graphical Causal Models",
    "section": "Forks",
    "text": "Forks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x_1\\) and \\(x_3\\) are associated through \\(x_2\\) as common cause or confounder\n\"Local Markov Assumption\": we can block the associative path by conditioning on parent \\(x_2\\)\n\n\\(x_1 \\perp\\!\\!\\!\\perp x_3 | x_2\\)\n=&gt; \\(P(x_1, x_3 | x_2) = P(x_1 | x_2) P(x_3 | x_2)\\)\n\nProof? Do try this sh.. at home!"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders",
    "href": "slides/02_graphs.html#immoralities-and-colliders",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders",
    "text": "Immoralities and Colliders\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nno association in the first place: \\(x_1 \\perp\\!\\!\\!\\perp x_3\\)\n\nno common cause (“confounder” like in a fork)\nneither is \\(x_3\\) a descendant of \\(x_1\\) (like in a chain)\n\\(x_1\\) and \\(x_3\\) are unrelated things contributing to \\(x_2\\)\n\\(x_2\\) acts as a \"collider\" that blocks the path between \\(x_1\\) and \\(x_3\\)\n\nbut only if we do not condition on \\(x_2\\)"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders-proof",
    "href": "slides/02_graphs.html#immoralities-and-colliders-proof",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders: Proof",
    "text": "Immoralities and Colliders: Proof\n\n\"Bayesian network factorization\" of immoralities:\n\n\\(P(x_1, x_2, x_3) = P(x_1)P(x_3)P(x_2 \\mid x_1, x_3)\\)\n\nMarginalizing out \\(x_2\\) (assuming discrete variables):\n\n\\(P(x_1, x_3) = \\sum_{x_2}P(x_1)P(x_3)P(x_2 \\mid x_1, x_3) = P(x_1)P(x_3) \\sum_{x_2}P(x_2 \\mid x_1, x_3)\\)\n\nSince summing over all possible values of the conditional probability \\(P(x_2 \\mid x_1, x_3)\\) equals 1, we obtain q.e.d.:\n\n\\(P(x_1, x_3) = P(x_1)P(x_3)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders-example",
    "href": "slides/02_graphs.html#immoralities-and-colliders-example",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders: Example",
    "text": "Immoralities and Colliders: Example\n\nLooks and talent are independent of each other in the general population\n\nbut both contribute to success (e.g. being casted as an actor, getting funding as founder, being in a relationship)\nin a selected sample of (un-) successful actors, looks and talent become negatively associated\nconditioning on success (by selecting a subsample) creates a selection bias (or Berkson's paradox)"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders-numerical-example",
    "href": "slides/02_graphs.html#immoralities-and-colliders-numerical-example",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders: Numerical Example",
    "text": "Immoralities and Colliders: Numerical Example\n\nData generating process (dgp): \\(x_1 \\sim N(0, 1), \\quad x_3 \\sim N(0,1), \\quad x_2 = x_1 + x_3\\)\nCovariance in the population:\n\n\\[\\begin{align*}\n\\text{Cov}(x_1, x_3) &= \\mathbb{E}[(x_1 - \\mathbb{E}[x_1])(x_3 - \\mathbb{E}[x_3])] \\\\\n&= \\mathbb{E}[x_1x_3] \\quad (\\text{zero mean})\\\\\n&= \\mathbb{E}[x_1]\\mathbb{E}[x_3] \\quad (\\text{independent}) \\\\\n&= 0\n\\end{align*}\\]\n\n\nConditional covariance is the expected value of the product \\(x_1x_3\\), conditioned on \\(x_2\\) being equal to some value \\(x\\):\n\n\\[\\begin{align*}\n\\text{Cov}(x_1, x_3 | x_2 = x)\n&= \\mathbb{E}[x_1x_3 | x_2 = x] \\\\\n&= \\mathbb{E}[x_1(x - x_1)] \\quad (\\text{substituting x_3 by x - x_1 as per dgp}) \\\\\n&= x\\mathbb{E}[x_1] - \\mathbb{E}[x_1^2] \\quad (\\text{x is constant and expectations linear}) \\\\\n&= -1 \\quad (\\text{E(x_1) = 0 and E(x_1*x_1) = Var(x_1) = 1})\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders-numerical-example-1",
    "href": "slides/02_graphs.html#immoralities-and-colliders-numerical-example-1",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders: Numerical Example",
    "text": "Immoralities and Colliders: Numerical Example\n\n\nShow code\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggpubr) \n\n# simulate data\nset.seed(123) # for reproducibility\nlooks &lt;- rnorm(1000)\ntalent &lt;- rnorm(1000)\nx &lt;- talent + looks\ngroup &lt;- 1 * (x &gt; quantile(x, c(.75)))\n\n# create a dataframe\ndf &lt;- data.frame(looks, talent, group) %&gt;%\n  mutate(group = if_else(group == 1, \"With Job\", \"Without Job\")) %&gt;%\n  add_row(looks = Inf, talent = -Inf, group = \"Overall\")\n\n# plot\nggplot(df, aes(x = looks, y = talent)) +\n  geom_point(aes(color = group)) + \n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ x, aes(color = \"Overall\")) + # Regression line for all data\n  geom_smooth(data = subset(df, group == \"With Job\"), method = \"lm\", se = FALSE, formula = y ~ x, aes(color = \"With Job\")) +\n  geom_smooth(data = subset(df, group == \"Without Job\"), method = \"lm\", se = FALSE, formula = y ~ x, aes(color = \"Without Job\")) +\n  stat_regline_equation(aes(label = ..eq.label.., color = as.factor(group)), formula = y ~ x) +\n  stat_regline_equation(aes(label = ..eq.label.., color = \"Overall\"), formula = y ~ x) +\n  labs(color = \"Group\") +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "slides/02_graphs.html#descendants-of-colliders",
    "href": "slides/02_graphs.html#descendants-of-colliders",
    "title": "(2) Graphical Causal Models",
    "section": "Descendants of Colliders",
    "text": "Descendants of Colliders"
  },
  {
    "objectID": "slides/02_graphs.html#d-separation-1",
    "href": "slides/02_graphs.html#d-separation-1",
    "title": "(2) Graphical Causal Models",
    "section": "d-Separation",
    "text": "d-Separation\n\nSo far we only looked at graphs containing three variables. Can we somehow generalize these criteria?\n\n\n\n\nDefinition 2.3: “Blocked Path”\n\n\nA path \\(p\\) between nodes \\(X\\) and \\(Y\\) is blocked by a (potentially empty) conditioning set \\(Z\\) if either of the following is true:\n\n\\(p\\) contains a chain of nodes \\(... \\rightarrow W \\rightarrow ...\\) or a fork \\(... \\leftarrow W \\rightarrow ...\\), and \\(W\\) is conditioned, i.e. \\(W \\in Z\\).\n\\(p\\) contains an immorality \\(... \\rightarrow W \\leftarrow ...\\), and the collider \\(W\\) is not conditioned, i.e. \\(W \\notin Z\\).\n\n\n\n\n\n\n\nDefinition 2.4: “d-Separation”\n\n\nTwo nodes \\(X\\) and \\(Y\\) are d-separated by a set of nodes \\(Z\\) if all of the paths between \\(X\\) and \\(Y\\) are blocked by \\(Z\\)."
  },
  {
    "objectID": "slides/02_graphs.html#d-separation-2",
    "href": "slides/02_graphs.html#d-separation-2",
    "title": "(2) Graphical Causal Models",
    "section": "d-Separation",
    "text": "d-Separation\n\nIf two nodes are d-separated, and not d-connected, the variables they represent are independent.\n\n\n\n\nTheorem 2: “Global Markov Assumption”\n\n\nGiven that \\(P\\) is Markov compatible with respect to \\(G\\) (satisfies the local Markov assumption), if \\(X\\) and \\(Y\\) are d-separated in \\(G\\) conditioned on \\(Z\\), then \\(X\\) and \\(Y\\) are independent in \\(P\\) conditioned on \\(Z\\).\nFormally, \\(X \\perp\\!\\!\\!\\perp_{G} Y \\,|\\, Z \\implies X \\perp\\!\\!\\!\\perp_{P} Y \\,|\\, Z\\)."
  },
  {
    "objectID": "slides/02_graphs.html#d-separation-practice-1",
    "href": "slides/02_graphs.html#d-separation-practice-1",
    "title": "(2) Graphical Causal Models",
    "section": "d-Separation Practice 1",
    "text": "d-Separation Practice 1\n\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\ndag &lt;- dagify(\n  # relationship for each node\n  W ~ Z,\n  W ~ X,\n  Y ~ X,\n  U ~ W,\n # Location of each node\n  coords = list(\n    x = c(Z = 0, W = 1, X = 2, Y = 3, U = 1),\n    y = c(Z = 0, W = -0.5, X = 0, Y = 0, U = -1)\n  )\n)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y,\n             xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\") +\n  geom_dag_edges() +\n  geom_dag_point(shape = 1) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\n\\(Z\\) and \\(Y\\) d-separated conditional on\n\n\\(\\emptyset\\) ? 2. \\(\\{W\\}\\) ? 3. \\(\\{U\\}\\) ? 4. \\(\\{W, X\\}\\) ?\n\n\n\n\n\n1:\n\n\nlibrary(dagitty)\ndag &lt;- dagify(\n  W ~ Z,\n  W ~ X,\n  Y ~ X,\n  U ~ W\n)\ndseparated(dag, X=\"Z\", Y=\"Y\", Z = c())\n\n[1] TRUE\n\n\n\n2:\n\n\n\n[1] FALSE\n\n\n\n3:\n\n\n\n[1] FALSE\n\n\n\n4:\n\n\n\n[1] TRUE"
  },
  {
    "objectID": "slides/02_graphs.html#d-separation-practice-2",
    "href": "slides/02_graphs.html#d-separation-practice-2",
    "title": "(2) Graphical Causal Models",
    "section": "d-Separation Practice 2",
    "text": "d-Separation Practice 2\n\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\ndag &lt;- dagify(\n  Y ~ M2 + X3 + W3,\n  W3 ~ W2,\n  W1 ~ W2,\n  T ~ W1,\n  M1 ~ T,\n  M2 ~ M1,\n  X1 ~ T,\n  X3 ~ Y,\n  X2 ~ X1 + X3,\n  coords = list(\n    x = c(T = 0, W1 = 1, W2 = 1.5, W3 = 2, M1 = 1, M2 = 2, Y = 3, X1 = 1, X2 = 1.5, X3 = 2),\n    y = c(T = -1, W1 = 0, W2 = 0.5, W3 = 0, M1 = -1, M2 = -1, Y = -1, X1 = -2, X2 = -2.5, X3 = -2)\n  )\n)\n\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y,\n             xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\") +\n  geom_dag_edges() +\n  geom_dag_point(shape = 1) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\n\\(T\\) and \\(Y\\) d-separated conditional on\n\n\\(\\emptyset\\) ? 2. \\(\\{W_2\\}\\) ? 3. \\(\\{W_2, M_1\\}\\) ?\n\\(\\{W_1, M_2\\}\\) ? 5. \\(\\{W_1, M_2, X_2 \\}\\) ? 6. \\(\\{W_1, M_2, X_2, X_3 \\}\\) ?\n\n\n\n\n\n1:\n\n\n\n[1] FALSE\n\n\n\n2:\n\n\n\n[1] FALSE\n\n\n\n3:\n\n\n\n[1] TRUE\n\n\n\n4:\n\n\n\n[1] TRUE\n\n\n\n5:\n\n\n\n[1] FALSE\n\n\n\n6:\n\n\n\n[1] TRUE"
  },
  {
    "objectID": "slides/02_graphs.html#flow-of-association-and-causation---summary",
    "href": "slides/02_graphs.html#flow-of-association-and-causation---summary",
    "title": "(2) Graphical Causal Models",
    "section": "Flow of Association and Causation - Summary",
    "text": "Flow of Association and Causation - Summary\n\nTotal association between two variables flows along all unblocked paths in a causal graph.\n\nAssociation that flows along directed, unblocked paths is causal association.\nThe remaining association is non-causal association, e.g. selection bias or confounding association.\nCausal association is asymmetric, non-causal association is symmetric.\nCausal association is a subcategory of total association.\n\nd-separation can imply “Association is Causation`\n\nIgnoring the causal paths, are X and Y d-separated otherwise?"
  },
  {
    "objectID": "slides/02_graphs.html#structural-causal-models",
    "href": "slides/02_graphs.html#structural-causal-models",
    "title": "(2) Graphical Causal Models",
    "section": "Structural Causal Models",
    "text": "Structural Causal Models\n\n\n\nA DAG represents an underlying structural causal model:\n\\(f_i\\)’s can be arbitrary, non-parametric functions\n\nas opposed to structural equation models (SEM) in econometrics\n\n\\(\\epsilon_i\\)’s are unobserved error terms\n\nMarkovian model: all errors are assumed to be jointly independent and hence not shown in the graph.\nsemi-Markovian model: some errors are correlated and shown in the graph; e.g. \\(u\\) in the example.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(Y = f_1(T, \\epsilon_1)\\)\n\\(T = f_2(X_1, X_2, \\epsilon_2)\\)\n\\(X_1 = f_3(u, \\epsilon_3)\\)\n\\(X_2 = f_4(u, \\epsilon_4)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#conditioning-vs-intervention",
    "href": "slides/02_graphs.html#conditioning-vs-intervention",
    "title": "(2) Graphical Causal Models",
    "section": "Conditioning vs Intervention",
    "text": "Conditioning vs Intervention\n\n\n\n\n\n\nNeal, Brady (2020). Introduction to causal inference from a Machine Learning Perspective. Course Lecture Notes (draft)."
  },
  {
    "objectID": "slides/02_graphs.html#interventions-and-the-do-operator",
    "href": "slides/02_graphs.html#interventions-and-the-do-operator",
    "title": "(2) Graphical Causal Models",
    "section": "Interventions and the do-Operator",
    "text": "Interventions and the do-Operator\n\nInterventions in causal models are defined by the do-operator.\nNotation: \\(P(Y|do(T = t))\\) stands for:\n\n“probability distribution of \\(Y\\) if we fix \\(T\\) to the specific value \\(t\\)”.\nInterventional distributions are not the same as conditional or observational distributions.\n\nWe can also write the ATE with it: \\[\\text{ATE} = \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)] = \\mathbb{E}[Y|do(T = 1)] - \\mathbb{E}[Y|do(T = 0)]\\]\nMany (if not most) questions we try to answer with data involve some form of intervention, treatment, or action:\n\nP(Performance | do(Training))\nP(Sales | do(Incentive))\nP(Click-through Rate | do(Advertising))\nP(Churn | do(Call Center))"
  },
  {
    "objectID": "slides/02_graphs.html#interventions-and-the-do-operator-1",
    "href": "slides/02_graphs.html#interventions-and-the-do-operator-1",
    "title": "(2) Graphical Causal Models",
    "section": "Interventions and the do-Operator",
    "text": "Interventions and the do-Operator\n\nIn graphical models, intervening on a variable X is similar to a kind of surgery in which we remove all edges into that variable:\n\n\n\n\nPre-Intervention\n\n\n\n\n\n\n\n\n\n\n\n\\(Y = f_y(T, X, \\epsilon_y)\\)\n\\(T = f_2(X, \\epsilon_T)\\)\n\\(X = f_3(\\epsilon_X)\\)\n\n\n\nPost-Intervention\n\n\n\n\n\n\n\n\n\n\n\n\\(Y = f_y(T, X, \\epsilon_y)\\)\n\\(T = t\\)\n\\(X = f_3(\\epsilon_X)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#interventions-and-the-do-operator-2",
    "href": "slides/02_graphs.html#interventions-and-the-do-operator-2",
    "title": "(2) Graphical Causal Models",
    "section": "Interventions and the do-Operator",
    "text": "Interventions and the do-Operator\n\nBayesian network factorization of the pre-intervention DAG:\n\n\\(P(Y, T, X) = P(X)P(T|X)P(Y|T,X)\\)\n\nIf we intervene on \\(T\\) and set it to \\(t\\), the factorization changes:\n\n\\(P(Y, X | do(T = t)) = P(X)P(Y|T = t, X)\\)\n\nMarginalizing out \\(X\\) gives the interventional distribution of \\(Y\\):\n\n\\(P(Y | do(T = t)) = \\sum_{x} P(Y|T = t, X = x)P(X = x)\\)\n\nTo obtain the causal effect, we condition on the values of \\(X\\) and average over the distribution.\nWe only obtain the associational counterpart \\(P(Y|T = t)\\) if \\(P(X)\\) would have to be replaced by \\(P(X|T = t)\\).\n\nThen: \\(\\sum_{x} P(Y|T = t, X = x)P(X|T = t) = \\sum_{x} P(Y, X|T = t) = P(Y| T= t)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#interventions-and-the-do-operator-3",
    "href": "slides/02_graphs.html#interventions-and-the-do-operator-3",
    "title": "(2) Graphical Causal Models",
    "section": "Interventions and the do-Operator",
    "text": "Interventions and the do-Operator\n\nCarrying out an intervention ourselves, in a randomized control trial, is not always feasible (too expensive, impractical, or unethical).\nHow can we then identify the effect of interventions purely from observational data?\n\nWe want to know \\(P(Y|do(T = t))\\) but all we have is data \\(P(Y,X,T)\\).\nAnd we know that \\(P(Y|do(T = t) \\neq P(Y|T))\\) (i.e. “correlation is not causation”).\nNo fancy machine learning algorithm will ever (?) solve this problem.\n\nOne way is to find a way to transform \\(P(Y|do(T = t))\\) into an expression that only contains observed, “do-free” quantities."
  },
  {
    "objectID": "slides/02_graphs.html#backdoor-adjustment-1",
    "href": "slides/02_graphs.html#backdoor-adjustment-1",
    "title": "(2) Graphical Causal Models",
    "section": "Backdoor Adjustment",
    "text": "Backdoor Adjustment\n\nThe backdoor criterion is a graphical condition that allows us to identify causal effects from observational data.\n\n\n\n\nDefinition 2.5: “Backdoor Criterion”\n\n\nA set of variables \\(W\\) satisfies the backdoor criterion relative to \\(T\\) and \\(Y\\) if the following are true:\n\n\\(W\\) blocks all backdoor paths between \\(T\\) and \\(Y\\) that contains an arrow into \\(T\\).\n\\(W\\) does not contain any descendants of \\(T\\).\n\n\n\n\n\nIf a set of variables \\(W\\) satisfies the backdoor criterion for \\(T\\) and \\(Y\\), then the causal effect is given by: \\(P(Y|\\text{do}(T = t)) = \\sum_{W} P(Y|T = t, W = w)P(W = w)\\).\n\ni.e. condition on the values of \\(W\\) and average over their joint distribution"
  },
  {
    "objectID": "slides/02_graphs.html#backdoor-adjustment-proof",
    "href": "slides/02_graphs.html#backdoor-adjustment-proof",
    "title": "(2) Graphical Causal Models",
    "section": "Backdoor Adjustment: Proof",
    "text": "Backdoor Adjustment: Proof\n\nConditioning on the variables \\(W\\) and marginalizing them out:\n\n\\(P(Y|\\text{do}(T = t)) = \\sum_{W} P(Y|\\text{do}(T = t), W = w)P(W| \\text{do}(T = t))\\)\n\nGet rid of the first “do” by using the definition of the do-operator - “all backdoor paths blocked”:\n\n\\(\\sum_{W} P(Y|\\text{do}(T = t), W = w)P(W| \\text{do}(T = t)) = \\sum_{W} P(Y|T = t, W = w)P(W| \\text{do}(T = t))\\)\n\nGet rid of the second “do” by using the definition of the do-operator - “no descendants of T in W”:\n\n\\(\\sum_{W} P(Y|T = t, W = w)P(W| \\text{do}(T = t)) = \\sum_{W} P(Y|T = t, W = w)P(W)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#backdoor-adjustment-example",
    "href": "slides/02_graphs.html#backdoor-adjustment-example",
    "title": "(2) Graphical Causal Models",
    "section": "Backdoor Adjustment: Example",
    "text": "Backdoor Adjustment: Example\n\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\ndag &lt;- dagify(\n  T ~ X1 + X2,\n  X6 ~ T,\n  X2 ~ X3,\n  X1 ~ X3 + X4,\n  X5 ~ X4,\n  Y ~ X1 + X5 + X6,\n  exposure = \"T\", outcome = \"Y\",\n  coords = list(\n    x = c(T = 0, X1 = 1, X2 = 0, X3 = 0, X4 = 2, X5 = 2, X6 = 1, Y = 2),\n    y = c(T = 0, X1 = 1, X2 = 1, X3 = 2, X4 = 2, X5 = 1, X6 = 0, Y = 0)\n  )\n)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y,\n             xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\") +\n  geom_dag_edges() +\n  geom_dag_point(shape = 1) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\n\nMinimum sufficient adjustment sets?\n\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\ndag &lt;- dagify(\n  T ~ X1 + X2,\n  X6 ~ T,\n  X2 ~ X3,\n  X1 ~ X3 + X4,\n  X5 ~ X4,\n  Y ~ X1 + X5 + X6,\n  exposure = \"T\", outcome = \"Y\",\n  coords = list(\n    x = c(T = 0, X1 = 1, X2 = 0, X3 = 0, X4 = 2, X5 = 2, X6 = 1, Y = 2),\n    y = c(T = 0, X1 = 1, X2 = 1, X3 = 2, X4 = 2, X5 = 1, X6 = 0, Y = 0)\n  )\n)\n\nadjustmentSets(dag)\n\n\n{ X1, X5 }\n{ X1, X4 }\n{ X1, X3 }\n{ X1, X2 }"
  },
  {
    "objectID": "slides/02_graphs.html#relation-to-the-potential-outcomes-framework",
    "href": "slides/02_graphs.html#relation-to-the-potential-outcomes-framework",
    "title": "(2) Graphical Causal Models",
    "section": "Relation to the Potential Outcomes Framework",
    "text": "Relation to the Potential Outcomes Framework\n\nATE in the PO framework:\n\n\\(\\tau = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mathbb{E_X}[\\mathbb{E}[Y_i|T_i=1, X_i] - \\mathbb{E}[Y_i|T_i=0, X_i]]\\)\n\ndo-notation \\(\\mathbb{E}(Y|do(T = t))\\) just another notation for the potential outcomes \\(\\mathbb{E}[Y(t)]\\).\n\nExpectations and discrete treatement vs. probability weighted averages and continuous/ multi-valued treatments.\n\nThe backdoor criterion is a graphical condition to identify valid adjustment sets for the potential outcomes framework.\n\nBut we had no way of knowing how to choose \\(W\\) such that it gives us conditional exchangeability.\nThe backdoor criterion is a graphical condition to choose a valid \\(W\\).\nIt is neither necessary nor suffcient to condition on all variables in the data and model.\nCan even be harmful to condition on a (collider) variable.\n\nOnce we have found an admissible adjustment set, we can estimate the causal effect by matching, inverse probability weighting, or linear regression (if you’re willing to assume linearity)."
  }
]