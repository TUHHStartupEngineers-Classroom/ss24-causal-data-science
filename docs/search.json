[
  {
    "objectID": "slides/01_intro.html#learning-goals",
    "href": "slides/01_intro.html#learning-goals",
    "title": "(1) Introduction to Causal Inference",
    "section": "Learning Goals",
    "text": "Learning Goals\n\n\nUnderstand the difference between “correlation” and “causation”\nUnderstand the shortcomings of current correlation-based approaches\nDevelop causal knowledge relevant for specific data-driven decisions\nFormalize intuition about causal relationships using a “language” of causality\nDerive causal hypotheses that can be tested with data\nDiscuss the conceptual ideas behind state-of-the-art causal data science tools and algorithms\nCarry out causal data analyses with state-of-the-art tools"
  },
  {
    "objectID": "slides/01_intro.html#map-of-causality",
    "href": "slides/01_intro.html#map-of-causality",
    "title": "(1) Introduction to Causal Inference",
    "section": "Map of Causality",
    "text": "Map of Causality\n\n\nSource: https://towardsdatascience.com (2023)."
  },
  {
    "objectID": "slides/01_intro.html#preliminary-schedule",
    "href": "slides/01_intro.html#preliminary-schedule",
    "title": "(1) Introduction to Causal Inference",
    "section": "Preliminary Schedule",
    "text": "Preliminary Schedule\n\n\n\nSession\nDate\nTopic\n\n\n\n\n1\nApril 15 & 16\nIntroduction to Causal Inference\n\n\n2\nApril 22 & 21\nGraphical Causal Models\n\n\n3\nApril 29 & 30\nRandomized Experiments\n\n\n4\nMay 6 & 7\nObserved Confounding\n\n\n5\nMay 13 & 14\nDouble Machine Learning\n\n\n-\nMay 20 & 21\nHoliday\n\n\n6\nMay 27 & 28\nEffect Heterogeneity\n\n\n7\nJune 3 & 4\nUnobserved Confounding & Instrumental Variables\n\n\n8\nJune 10 & 11\nDifference-in-Difference\n\n\n9\nJune 17 & 18\nSynthetic Control\n\n\n10\nJune 24 & 25\nRegression Discontinuity\n\n\n11\nJuly 1 & 2\nCausal Mediation\n\n\n12\nJuly 8 & 9\nFurther Topics in Causal Machine Learning"
  },
  {
    "objectID": "slides/01_intro.html#course-structure",
    "href": "slides/01_intro.html#course-structure",
    "title": "(1) Introduction to Causal Inference",
    "section": "Course Structure",
    "text": "Course Structure\n\nLecture - Causal Data Science: Monday, 11.30 - 13.00, Building D, Room D - 1.023\nLab - Business Analytics with Causal Data Science: Tuesday, 15.00 - 16.30, Building O, Room O - 0.007\n\n\n\nExamination: 10 challenges related to each topic documented in a lab journal\n\n\n\nContact: Oliver Mork (oliver.mork@tuhh.de)"
  },
  {
    "objectID": "slides/01_intro.html#course-literature",
    "href": "slides/01_intro.html#course-literature",
    "title": "(1) Introduction to Causal Inference",
    "section": "Course Literature",
    "text": "Course Literature\n\nPrimary:Secondary:\n\n\n\nDing, Peng (2023). A First Course in Causal Inference. arXiv preprint arXiv:2305.18793.\nFacure, Matheus (2023). Causal Inference in Python - Applying Causal Inference in the Tech Industry. O’Reilly Media.\nHuber, Martin (2023). Causal analysis: Impact evaluation and Causal Machine Learning with applications in R. MIT Press, 2023.\nNeal, Brady (2020). Introduction to causal inference from a Machine Learning Perspective. Course Lecture Notes (draft).\n\n\n\n\nAngrist, J. D., & Pischke, J. S. (2014). Mastering metrics: The path from cause to effect. Princeton university press.\nCunningham, Scott (2021). Causal Inference: The Mixtape, New Haven: Yale University Press.\nGertler, Paul J., et al. (2016). Impact evaluation in practice. World Bank Publications.\nHernán Miguel A., and Robins James M. (2020). Causal Inference: What If. Boca Raton: Chapman & Hall/CRC.\nHuntington-Klein, Nick (2021). The effect: An introduction to research design and causality. Chapman and Hall/CRC.\nImbens, G. W., & Rubin, D. B. (2015). Causal inference in statistics, social, and biomedical sciences. Cambridge University Press.\nMullainathan, Sendhil, and Jann Spiess. (2017). Machine Learning: An Applied Econometric Approach. Journal of Economic Perspectives, 31(2): 87–106.\nPearl, Judea, and Dana Mackenzie (2018). The Book of Why. Basic Books, New York, NY.\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell (2016). Causal Inference in Statistics: A Primer. John Wiley & Sons, Inc., New York, NY.\nPeters, Jonas, Dominik Janzing, and Bernhard Schölkopf (2017). Elements of causal inference: foundations and learning algorithms. The MIT Press."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation",
    "href": "slides/01_intro.html#causality-vs.-correlation",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\nCausality is central to human knowledge.\nTwo famous quotes from ancient Greeks:\n\n“I would rather discover one causal law than be King of Persia.” (Democritus)\n“We do not have knowledge of a thing until we grasped its cause.” (Aristotle) \n\nHowever:\n\nClassic statistics is about association rather than causation.\nMachine learning is about prediction rather than causation."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-1",
    "href": "slides/01_intro.html#causality-vs.-correlation-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\n“Correlation does not imply causation.”\n“You can not prove causality with statistics.” \nBut statistics is crucial for understanding causality:\n\nFormal language for causal inference.\nMethods to estimate causal effects."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-2",
    "href": "slides/01_intro.html#causality-vs.-correlation-2",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\n\nSource: https://hbr.org/2021/11/leaders-stop-confusing-correlation-with-causation."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-3",
    "href": "slides/01_intro.html#causality-vs.-correlation-3",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\n\nSource: https://www.tylervigen.com/spurious- correlations."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-4",
    "href": "slides/01_intro.html#causality-vs.-correlation-4",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\n\n\n\n\n\nSource: Peters, Jonas. 2015. Causality: Lecture Notes, ETH Zurich."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-5",
    "href": "slides/01_intro.html#causality-vs.-correlation-5",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\nCorrelation, or better association, is not (entirely) causation, if there is confounding association due to a common cause, i.e. a confounder.\nE.g. drinking the night before is a common cause of sleeping with shoes on and of waking up with a headache:\n\n \n\nSource: Neal, Brady (2020). Introduction to causal inference from a Machine Learning Perspective. Course Lecture Notes (draft)."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-6",
    "href": "slides/01_intro.html#causality-vs.-correlation-6",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\nCorrelation, or better association, is not (entirely) causation, if there is confounding association due to a common cause, i.e. a confounder.\nE.g. Consumers’ purchase intent is a common cause of the amount spent on search engine marketing (SEM) (esp. for branded vs. non-branded ads) and sales (especially for frequent consumers):\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\n\ncoord_dag &lt;- list(\n  x = c(SEM = 0, Intent = 1, Sales = 2),\n  y = c(SEM = 0, Intent = 1, Sales = 0)\n)\n\ndag &lt;- ggdag::dagify(SEM ~ Intent,\n                     Sales ~ SEM,\n                     Sales ~ Intent,\n                     coords = coord_dag)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(colour = \"grey\") +\n  geom_dag_edges() +\n  geom_dag_text(colour = \"black\", size = 5) +\n  theme_dag(legend.position = \"none\")\n\n\n\n\n(Source: Blake et al. (2015). Consumer heterogeneity and paid search effectiveness: A large‐scale field experiment. Econometrica, 83(1), 155-174.)"
  },
  {
    "objectID": "slides/01_intro.html#motivating-example-gender-pay-gap-1",
    "href": "slides/01_intro.html#motivating-example-gender-pay-gap-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Motivating Example: Gender Pay Gap (1)",
    "text": "Motivating Example: Gender Pay Gap (1)\n- Reported by The New York Times in March 2019:\n      “When Google conducted a study recently to determine whether\n      the company was underpaying women and minority groups, it found\n      that men were paid less money than women for doing similar work.”\n\n(Source: https://www.nytimes.com/2019/03/04/technology/google-gender-pay-gap.html)\n\n\nThe study led Google to increase the pay of its male employees to fight this blatant discrimination of men.\nWhat’s going on here? Wasn’t Google just recently accused of discriminating against women, not men?\n\n      “Department of Labor claims that Google systematically underpays its\n      female employees.”\n\n(Source: https://www.theverge.com/2017/4/8/15229688/department-of-labor-google-gender-pay-gap)"
  },
  {
    "objectID": "slides/01_intro.html#motivating-example-gender-pay-gap-2",
    "href": "slides/01_intro.html#motivating-example-gender-pay-gap-2",
    "title": "(1) Introduction to Causal Inference",
    "section": "Motivating Example: Gender Pay Gap (2)",
    "text": "Motivating Example: Gender Pay Gap (2)\n\nSuppose we collected data on wages payed to 100 women and 100 men in company X.\nWe observe the following average monthly salaries for women and men in management and non-management positions (case numbers in parentheses):\n\n\n\n\n\nWomen\nMen\n\n\n\n\n\nNon-management:\n$3,163.30 (87)\n$3,015.18 (59)\n\n\n\nManagement:\n$5,592.44 (13)\n$5,319.82 (41)\n\n\n\n\n\n\nOur goal is to estimate the magnitude of the gender pay gap in company X. How should we tackle this problem?"
  },
  {
    "objectID": "slides/01_intro.html#motivating-example-gender-pay-gap-3",
    "href": "slides/01_intro.html#motivating-example-gender-pay-gap-3",
    "title": "(1) Introduction to Causal Inference",
    "section": "Motivating Example: Gender Pay Gap (3)",
    "text": "Motivating Example: Gender Pay Gap (3)\n\nOn average, women earn less in this example: \\[\n   \\left(\\frac{87}{100} \\cdot \\$3163.30\\right) + \\left(\\frac{13}{100} \\cdot \\$5592.44\\right) -\n   \\left(\\frac{59}{100} \\cdot \\$3015.18\\right) + \\left(\\frac{41}{100} \\cdot \\$5319.82\\right) \\\\\n   \\approx -\\$481\n\\]\nBut in each subcategory women actually have higher salaries:\n\n  - Non- Management: \\(\\$3163.30 - \\$3015.18 = \\$148.12\\)\n  - Management: \\(\\$5592.44 - \\$5319.82 = \\$272.62\\)\n\nConditioning on job position gives the adjusted gender pay gap:\n\n\\[\n   \\left(\\frac{87 + 59}{200} \\cdot \\$148.12\\right) + \\left(\\frac{13 + 41}{200} \\cdot \\$272.62\\right) \\approx \\$181.74\n\\]\n\nWhich estimate gives us a more accurate picture of the gender pay gap?"
  },
  {
    "objectID": "slides/01_intro.html#motivating-example-gender-pay-gap-4",
    "href": "slides/01_intro.html#motivating-example-gender-pay-gap-4",
    "title": "(1) Introduction to Causal Inference",
    "section": "Motivating Example: Gender Pay Gap (4)",
    "text": "Motivating Example: Gender Pay Gap (4)\n\n\nShow code\ndata &lt;- data.frame(\n  Salary = c(5319.82, 3015.18, 5592.44, 3163.30, 3960.08, 3479.09),\n  Position = c(\"Management\", \"Non-Management\", \"Management\", \"Non-Management\", \"All Positions\", \"All Positions\"),\n  Gender = c(\"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Female\")\n)\n\nlibrary(ggplot2)\n\ndata |&gt; \n  ggplot(aes(x=Gender, y=Salary, group=Position, colour=Position)) +\n  geom_line() + geom_point() + \n  theme_bw()"
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-1",
    "href": "slides/01_intro.html#simpsons-paradox-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (1)",
    "text": "Simpson’s Paradox (1)\n\nThe phenomenon that a statistical association, which holds in a population, can be reversed in every subpopulation is named after the British statistician Edward Simpson.\nSimpson’s paradox well-known, for example, in epidemiology and labor economics.\nIn the gender pay gap example, the unadjusted gender pay (- $481) gap gives the right answer.\n\n\n\nBut what about this example?\n\n\n\n\n\nHealthy Lifestyle\nUnhealthy Lifestyle\n\n\n\n\n\nNon-management:\n$3,163.30 (87)\n$3,015.18 (59)\n\n\n\nManagement:\n$5,592.44 (13)\n$5,319.82 (41)"
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-2",
    "href": "slides/01_intro.html#simpsons-paradox-2",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (2)",
    "text": "Simpson’s Paradox (2)\n\n\nHere, we would correctly infer that people with a healthy lifestyle earn more on average ($181.74)."
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-3",
    "href": "slides/01_intro.html#simpsons-paradox-3",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (3)",
    "text": "Simpson’s Paradox (3)\n\nWhat is the difference between the two examples?\n\n\n\n\n\nShow code\nlibrary(ggdag)\n\ncoord_dag &lt;- list(\n  x = c(Gender = 0, Management = 1, Salary = 2),\n  y = c(Gender = 0, Management = 1, Salary = 0)\n)\n\ndag &lt;- ggdag::dagify(Management ~ Gender,\n                     Salary ~ Gender,\n                     Salary ~ Management,\n                     coords = coord_dag)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(colour = \"grey\") +\n  geom_dag_edges() +\n  geom_dag_text(colour = \"black\", size = 5) +\n  theme_dag(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nManagement as “mediator”\n\n\n\n\nShow code\nlibrary(ggdag)\n\ncoord_dag &lt;- list(\n  x = c(Lifestyle = 0, Management = 1, Salary = 2),\n  y = c(Lifestyle = 0, Management = 1, Salary = 0)\n)\n\ndag &lt;- ggdag::dagify(Lifestyle ~ Management,\n                     Salary ~ Lifestyle,\n                     Salary ~ Management,\n                     coords = coord_dag)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(colour = \"grey\") +\n  geom_dag_edges() +\n  geom_dag_text(colour = \"black\", size = 5) +\n  theme_dag(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nManagement as “confounder”"
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-4",
    "href": "slides/01_intro.html#simpsons-paradox-4",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (4)",
    "text": "Simpson’s Paradox (4)\n\nStatistics alone doesn’t help us to answer this question.\nNote that the joint distribution of salaries is the same in both cases.\nBoth problems are thus identical from a statistical point of view.\nInstead, we need to make causal assumptions in order to come to a conclusion here:\n\nGender affects both a person’s salary level and job position.\nWhereas lifestyle affects salaries, but is itself affected by a person’s job position.\n\nAfter the course you will know how to incorporate this kind of causal knowledge in your analysis in order to solve all sorts of practical problems of causal inference."
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-5",
    "href": "slides/01_intro.html#simpsons-paradox-5",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (5)",
    "text": "Simpson’s Paradox (5)\n\n\nSource: https://rpubs.com/lakenp/simpsonsparadox."
  },
  {
    "objectID": "slides/01_intro.html#experimentalists-view-of-causal-inference",
    "href": "slides/01_intro.html#experimentalists-view-of-causal-inference",
    "title": "(1) Introduction to Causal Inference",
    "section": "Experimentalists’ View of Causal Inference",
    "text": "Experimentalists’ View of Causal Inference\n\n“No causation without manipulation.” (Rubin, 1975; Holland, 1986)\n(Thought) Experiments with manipulation; also called intervention or treatment.\nTreatments can be binary, continuous, or multi-valued.\nExamples:\n\ntake a drug vs. don’t take a drug\nparticipate in a training program A vs B vs. don’t participate\namount of money spent on advertising\nchange race of job applicants? Resumes with African-American- or White-sounding names (Bertrand and Mullainathan, 2004).\nlevel of neuroticism?\n\nThe potential outcomes framework (Neyman, 1923; Rubin, 1974) is a way to formalize this idea."
  },
  {
    "objectID": "slides/01_intro.html#formal-notation-of-potential-outcomes",
    "href": "slides/01_intro.html#formal-notation-of-potential-outcomes",
    "title": "(1) Introduction to Causal Inference",
    "section": "Formal Notation of Potential Outcomes",
    "text": "Formal Notation of Potential Outcomes\n\n\\(n\\) experimental units indexed by \\(i = 1, . . . , n\\)\n\\(Y\\) is the outcome of interest.\n\\(T_i\\) is the (random) treatment variable for unit \\(i\\).\n\nAssume it can take two levels: \\(t_i = 1\\) for treatment and \\(t_i = 0\\) for control.\n\n\\(Y_i(1)\\) is the potential outcome for unit \\(i\\) if unit \\(i\\) receives treatment.\n\\(Y_i(0)\\) is the potential outcome for unit \\(i\\) if unit \\(i\\) does not receive treatment. \nThe Individual Treatment Effect (ITE) for unit \\(i\\) is defined as:\n\n\\(\\tau_i = Y_i(1) - Y_i(0) \\quad \\forall \\quad i = 1, . . . , n\\)."
  },
  {
    "objectID": "slides/01_intro.html#assumptions-in-the-po-framework-1",
    "href": "slides/01_intro.html#assumptions-in-the-po-framework-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Assumptions in the PO Framework (1)",
    "text": "Assumptions in the PO Framework (1)\nFor the potential outcomes and the ITE to be precisely defined, we need to make an initial set of assumptions:\n\n\n\nAssumption 1: “No Interference”\n\n\nUnit i’s potential outcomes do not depend on other units’ treatments.\n\\(Y_i(t_1,...,t_{i-1},t_i,t_{i+1},...t_n) = Y_i(t_i)\\)\n\n\n\n\n\n\nAssumption 2: “Consistency.”\n\n\nThere are no other versions of the treatment. Equivalently, we require that the treatment levels be well-defined, or have no ambiguity at least for the outcome of interest. If the treatment is \\(T\\), then the observed outcome \\(Y\\) is the potential outcome under treatment \\(T\\).\nFormally, \\(T = t  =&gt; Y = Y(t)\\) or equivalently \\(Y = Y(T)\\)\n\n\n\n\n\n\nAssumption 3: “Stable Unit Treatment Value Assumption (SUTVA).”\n\n\nBoth Assumptions 1 and 2 hold: \\(Y_i = Y(T_i)\\)"
  },
  {
    "objectID": "slides/01_intro.html#fundamental-problem-of-causal-inference",
    "href": "slides/01_intro.html#fundamental-problem-of-causal-inference",
    "title": "(1) Introduction to Causal Inference",
    "section": "Fundamental Problem of Causal Inference",
    "text": "Fundamental Problem of Causal Inference\n\nTypically, only one of those outcomes is actually observed for unit \\(i\\):\n\n\\(Y_i = T_iY_i(1) + (1 − T_i)Y_i(0)\\).\n\nThe other one remains unobserved or counterfactual.\nThis makes calculating the ITE \\(\\tau_i\\) impossible.\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i\\)\n\\(Y_i(1)\\)\n\\(Y_i(0)\\)\n\\(Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n0\n0\n?\n0\n?\n\n\n2\n1\n1\n1\n?\n?\n\n\n3\n1\n0\n0\n?\n?\n\n\n4\n0\n0\n?\n0\n?\n\n\n5\n0\n1\n?\n1\n?\n\n\n6\n1\n1\n1\n?\n?"
  },
  {
    "objectID": "slides/01_intro.html#getting-around-the-fundamental-problem",
    "href": "slides/01_intro.html#getting-around-the-fundamental-problem",
    "title": "(1) Introduction to Causal Inference",
    "section": "Getting Around the Fundamental Problem",
    "text": "Getting Around the Fundamental Problem\n\nDoes the Average Treatment Effect (ATE) help?\nDefined in terms of expectations:\n\n\\(\\tau = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\\)\n\nDefined in terms of averages:\n\n\\(\\tau = \\frac{1}{n} \\sum_{i=1}^{n} [\\tau_i] = \\frac{1}{n} \\sum_{i=1}^{n} [Y_i(1) - Y_i(0)] = \\frac{1}{n} \\sum_{i=1}^{n} [Y_i(1)] - \\frac{1}{n} \\sum_{i=1}^{n} [Y_i(0)]\\)\n\n\n\n\nStill not computable, because we don’t know the counterfactuals."
  },
  {
    "objectID": "slides/01_intro.html#assumptions-in-the-po-framework-2",
    "href": "slides/01_intro.html#assumptions-in-the-po-framework-2",
    "title": "(1) Introduction to Causal Inference",
    "section": "Assumptions in the PO Framework (2)",
    "text": "Assumptions in the PO Framework (2)\n\nWe need to make further assumptions to make progress.\n\n\n\n\nAssumption 4: “Ignorability / Exchangeability”.\n\n\nIgnorability (of how people selected their treatment) is equivalent to random assignment into treatments.\nExchangeability means that observations in treatment and control group could be swapped, and one would still obtain the same outcomes. This implies that observations in groups are the same in all relevant aspects other than the treatment.\nFormally, \\((Y(1), Y(0)) \\perp\\!\\!\\!\\perp T\\)."
  },
  {
    "objectID": "slides/01_intro.html#ate-identification---intuition",
    "href": "slides/01_intro.html#ate-identification---intuition",
    "title": "(1) Introduction to Causal Inference",
    "section": "ATE Identification - Intuition",
    "text": "ATE Identification - Intuition\n\nUsing assumptions 4 and 2, we obtain the following simplification:\n\n\\(\\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mathbb{E}[Y_i(1)|T_i=1] - \\mathbb{E}[Y_i(0)|T_i=0] = \\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]\\)\n\nThis implies the ATE to be obtainable as associational difference:\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i\\)\n\\(Y_i(1)\\)\n\\(Y_i(0)\\)\n\n\n\n\n1\n0\n0\n?\n0\n\n\n4\n0\n0\n?\n0\n\n\n5\n0\n1\n?\n1\n\n\n2\n1\n1\n1\n?\n\n\n3\n1\n0\n0\n?\n\n\n6\n1\n1\n1\n?\n\n\n\n\nWe can then estimate \\(\\mathbb{E}[Y_i|T_i=1] = 0.66\\) and \\(\\mathbb{E}[Y_i|T_i=0] = 0.33\\) and use these values to replace the missing counterfactuals.\nATE is now identifiable in the sense that it can be computed from a purely statistical quantity."
  },
  {
    "objectID": "slides/01_intro.html#assumptions-in-the-po-framework-3",
    "href": "slides/01_intro.html#assumptions-in-the-po-framework-3",
    "title": "(1) Introduction to Causal Inference",
    "section": "Assumptions in the PO Framework (3)",
    "text": "Assumptions in the PO Framework (3)\n\nLet’s make exchangeability more realistic, i.e. conditional on covariates, so that subgroups will be exchangable.\n\n\n\n\nAssumption 5: “Conditional Exchangeability / Unconfoundedness”.\n\n\nFormally, \\((Y(1), Y(0)) \\perp\\!\\!\\!\\perp T \\, | \\, X\\)."
  },
  {
    "objectID": "slides/01_intro.html#assumptions-in-the-po-framework-4",
    "href": "slides/01_intro.html#assumptions-in-the-po-framework-4",
    "title": "(1) Introduction to Causal Inference",
    "section": "Assumptions in the PO Framework (4)",
    "text": "Assumptions in the PO Framework (4)\n\nConditioning on many covariates can also be detrimental, because we might end up conditioning on a zero probability event for some subgroups / values of X (division by zero)\n\n\n\n\nAssumption 6: “Positivity / Overlap / Common Support”.\n\n\nFor all values of covariates \\(x\\) present in the population of interest (i.e. \\(x\\) such that \\(P(X=x) &gt; 0\\)), we have \\(0 &lt; P(T=1|X=x) &lt; 1\\).\n\n\n\n\nThere is a trade-off between positivity and unconfoundedness.\nSome models might be forced to extrapolate to regions without sufficient support by using their parametric assumptions."
  },
  {
    "objectID": "slides/01_intro.html#derivation-of-the-average-treatment-effect-ate",
    "href": "slides/01_intro.html#derivation-of-the-average-treatment-effect-ate",
    "title": "(1) Introduction to Causal Inference",
    "section": "Derivation of the Average Treatment Effect (ATE)",
    "text": "Derivation of the Average Treatment Effect (ATE)\n\nWith the assumptions of conditional unconfoundedness, positivity, consistency, and no interference, we can identify the ATE as:\n\n\n\n\nTheorem 1: “Identification of the ATE”:\n\n\n\\(\\tau = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mathbb{E_X}[\\mathbb{E}[Y_i|T_i=1, X_i] - \\mathbb{E}[Y_i|T_i=0, X_i]]\\)"
  },
  {
    "objectID": "slides/01_intro.html#derivation-of-the-average-treatment-effect-ate-1",
    "href": "slides/01_intro.html#derivation-of-the-average-treatment-effect-ate-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Derivation of the Average Treatment Effect (ATE)",
    "text": "Derivation of the Average Treatment Effect (ATE)\n\nProof:\n\n\\[\\begin{align*}\n\\tau = \\mathbb{E}[\\tau_i] &= \\mathbb{E}[Y_i(1) - Y_i(0)] \\\\\n&= \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] \\\\\n& \\text{(linearity of expectation)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i(1) \\mid X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i(0) \\mid X_i]] \\\\\n&\\text{(law of iterated expectations)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i(1) \\mid T_i = 1, X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i(0) \\mid T_i = 0, X_i]] \\\\\n&\\text{(unconfoundedness and positivity)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i \\mid T_i = 1, X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i \\mid T_i = 0, X_i]] \\\\\n&\\text{(consistency)}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/01_intro.html#other-causal-quantities",
    "href": "slides/01_intro.html#other-causal-quantities",
    "title": "(1) Introduction to Causal Inference",
    "section": "Other Causal Quantities",
    "text": "Other Causal Quantities\n\nThe ATE is just one of many causal quantities that can be estimated using the PO framework.\n\n\n\n\n“Average Treatment Effect on the Treated” (ATT):\n\n\n\\(ATT = \\mathbb{E}[Y_i(1)|T_i=1] - \\mathbb{E}[Y_i(0)|T_i=1]\\)\n\n\n\n\n\n\n“Conditional Average Treatment Effect” (CATE):\n\n\n\\(CATE = \\mathbb{E}[Y_i(1)|X_i=x] - \\mathbb{E}[Y_i(0)|X_i=x]\\)"
  }
]