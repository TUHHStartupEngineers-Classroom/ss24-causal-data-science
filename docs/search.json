[
  {
    "objectID": "slides/07_unob_conf.html#motivation",
    "href": "slides/07_unob_conf.html#motivation",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Motivation",
    "text": "Motivation\n\nConditional Independence / Unconfoundedness: assumption is not testable.\n“The Law of Decreasing Credibility: The credibility of inference decreases with the strength of the assumptions maintained.” (Manski, 2003)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\tau_{\\text{ATE}} &= \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] \\\\\n&= \\mathbb{E}_{\\mathbf{X, U}}[\\mathbb{E}[Y_i|T_i=1, \\mathbf{X_i, U_i}] - \\mathbb{E}[Y_i|T_i=0, \\mathbf{X_i, U_i}]] \\\\\n& \\color{#FF7E15}{\\stackrel{?}{\\approx}} \\mathbb{E}_{\\mathbf{X}}[\\mathbb{E}[Y_i|T_i=1, \\mathbf{X_i}] - \\mathbb{E}[Y_i|T_i=0, \\mathbf{X_i}]]\n\\end{align*}\n\\]\n\n“Questionable” equality is required to hold for a point estimate of the ATE.\nPartial Identification is the method to estimate the ATE under weaker assumptions yielding a set estimate - an interval with upper and lower bounds.\nTrade-off between assumptions and width of the interval."
  },
  {
    "objectID": "slides/07_unob_conf.html#no-assumption-worst-case-bounds",
    "href": "slides/07_unob_conf.html#no-assumption-worst-case-bounds",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "No Assumption (Worst-case) Bounds",
    "text": "No Assumption (Worst-case) Bounds\n\nAssume potential outcomes are bounded: \\(y^{LB} \\leq Y_i(t) \\leq y^{UB}\\), \\(\\forall t\\).\n\nBounds of ITE: \\(y^{LB} - y^{UB} \\leq Y_i(1) - Y_i(0) \\leq y^{UB} - y^{LB}\\)\nBounds of ATE: \\(y^{LB} - y^{UB} \\leq \\mathbb{E}[Y_i(1) - Y_i(0)] \\leq y^{UB} - y^{LB}\\)\nInterval length: \\(2(y^{UB} - y^{LB})\\)\n\nBut the ATE interval length can actually be halved. How?\n\n\n\nLet’s use the observational-counterfactual decomposition of the ATE: \\[\n\\begin{align*}\n\\mathbb{E}[Y_i(1) - Y_i(0)] &= \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] \\\\\n&= P(T_i=1)\\color{#00C1D4}{\\mathbb{E}[Y_i(1)|T_i=1]} + P(T_1=0)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=0]} - P(T_i=1)\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=1]} - P(T_i=0)\\color{#00C1D4}{\\mathbb{E}[Y_i(0)|T_i=0]}\\\\\n&= P(T_i=1)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + P(T_i=0)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=0]} - P(T_i=1)\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=1]} - P(T_i=0)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&:= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=0]} - p\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=1]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n\\end{align*}\n\\]\n\n\n\n\nUpper bound: \\(\\mathbb{E}[Y_i(1) - Y_i(0)] \\leq  p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#00C1D4}{y^{UB}} - p\\color{#00C1D4}{y^{LB}} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\)\nLower bound: \\(\\mathbb{E}[Y_i(1) - Y_i(0)] \\geq  p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#00C1D4}{y^{LB}} - p\\color{#00C1D4}{y^{UB}} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\)\nInterval length: \\((1-p)y^{UB} - py^{LB} - (1-p)y^{LB} + py^{UB} = y^{UB} - y^{LB}\\)\nUnfortunately, the interval always contains 0. We need more assumptions!"
  },
  {
    "objectID": "slides/07_unob_conf.html#monotone-treatment-response-mtr-bounds",
    "href": "slides/07_unob_conf.html#monotone-treatment-response-mtr-bounds",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Monotone Treatment Response (MTR) Bounds",
    "text": "Monotone Treatment Response (MTR) Bounds\n\nAssume that the treatment has a non-negative monotone effect on the outcome: \\(Y_i(1) \\geq Y_i(0)\\), \\(\\forall i\\).\n\n(Works also with a non-positive monotone effect).\nLower bound of ITE: \\(Y_i(1) - Y_i(0) \\geq  0\\).\nLower bound of ATE: \\(\\mathbb{E}[Y_i(1) - Y_i(0)] \\geq 0\\).\nWhy?\n\n\n\n\nFirst use the assumption to derive the following two implications:\n\n\\(\\mathbb{E}[Y_i(1)|T_i=0] \\geq \\mathbb{E}[Y_i(0)|T_i=0] = \\mathbb{E}[Y_i|T_i=0]\\).\n\\(-\\mathbb{E}[Y_i(0)|T_i=1] \\geq -\\mathbb{E}[Y_i(1)|T_i=1] = -\\mathbb{E}[Y_i|T_i=1]\\).\n\n\n\n\n\nUse the two implications to replace the counterfactuals in the observational-counterfactual decomposition to derive a lower bound of the ATE: \\[\n\\begin{align*}\n\\mathbb{E}[Y_i(1) - Y_i(0)] &= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=0]} - p\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=1]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n& \\geq p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#FF7E15}{\\mathbb{E}[Y_i|T_i=0]} - p\\color{#FF7E15}{\\mathbb{E}[Y_i|T_i=1]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]} \\\\\n&= 0\n\\end{align*}\n\\]\n\n\n\n\nCan be combined with no-assumption upper bound to get a tighter interval, but it still always contains 0."
  },
  {
    "objectID": "slides/07_unob_conf.html#monotone-treatment-selection-mts-bounds",
    "href": "slides/07_unob_conf.html#monotone-treatment-selection-mts-bounds",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Monotone Treatment Selection (MTS) Bounds",
    "text": "Monotone Treatment Selection (MTS) Bounds\n\nAssume positive self-selection: those who generally have better outcomes self-select into treatment:\n\n\\(\\mathbb{E}[Y_i(1)|T_i=1] \\geq \\mathbb{E}[Y_i(1)|T_i=0]\\).\n\\(\\mathbb{E}[Y_i(0)|T_i=1] \\geq \\mathbb{E}[Y_i(0)|T_i=0]\\).\nUpper bound of ATE is the associational difference: \\(\\mathbb{E}[Y_i(1) - Y_i(0)] \\leq \\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]\\).\nWhy?\n\n\n\n\nLet’s use again the observational-counterfactual decomposition of the ATE and replace: \\[\n\\begin{align*}\n\\mathbb{E}[Y_i(1) - Y_i(0)] &= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=0]} - p\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=1]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&\\leq p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=1]} - p\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=0]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} - p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&= \\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} - \\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n\\end{align*}\n\\]\n\n\n\n\nCan be combined with MTR lower bound to get a tighter interval, but it still always contains 0."
  },
  {
    "objectID": "slides/07_unob_conf.html#optimal-treatment-selection-ots-bounds-1",
    "href": "slides/07_unob_conf.html#optimal-treatment-selection-ots-bounds-1",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Optimal Treatment Selection (OTS) Bounds 1",
    "text": "Optimal Treatment Selection (OTS) Bounds 1\n\nAssume individuals always receive the treatment that is best for them:\n\n\\(T_i = 0 \\implies Y_i(0) &gt; Y_i(1) \\quad\\) and \\(\\quad T_i = 1 \\implies Y_i(1) \\geq Y_i(0)\\).\n\n\n\n\nFrom the assumption, we know:\n\n\\(\\mathbb{E}[Y_i(1)|T_i=0] \\leq \\mathbb{E}[Y_i(0)|T_i=0] = \\mathbb{E}[Y_i|T_i=0]  \\quad\\) and \\(\\quad \\mathbb{E}[Y_i(0)|T_i=1] \\leq \\mathbb{E}[Y_i(1)|T_i=1] = \\mathbb{E}[Y_i|T_i=1]\\).\n\n\n\n\n\nTherefore, we can derive an upper bound for the ATE (together with no-assumption lower bound): \\[\n\\begin{align*}\n\\mathbb{E}[Y_i(1) - Y_i(0)] &= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=0]} - p\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=1]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&\\leq p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]} - p\\color{#00C1D4}{y^{LB}} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} - p\\color{#00C1D4}{y^{LB}}\\\\\n\\end{align*}\n\\]\n\n\n\n\nAnd a lower bound for the ATE (together with no-assumption lower bound): \\[\n\\begin{align*}\n\\mathbb{E}[Y_i(1) - Y_i(0)] &= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=0]} - p\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=1]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&\\geq p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#00C1D4}{y^{LB}} - p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&= (1-p)\\color{#00C1D4}{y^{LB}} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n\\end{align*}\n\\]\n\n\n\n\nInterval still always includes 0 and has length: \\(p\\mathbb{E}[Y_i|T_i=1] + (1 - p)\\mathbb{E}[Y_i|T_i=0]  - y^{LB}\\)."
  },
  {
    "objectID": "slides/07_unob_conf.html#optimal-treatment-selection-ots-bounds-2",
    "href": "slides/07_unob_conf.html#optimal-treatment-selection-ots-bounds-2",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Optimal Treatment Selection (OTS) Bounds 2",
    "text": "Optimal Treatment Selection (OTS) Bounds 2\n\nAssume individuals always receive the treatment that is best for them, but add counterpositive:\n\n\\(T_i = 0 \\implies Y_i(0) &gt; Y_i(1) \\quad\\) Counterpositive: \\(T_i = 1 \\impliedby Y_i(0) \\leq Y_i(1)\\).\n\\(T_i = 1 \\implies Y_i(1) \\geq Y_i(0) \\quad\\) Counterpositive: \\(T_i = 0 \\impliedby Y_i(1) &lt; Y_i(0)\\).\n\n\n\n\nFrom the above, we can derive two implications:\n\n\\(\\mathbb{E}[Y_i(1)|T_i=0] = \\mathbb{E}[Y_i(1)|Y_i(0) &gt; Y_i(1)] \\color{#00C1D4}{\\leq} \\mathbb{E}[Y_i(1)|Y_i(0) \\leq Y_i(1)] = \\mathbb{E}[Y_i(1)|T_i=1] = \\mathbb{E}[Y_i|T_i=1]\\)\n\\(\\mathbb{E}[Y_i(0)|T_i=1] = \\mathbb{E}[Y_i(0)|Y_i(1) \\geq Y_i(0)] \\color{#00C1D4}{&lt;} \\mathbb{E}[Y_i(0)|Y_i(1) &lt; Y_i(0)] = \\mathbb{E}[Y_i(0)|T_i=0] = \\mathbb{E}[Y_i|T_i=0]\\)\n\n\n\n\n\nTherefore, we can derive an upper and lower bound for the ATE:\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_i(1) - Y_i(0)] &= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=0]} - p\\color{#FF7E15}{\\mathbb{E}[Y_i(0)|T_i=1]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&\\leq p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} - p\\color{#00C1D4}{y^{LB}} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&= \\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} - p\\color{#00C1D4}{y^{LB}} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n\\end{align*}\n\\] \\[\n\\begin{align*}\n\\mathbb{E}[Y_i(1) - Y_i(0)] &\\geq p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#00C1D4}{y^{LB}} - p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]} - (1-p)\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n&= p\\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=1]} + (1-p)\\color{#00C1D4}{y^{LB}} - \\color{#00C1D4}{\\mathbb{E}[Y_i|T_i=0]}\\\\\n\\end{align*}\n\\]\n\n\n\nInterval can, but doesn’t have to include 0, finally. Length: \\((1-p)\\mathbb{E}[Y_i|T_i=1] + p\\mathbb{E}[Y_i|T_i=0]  - y^{LB}\\)."
  },
  {
    "objectID": "slides/07_unob_conf.html#partial-identification-and-bounds-example",
    "href": "slides/07_unob_conf.html#partial-identification-and-bounds-example",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Partial Identification and Bounds: Example",
    "text": "Partial Identification and Bounds: Example\n\nAssess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.\n\n\n\n\nlibrary(hdm) # for the data\nlibrary(drgee) # for doubly robust estimator\ndata(pension) # Get data\nY = pension$net_tfa # Outcome\nT = pension$p401 # Treatment\nX = cbind(pension$age,pension$db,pension$educ,pension$fsize,pension$hown,\n          pension$inc,pension$male,pension$marr,pension$pira,pension$twoearn) # covariates \ndr = drgee(oformula = formula(Y ~ X), eformula = formula(T ~ X), elink=\"logit\") # DR reg\nATE &lt;- as.numeric(dr$coefficients) # ATE           \np = mean(T) # Propensity score\nymin = as.numeric(quantile(Y, probs = 0.05)) # outcome lower bound\nymax = as.numeric(quantile(Y, probs = 0.95)) # outcome upper bound\nY1 = mean(Y[T == 1]) # outcome mean for treated\nY0 = mean(Y[T == 0]) # outcome mean for untreated\n\n# No assumption (worst case) bounds\nUB = p*Y1 + (1-p)*ymax-p*ymin-(1-p)*Y0\nLB = p*Y1 + (1-p)*ymin-p*ymax-(1-p)*Y0\nL = UB - LB\ncat(sprintf(\"LowerBound (worst) = %d, ATE = %d, UpperBound (worst) = %d, IntervalLength = %d\", round(LB), round(ATE), round(UB), round(L)))\n\n# Monotone Treatment Response (MTR) Bounds\nUB = p*Y1 + (1-p)*ymax-p*ymin-(1-p)*Y0\nLB = 0\nL = UB - LB\ncat(sprintf(\"LowerBound (MTR) = %d, ATE = %d, UpperBound (worst) = %d, IntervalLength = %d\", round(LB), round(ATE), round(UB), round(L)))\n\n\n\n# Monotone Treatment Selection (MTS) Bounds\nUB = Y1 - Y0\nL = UB - LB\ncat(sprintf(\"LowerBound (MTR) = %d, ATE = %d, UpperBound (MTS) = %d, IntervalLength = %d\", round(LB), round(ATE), round(UB), round(L)))\n\n# Optimal Treatment Selection 1 (OTS 1) Bounds\nUB = p*Y1 - p*ymin\nLB = (1-p)*ymin - (1-p)*Y0\nL = UB - LB\ncat(sprintf(\"LowerBound (OTS 1) = %d, ATE = %d, UpperBound (OTS 1) = %d, IntervalLength = %d\", round(LB), round(ATE), round(UB), round(L)))\n\n# Optimal Treatment Selection 2 (OTS 2) Bounds\nUB = Y1 - p*ymin - (1-p)*Y0\nLB = p*Y1 + (1-p)*ymin - Y0\nL = UB - LB\ncat(sprintf(\"LowerBound (OTS 2) = %d, ATE = %d, UpperBound (OTS 2) = %d, IntervalLength = %d\", round(LB), round(ATE), round(UB), round(L)))\n\n# Mix OTS1 (Upper) and OTS 2 (Lower) Bounds\nUB = p*Y1 - p*ymin\nLB = p*Y1 + (1-p)*ymin - Y0\nL = UB - LB\ncat(sprintf(\"LowerBound (OTS 2) = %d, ATE = %d, UpperBound (OTS 1) = %d, IntervalLength = %d\", round(LB), round(ATE), round(UB), round(L)))\n\n\n\nLowerBound (worst) = -28746, ATE = 11333, UpperBound (worst) = 72253, IntervalLength = 100999\n\n\nLowerBound (MTR) = 0, ATE = 11333, UpperBound (worst) = 72253, IntervalLength = 72253\n\n\nLowerBound (MTR) = 0, ATE = 11333, UpperBound (MTS) = 27372, IntervalLength = 27372\n\n\nLowerBound (OTS 1) = -14687, ATE = 11333, UpperBound (OTS 1) = 12365, IntervalLength = 27052\n\n\nLowerBound (OTS 2) = -7526, ATE = 11333, UpperBound (OTS 2) = 32575, IntervalLength = 40101\n\n\nLowerBound (OTS 2) = -7526, ATE = 11333, UpperBound (OTS 1) = 12365, IntervalLength = 19890"
  },
  {
    "objectID": "slides/07_unob_conf.html#linear-model-single-confounder",
    "href": "slides/07_unob_conf.html#linear-model-single-confounder",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Linear Model & Single Confounder",
    "text": "Linear Model & Single Confounder\n\n\\(Y_i\\) as linear function of \\(T_i\\), observed confounding variables \\(\\mathbf{X_i}\\) and a single unobserved confounding variables \\(U_i\\):\n\n\\(Y_i = \\tau T_i + \\mathbf{\\beta' X_i} + \\gamma U_i + \\epsilon_{Y_i}\\) and assume that \\(Cov(\\epsilon_{Y_i},T_i) = 0\\)\n\nSince \\(U_i\\) is unobserved, we have to estimate this model:\n\n\\(Y_i = \\tilde{\\tau}T_i + \\mathbf{\\tilde{\\beta}' X_i} + \\tilde{\\epsilon}_{Y_i}\\)\n\n\n\n\nHow does the estimable treatment effect \\(\\tilde{\\tau}\\) differ from the true treatment effect \\(\\tau\\)?\nTo find out, let’s apply the Frisch-Waugh-Lovell theorem to the above models to partial out the observed covariates \\(\\mathbf{X_i}\\):\n\n\\((Y_i - \\mathbb{E}(Y_i|\\mathbf{X_i}) = \\tau(T_i - \\mathbb{E}(T_i|\\mathbf{X_i})) + \\gamma(U_i - \\mathbb{E}(U_i|\\mathbf{X_i})) + \\epsilon_{Y_i}\\)\n\\((Y_i - \\mathbb{E}(Y_i|\\mathbf{X_i}) = \\tilde{\\tau}(T_i - \\mathbb{E}(T_i|\\mathbf{X_i})) + \\tilde{\\epsilon}_{Y_i}\\)\n\n\n\n\n\nObtain \\(\\tilde{\\tau}\\) and replace \\((Y_i - \\mathbb{E}(Y_i|\\mathbf{X_i})\\):\n\n\\[\n\\begin{align*}\n\\tilde{\\tau} &= \\frac{Cov((Y_i - \\mathbb{E}(Y_i|\\mathbf{X_i}), (T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))}{Var((T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))} = \\frac{Cov((\\tau(T_i - \\mathbb{E}(T_i|\\mathbf{X_i})) + \\gamma(U_i - \\mathbb{E}(U_i|\\mathbf{X_i})) + \\epsilon_{Y_i}), (T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))}{Var((T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))} \\\\\n&= \\tau \\underbrace{\\frac{ Cov((T_i - \\mathbb{E}(T_i|\\mathbf{X_i})),(T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))}{Var((T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))}}_{=1} + \\gamma \\underbrace{\\frac{ Cov((U_i - \\mathbb{E}(U_i|\\mathbf{X_i})),(T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))}{Var((T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))}}_{:=\\delta} + \\underbrace{\\frac{ Cov(\\epsilon_{Y_i},(T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))}{Var((T_i - \\mathbb{E}(T_i|\\mathbf{X_i})))}}_{=0}= \\tau + \\color{#FF7E15}{\\underbrace{\\gamma \\delta}_{\\text{Bias}}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/07_unob_conf.html#ommitted-confounder-bias---interpretation",
    "href": "slides/07_unob_conf.html#ommitted-confounder-bias---interpretation",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Ommitted Confounder Bias - Interpretation",
    "text": "Ommitted Confounder Bias - Interpretation\n\n\\(\\gamma\\) is the impact of the unobserved confounder \\(U_i\\) on the outcome \\(Y_i\\).\n\\(\\delta\\) is the impact of the treatment \\(T_i\\) on the unobserved confounder \\(U_i\\) while controlling for the observed coundounder \\(\\mathbf{X_i}\\).\n\n\\(\\delta\\) can be interpreted as imbalance in the unobserved confounder \\(U_i\\) across values of \\(T_i\\).\n\n\n\n\nOverall bias results from an unobserved confounder’s impact on the outcome times its imbalance across treatment levels.\nQuestion: How strong does the bias of an unobserved confounder have to be to invalidate the treatment effect estimate?\n\n\n\n\nAnswers to this question can be visualized by a contour plot of the bias \\(\\gamma \\delta\\) as a function of \\(\\gamma\\) and \\(\\delta\\)."
  },
  {
    "objectID": "slides/07_unob_conf.html#ommitted-confounder-bias---contour-plot",
    "href": "slides/07_unob_conf.html#ommitted-confounder-bias---contour-plot",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Ommitted Confounder Bias - Contour Plot",
    "text": "Ommitted Confounder Bias - Contour Plot\n\n\n\nHypothetical example: estimated treatment effect unadjusted for the unobserved confounder \\(\\tilde{\\tau} = 25\\).\nLevels of bias (contours) diminish the estimated \\(\\tilde{\\tau}\\) implying different levels of \\(\\tau\\).\nBenchmark covariates \\(X_b\\) for comparison."
  },
  {
    "objectID": "slides/07_unob_conf.html#recent-extensions-to-more-general-settings",
    "href": "slides/07_unob_conf.html#recent-extensions-to-more-general-settings",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Recent Extensions to More General Settings",
    "text": "Recent Extensions to More General Settings\n\nCinelli & Hazlett (2020):\n\n\nApproach:\n\nReparameterize the bias terms with scale-free partial \\(R^2\\) measures:\n\n\\(\\gamma\\): \\(R^2\\) to assess the strength of association between \\(\\mathbf{U_i}\\) and \\(Y_i\\) while controlling for \\(\\mathbf{X_i}\\).\n\\(\\delta\\): \\(R^2\\) to assess the strength of association between \\(\\mathbf{U_i}\\) and \\(T_i\\) while controlling for \\(\\mathbf{X_i}\\).\n\nDerive two new sensitivity measures:\n\nRobustness Value (RV): minimum strength of association that \\(\\mathbf{U_i}\\) must have with both \\(T_i\\) and \\(Y_i\\) to explain away the estimated \\(\\tilde{\\tau}\\).\n\\(\\color{#00C1D4}{R^2_{Y \\sim T|\\mathbf{X}}}\\): an extreme confounder \\(U^E_i\\) that explains 100% of the residual variance of \\(Y_i\\) (=&gt; \\(R^2_{Y \\sim U^E|T\\mathbf{X}} = 1\\)), must explain at least as much as \\(R^2_{T \\sim U^E|\\mathbf{X}} = R^2_{Y \\sim T|\\mathbf{X}}\\) of the residual variance of \\(T_i\\) to fully explain away the estimated \\(\\tilde{\\tau}\\).\n\n\n\n\n\nKey Advantages:\n\nNo assumptions on functional form of the treatment mechanism or the distribution of unobserved confounders.\nHandles multiple confounders that may interact with the treatment and outcome in non-linear ways.\nBenchmark the strength of confounders based on comparisons with observed covariates.\n\nImplementation: R package “sensemakr”."
  },
  {
    "objectID": "slides/07_unob_conf.html#recent-extensions-to-more-general-settings-1",
    "href": "slides/07_unob_conf.html#recent-extensions-to-more-general-settings-1",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Recent Extensions to More General Settings",
    "text": "Recent Extensions to More General Settings\n\nChernozhukov, Cinelli, et al. (2021-2024):\n\n\nApproach:\n\nUsing Riesz representers to derive influence functions for causal parameters in non-parametric settings.\n\nKey Advantages:\n\nApplicable in general nonparametric models without stringent assumptions about functional forms or distributions.\nBoth treatment mechanism and outcome mechanism can be modeled with arbitrary machine learning models.\nExtends to a broad range of causal parameters (also from AIPW, IV, DiD models).\n\nImplementation: R package “dml.sensemakr”."
  },
  {
    "objectID": "slides/07_unob_conf.html#sensitivity-analysis-example",
    "href": "slides/07_unob_conf.html#sensitivity-analysis-example",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Sensitivity Analysis: Example",
    "text": "Sensitivity Analysis: Example\n\nAssess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.\n\n\n\n\nlibrary(hdm) # for the data\nlibrary(sensemakr) # load sensemakr package\ndata(pension) # Get data\n\n# runs conditional outcome regression model\nmodel &lt;- lm(net_tfa ~ p401 + age + db + educ + fsize + hown + inc + \n            male + marr + pira + twoearn, data = pension)\n\n# runs sensemakr for sensitivity analysis\nsensitivity &lt;- sensemakr(model = model, treatment = \"p401\",\n                         benchmark_covariates = c(\"inc\"), kd=1:3)\n\n# plot \n# plot(sensitivity)\n\n# short description of results\nsensitivity\n\nSensitivity Analysis to Unobserved Confounding\n\nModel Formula: net_tfa ~ p401 + age + db + educ + fsize + hown + inc + male + \n    marr + pira + twoearn\n\nNull hypothesis: q = 1 and reduce = TRUE \n\nUnadjusted Estimates of ' p401 ':\n  Coef. estimate: 11590.38 \n  Standard Error: 1345.253 \n  t-value: 8.61577 \n\nSensitivity Statistics:\n  Partial R2 of treatment with outcome: 0.00744 \n  Robustness Value, q = 1 : 0.08291 \n  Robustness Value, q = 1 alpha = 0.05 : 0.06468 \n\nFor more information, check summary."
  },
  {
    "objectID": "slides/07_unob_conf.html#what-is-an-instrumental-variable",
    "href": "slides/07_unob_conf.html#what-is-an-instrumental-variable",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "What is an Instrumental Variable?",
    "text": "What is an Instrumental Variable?\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssumptions:\n\nRelevance: \\(Z\\) is significantly correlated with \\(T\\), i.e. \\(Cov(Z, T) \\neq 0\\).  Path 1 must exist.\nExclusion Restriction: \\(Z\\) affects \\(Y\\) only through \\(T\\).  A direct path 2 must not exist.\nUnconfoundedness (Exogeneity, Validity): \\(Z\\) is independent of \\(U\\), i.e. \\(Cov(Z, \\epsilon_Y) = 0\\).  Conditioning on \\(\\mathbf{X}\\) required in some contexts (will cover this later).  Path 3 must not exist.\n\n\n\n\n\n\nEven with these assumptions fulfilled, there is no nonparametric identification of the ATE.\n\nThe backdoor path \\(T \\leftarrow U \\rightarrow Y\\) cannot be blocked.\n\nTwo identification approaches:\n\nParametric assumption (i.e. linearity):\n\nIdentification of homogeneous treatment effect.\n\nNo parametric, but monotonicity assumption:\n\nNonparametric identification of Local Average Treatment Effect (LATE) instead of ATE."
  },
  {
    "objectID": "slides/07_unob_conf.html#where-do-good-ivs-come-from",
    "href": "slides/07_unob_conf.html#where-do-good-ivs-come-from",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Where do Good IVs come from?",
    "text": "Where do Good IVs come from?\n\nLotteries - purely random:\n\nBy the researcher: randomized experiments with respect to the instrument not the treatment itself.\n\nEncouragement designs: random assignment of invitations or incentives to participate in a program.\n\nSometimes also institutionalized: e.g. draft lotteries in sport or military, school assignment, prize lotteries among customers as marketing device.\n\nNatural Experiments - as-good-as-random:\n\nRandom conditional on some covariates, i.e. rely on a selection-on-observables for the IV instead of the treatment.\nChanges in policy, regulation or law applicable to defined subpopulation.\nVariation in decision makers, evaluators, judges.\nEconomic shocks.\nHistorical events.\nChanges in weather conditions.\nVariation in geographical distance."
  },
  {
    "objectID": "slides/07_unob_conf.html#binary-linear-setting",
    "href": "slides/07_unob_conf.html#binary-linear-setting",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Binary Linear Setting",
    "text": "Binary Linear Setting\n\nAdditional Assumptions:\n\nBinary \\(Z_i\\) and \\(T_i\\) and linear outcome model with exclusion restriction for \\(Z_i\\): \\(Y_i = \\beta_0 + \\tau T_i + \\beta_U U_i + \\epsilon_i\\).\n\n\n\n\nLet us derive the Wald Estimand for the treatment effect in this IV setting in the following steps:\n\nStart by the associational difference.\nUse linearity of expectations and instrumental unconfoundedness assumption - rearrange.\nUse instrumental unconfoundedness assumption again.\n\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_i | Z_i = 1] &- \\mathbb{E}[Y_i | Z_i = 0] = \\mathbb{E}[\\beta_0 + \\tau T_i + \\beta_U U_i + \\epsilon_i | Z_i = 1] - \\mathbb{E}[\\beta_0 + \\tau T_i + \\beta_U U_i + \\epsilon_i | Z_i = 0] \\\\\n&= \\beta_0 + \\tau \\mathbb{E}[T_i | Z_i = 1] + \\beta_u \\mathbb{E}[U_i | Z_i = 1] + \\mathbb{E}[\\epsilon_i | Z_i = 1] - \\beta_0 - \\tau \\mathbb{E}[T_i | Z_i = 0] - \\beta_u \\mathbb{E}[U_i | Z_i = 0] - \\mathbb{E}[\\epsilon_i | Z_i = 0] \\\\\n&= \\tau (\\mathbb{E}[T_i | Z_i = 1] - \\mathbb{E}[T_i | Z_i = 0]) + \\beta_u (\\mathbb{E}[U_i | Z_i = 1] - \\mathbb{E}[U_i | Z_i = 0]) \\\\\n&= \\tau (\\mathbb{E}[T_i | Z_i = 1] - \\mathbb{E}[T_i | Z_i = 0]) + \\beta_u (\\mathbb{E}[U_i] - \\mathbb{E}[U_i]) = \\tau (\\mathbb{E}[T_i | Z_i = 1] - \\mathbb{E}[T_i | Z_i = 0])\n\\end{align*}\n\\]\n\n\n\n\n\nSolve for \\(\\tau\\) to get the Wald Estimand:\n\n\\[\n\\tau = \\frac{\\mathbb{E}[Y_i | Z_i = 1] - \\mathbb{E}[Y_i | Z_i = 0]}{\\mathbb{E}[T_i | Z_i = 1] - \\mathbb{E}[T_i | Z_i = 0]}\n\\]\n\n\nSample version, i.e. Wald Estimator:\n\n\\[\n\\hat{\\tau} = \\frac{\\sum_{i=1}^n Y_i \\cdot Z_i - \\sum_{i=1}^n Y_i \\cdot (1 - Z_i)}{\\sum_{i=1}^n T_i \\cdot Z_i - \\sum_{i=1}^n T_i \\cdot (1 - Z_i)}\n\\]\n\n\nRelevance assumption ensures that denominator is not zero."
  },
  {
    "objectID": "slides/07_unob_conf.html#continuous-linear-setting",
    "href": "slides/07_unob_conf.html#continuous-linear-setting",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Continuous Linear Setting",
    "text": "Continuous Linear Setting\n\nAdditional Assumptions:\n\nContinuous. \\(Z_i\\) and \\(T_i\\) and linear outcome model with exclusion restriction for \\(Z_i\\): \\(Y_i = \\beta_0 + \\tau T_i + \\beta_U U_i + \\epsilon_i\\).\n\n\n\n\nLet us derive the Wald Estimand for the treatment effect in this IV setting in the following steps:\n\nStart with the classic covariance identity.\nUse linearity of expectations and instrumental unconfoundedness - rearrange.\nUse covariance identity and instrumental unconfoundedness assumption again.\n\n\n\\[\n\\begin{align*}\nCov(Y_i, Z_i) &= \\mathbb{E}[Y_i Z_i] - \\mathbb{E}[Y_i] \\mathbb{E}[Z_i] = \\mathbb{E}[(\\beta_0 + \\tau T_i + \\beta_U U_i + \\epsilon_i) Z_i] - \\mathbb{E}[\\beta_0 + \\tau T_i + \\beta_U U_i + \\epsilon_i] \\mathbb{E}[Z_i] \\\\\n&= \\beta_0\\mathbb{E}[Z_i] + \\tau\\mathbb{E}[T_iZ_i] + \\beta_U \\mathbb{E}[U_iZ_i] + \\mathbb{E}[\\epsilon_iZ_i] - \\beta_0\\mathbb{E}[Z_i] - \\tau\\mathbb{E}[T_i]\\mathbb{E}[Z_i] - \\beta_U\\mathbb{E}[U_i]\\mathbb{E}[Z_i] - \\mathbb{E}[\\epsilon_i]\\mathbb{E}[Z_i]\\\\\n&= \\tau\\mathbb{E}[T_iZ_i] + \\beta_U \\mathbb{E}[U_iZ_i] - \\tau\\mathbb{E}[T_i]\\mathbb{E}[Z_i] - \\beta_U\\mathbb{E}[U_i]\\mathbb{E}[Z_i] = \\tau(\\mathbb{E}[T_iZ_i] - \\mathbb{E}[T_i]\\mathbb{E}[Z_i]) + \\beta_U (\\mathbb{E}[U_iZ_i]  - \\mathbb{E}[U_i]\\mathbb{E}[Z_i])\\\\\n&= \\tau Cov(T_i, Z_i) + \\beta_U Cov(U_i, Z_i) = \\tau Cov(T_i, Z_i)\n\\end{align*}\n\\]\n\n\n\n\n\nSolve for \\(\\tau\\) to get the Wald Estimand:\n\n\\[\n\\tau = \\frac{Cov(Y_i, Z_i)}{Cov(T_i, Z_i)}\n\\]\n\n\nSample version, i.e. Wald Estimator:\n\n\\[\n\\hat{\\tau} = \\frac{\\sum_{i=1}^n Y_i \\cdot Z_i - \\bar{Y} \\bar{Z}}{\\sum_{i=1}^n T_i \\cdot Z_i - \\bar{T} \\bar{Z}}\n\\]\n\n\nRelevance assumption ensures that denominator is not zero."
  },
  {
    "objectID": "slides/07_unob_conf.html#two-stage-least-squares-estimator-2sls",
    "href": "slides/07_unob_conf.html#two-stage-least-squares-estimator-2sls",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Two-Stage Least Squares Estimator (2SLS)",
    "text": "Two-Stage Least Squares Estimator (2SLS)\n\nStage: Linearly regress \\(T_i\\) on \\(Z_i\\) to estimate \\(\\mathbb{E}[T_i|Z_i]\\). This gives the projection of \\(T_i\\) onto \\(Z_i\\): \\(\\hat{T}_i\\).\nStage: Linearly regress \\(Y_i\\) on \\(\\hat{T}_i\\) to estimate \\(\\mathbb{E}[Y_i|\\hat{T}_i]\\). Obtain the estimate \\(\\hat{\\tau}\\) as the fitted coefficient of \\(\\hat{T}_i\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlso works as an estimator in the binary setting."
  },
  {
    "objectID": "slides/07_unob_conf.html#stratification-of-data",
    "href": "slides/07_unob_conf.html#stratification-of-data",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Stratification of Data",
    "text": "Stratification of Data\n\nDefine potential treatments conditional on \\(Z_i\\): \\(T_i(0)\\) if \\(Z_i = 0\\) and \\(T_i(1)\\) if \\(Z_i = 1\\).\n\n\n\nPrincipal strata:\n\nCompliers always take the treatment that they’re encouraged to take: \\(T_i(1) = 1\\) and \\(T_i(0) = 0\\).\nAlways-Takers always take the treatment, regardless of encouragement: \\(T_i(1) = 1\\) and \\(T_i(0) = 1\\).\nNever-Takers never take the treatment, regardless of encouragement: \\(T_i(1) = 0\\) and \\(T_i(0) = 0\\).\nDefiers always take the opposite treatment that they’re encouraged to take: \\(T_i(1) = 0\\) and \\(T_i(0) = 1\\).\n\n\n\n\n\n\n\nCausal graph for compliers and defiers:\n\n\n\n\n\n\n\n\n\n\n\n\nCausal graph for always-takers and never-takers:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBut can’t identify what strata a given unit is in: e.g. \\(Z_i = 0\\) & \\(T_i = 0\\) could be compliers or never-takers; etc."
  },
  {
    "objectID": "slides/07_unob_conf.html#late-definition-identification",
    "href": "slides/07_unob_conf.html#late-definition-identification",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "LATE: Definition & Identification",
    "text": "LATE: Definition & Identification\n\nInstead of nonparametrically identifying the ATE, it is only possible to nonparametrically identify the LATE:\n\n\n\n\nDefinition: “Local Average Treatment Effect (LATE) / Complier Average Causal Effect (CACE)”\n\n\n\\(\\mathbb{E}[Y_i(T_i=1) - Y_i(T_i=0) | T_i(Z_i=1) = 1, T_i(Z_i=0) = 0]\\)\n\n\n\n\nInstead of the linearity assumption, we need the monotonicity assumption:\n\n\n\n\nAssumption: “Monotonicity”\n\n\n\\(\\forall i, T_i(Z_i=1) \\geq T_i(Z_i=0)\\)\n\n\n\n\nMonotonicity implies that there are no defiers in the population.\n\n\n\n\nTheorem: “LATE Nonparametric Identification”\n\n\n\nGiven that \\(Z_i\\) is an instrument, \\(Z_i\\) and \\(T_i\\) are binary variables, and that monotonicity holds, the following is true:\n\n\\(\\mathbb{E}[Y_i(1) - Y_i(0) | T_i(1) = 1, T_i(0) = 0] = \\frac{\\mathbb{E}[Y_i | Z_i = 1] - \\mathbb{E}[Y_i | Z_i = 0]}{\\mathbb{E}[T_i | Z_i = 1] - \\mathbb{E}[T_i | Z_i = 0]}\\)\n\n\n\n\nNumerator is 2nd-stage Intention-to-Treat (ITT) Effect; denominator is 1st-stage effect or Complier Share."
  },
  {
    "objectID": "slides/07_unob_conf.html#late-proof-1",
    "href": "slides/07_unob_conf.html#late-proof-1",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "LATE: Proof 1",
    "text": "LATE: Proof 1\n\nStart with causal effect of \\(Z_i\\) on \\(Y_i\\) and decompose it into weighted stratum-specific causal effects:\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_i(Z_i=1) - Y_i(Z_i=0)] &= \\mathbb{E}[Y_1(Z_i = 1) - Y_i(Z_i = 0) \\mid T_i(1) = 1, T_i(0) = 0]P(T_i(1) = 1, T_i(0) = 0) \\quad \\text{(compliers)} \\\\\n&+ \\mathbb{E}[Y_1(Z_i = 1) - Y_i(Z_i = 0) \\mid T_i(1) = 0, T_i(0) = 1]P(T_i(1) = 0, T_i(0) = 1) \\quad \\text{(defiers)}\\\\\n&+ \\mathbb{E}[Y_1(Z_i = 1) - Y_i(Z_i = 0) \\mid T_i(1) = 1, T_i(0) = 1]P(T_i(1) = 1, T_i(0) = 1) \\quad \\text{(always-takers)}\\\\\n&+ \\mathbb{E}[Y_1(Z_i = 1) - Y_i(Z_i = 0) \\mid T_i(1) = 0, T_i(0) = 0]P(T_i(1) = 0, T_i(0) = 0) \\quad \\text{(never-takers)}\\\\\n\\end{align*}\n\\]\n\nSolve for the effect of \\(Z_i\\) on \\(Y_i\\) among compliers:\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_1(Z_i = 1) - Y_i(Z_i = 0) \\mid T_i(1) = 1, T_i(0) = 0] = \\frac{\\mathbb{E}[Y_i(Z_i=1) - Y_i(Z_i=0)]}{P(T_i(1) = 1, T_i(0) = 0)}\n\\end{align*}\n\\]\n\nCompliers always take the treatment they are encouraged to (replace Z for T) and apply instrumental unconfoundedness assumption to identify the numerator:\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_1(T_i = 1) - Y_i(T_i = 0) \\mid T_i(1) = 1, T_i(0) = 0] = \\frac{\\mathbb{E}[Y_i(Z_i=1) - Y_i(Z_i=0)]}{P(T_i(1) = 1, T_i(0) = 0)} = \\frac{\\mathbb{E}[Y_i|Z_i=1] - \\mathbb{E}[Y_i|Z_i=0)]}{P(T_i(1) = 1, T_i(0) = 0)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/07_unob_conf.html#late-proof-2",
    "href": "slides/07_unob_conf.html#late-proof-2",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "LATE: Proof 2",
    "text": "LATE: Proof 2\n\nTo identify the denominator (pobability of being a complier), take everyone (probability 1) and subtract always-takers and never-takers, since there are no defiers, due to monotonicity:\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_1(T_i = 1) - Y_i(T_i = 0) \\mid T_i(1) = 1, T_i(0) = 0] &= \\frac{\\mathbb{E}[Y_i|Z_i=1] - \\mathbb{E}[Y_i|Z_i=0)]}{P(T_i(1) = 1, T_i(0) = 0)} \\\\\n&= \\frac{\\mathbb{E}[Y_i|Z_i=1] - \\mathbb{E}[Y_i|Z_i=0)]}{1 - P(T_i = 0 | Z_i = 1) - P(T_i = 1 | Z_i = 0)} \\\\\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_1(T_i = 1) - Y_i(T_i = 0) \\mid T_i(1) = 1, T_i(0) = 0] &= \\frac{\\mathbb{E}[Y_i|Z_i=1] - \\mathbb{E}[Y_i|Z_i=0)]}{1 - (1 - P(T_i = 1 | Z_i = 1)) - P(T_i = 1 | Z_i = 0)} \\\\\n&= \\frac{\\mathbb{E}[Y_i|Z_i=1] - \\mathbb{E}[Y_i|Z_i=0)]}{P(T_i = 1 | Z_i = 1) - P(T_i = 1 | Z_i = 0)} \\\\\n\\end{align*}\n\\]\n\nFinally, because \\(T_i\\) is a binary variable, we can swap probabilities of \\(T_i = 1\\) for expectations:\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_1(T_i = 1) - Y_i(T_i = 0) \\mid T_i(1) = 1, T_i(0) = 0] = \\frac{\\mathbb{E}[Y_i|Z_i=1] - \\mathbb{E}[Y_i|Z_i=0)]}{\\mathbb{E}[T_i | Z_i = 1] - \\mathbb{E}[T_i | Z_i = 0)]} \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/07_unob_conf.html#iv-estimation-example",
    "href": "slides/07_unob_conf.html#iv-estimation-example",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "IV Estimation: Example",
    "text": "IV Estimation: Example\n\nAssess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.\n\n\n\n\nlibrary(hdm) # for the data\ndata(pension) # Get data\nY = pension$net_tfa # Outcome\nZ = pension$e401 # Instrument\nT = pension$p401 # Treatment\nITT=mean(Y[Z==1])-mean(Y[Z==0])   # estimate intention-to-treat effect (ITT)\nfirst=mean(T[Z==1])-mean(T[Z==0]) # estimate first stage effect (complier share)\nLATE=ITT/first                    # compute LATE\nITT; first; LATE                  # show ITT, first stage effect, and LATE\n\n[1] 19559.34\n\n\n[1] 0.7045084\n\n\n[1] 27763.11\n\n\n\n\nlibrary(hdm) # for the data\nlibrary(AER) # load AER package for ivreg (2SLS)\ndata(pension) # Get data\nY = pension$net_tfa # Outcome\nZ = pension$e401 # Instrument\nT = pension$p401 # Treatment\n\nLATE=ivreg(Y~T|Z)                 # run two stage least squares regression\nsummary(LATE,vcov = vcovHC)       # results with heteroscedasticity-robust se\n\n\nCall:\nivreg(formula = Y ~ T | Z)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-513090  -15011  -10788   -1624 1498247 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  10788.0      690.6   15.62   &lt;2e-16 ***\nT            27763.1     1985.4   13.98   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 62380 on 9913 degrees of freedom\nMultiple R-Squared: 0.03586,    Adjusted R-squared: 0.03577 \nWald test: 195.5 on 1 and 9913 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "slides/07_unob_conf.html#motivation-control-for-covariates",
    "href": "slides/07_unob_conf.html#motivation-control-for-covariates",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Motivation: Control for Covariates",
    "text": "Motivation: Control for Covariates\n\nIn many applications, it may not be credible that IV assumptions like random assignment hold unconditionally, i.e. without controlling for observed covariates.\n\nNatural experiments vs. purely randomized encouragement design.\nProblematic if covariates are confounders between instrument and outcome.\nE.g. geographic proximity to college as IV when assessing the effect of eductaion (treatment) on earnings (outcome). Pros & cons of this IV?\n\n2SLS can be extended, but the linear specification for covariates has to be correct."
  },
  {
    "objectID": "slides/07_unob_conf.html#partially-linear-iv-model",
    "href": "slides/07_unob_conf.html#partially-linear-iv-model",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Partially Linear IV Model",
    "text": "Partially Linear IV Model\n\n\\(T_i\\) is additively separable and we require conditional unconfoundedness of the instrument \\(Z_i\\): \\[\\begin{align}\\begin{aligned}Y_i = \\tau T_i + g(\\mathbf{X_i}) + \\epsilon_{Y_i}, & &\\mathbb{E}(\\epsilon_{Y_i} | Z_i,\\mathbf{X_i}) = 0 \\\\Z_i = h(\\mathbf{X_i}) + \\epsilon_{Z_i}, & &\\mathbb{E}(\\epsilon_{Z_i} | \\mathbf{X_i}) = 0\\end{aligned}\\end{align}\\] \nRobinson (1988)-style/ partialling-out version of the Wald estimand:\n\n\\(\\tau\\) is identified by using residuals of the predicted instrument as instrument for the residual-on-residual regression:\n\n\n\\[\\tau = \\frac{\\mathbb{E}[(Y_i - \\mu(\\mathbf{X_i})) (Z_i - h(\\mathbf{X_i}))]}{\\mathbb{E}[(T_i - e(\\mathbf{X_i})) (Z_i - h(\\mathbf{X_i}))]} = \\frac{\\text{Cov}[(Y_i - \\mu(\\mathbf{X_i})), (Z_i - h(\\mathbf{X_i}))]}{\\text{Cov}[(T_i - e(\\mathbf{X_i})), (Z_i - h(\\mathbf{X_i}))]}\\]"
  },
  {
    "objectID": "slides/07_unob_conf.html#partially-linear-iv-model-1",
    "href": "slides/07_unob_conf.html#partially-linear-iv-model-1",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Partially Linear IV Model",
    "text": "Partially Linear IV Model\n\nNuisance parameters: \\(\\quad \\mu(\\mathbf{X_i}) = \\mathbb{E}[Y_i \\mid \\mathbf{X_i}] \\quad \\quad \\quad e(\\mathbf{X_i}) = \\mathbb{E}[T_i \\mid \\mathbf{X_i}] \\quad \\quad \\quad h(\\mathbf{X_i}) = \\mathbb{E}[Z_i \\mid \\mathbf{X_i}]\\)\n\n\n\nDML recipe: we need a moment condition of a Neyman-orthogonal score with the estimand as solution:\n\n\\[\n\\begin{align}\n\\mathbb{E} [\n( Y_i - \\mu(X) - \\tau (T_i - e(\\mathbf{X_i})) ) (Z - h(\\mathbf{X_i}))\n] &= 0 \\\\\n\\mathbb{E} \\left[\n(Y_i - \\mu(\\mathbf{X_i}))(Z_i - h(\\mathbf{X_i})) - \\tau (T_i - e(\\mathbf{X_i}))(Z_i - h(\\mathbf{X_i}))\n\\right] &= 0 \\\\\n\\tau \\mathbb{E} [ \\underbrace{(-1)(T_i - e(\\mathbf{X_i}))(Z_i - h(\\mathbf{X_i}))}_{\\psi_a} ] + \\mathbb{E} [ \\underbrace{(Y_i - \\mu(\\mathbf{X_i}))(Z_i - h(\\mathbf{X_i}))}_{\\psi_b} ] &= 0\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/07_unob_conf.html#interactive-aipw-iv-model",
    "href": "slides/07_unob_conf.html#interactive-aipw-iv-model",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Interactive (AIPW) IV Model",
    "text": "Interactive (AIPW) IV Model\n\nRelaxing homogeneous treatment assumption, but we require conditional unconfoundedness of \\(Z_i\\): \\[\\begin{align}\\begin{aligned}Y_i = g(T_i, \\mathbf{X_i}) + \\epsilon_{Y_i}, & &\\mathbb{E}(\\epsilon_{Y_i} | Z_i,\\mathbf{X_i}) = 0 \\\\Z_i = h(\\mathbf{X_i}) + \\epsilon_{Z_i}, & &\\mathbb{E}(\\epsilon_{Z_i} | \\mathbf{X_i}) = 0\\end{aligned}\\end{align}\\]\n\n\n\nBased on Frölich (1988), generalizing the Wald estimator of LATE to the case with confounders.\n\nATE of \\(Z_i\\) on \\(Y_i\\) (reduced form, intention-to-treat effect) divided by ATE of \\(Z_i\\) on \\(T_i\\) (first stage / complier share).\n\n\n\\[\\tau_{\\text{LATE}} = \\frac{\\mathbb{E}\\left[\\mu(1, \\mathbf{X_i}) - \\mu(0, \\mathbf{X_i}) + \\frac{Z_i(Y_i - \\mu(1, \\mathbf{X_i}))}{h(\\mathbf{X_i})} - \\frac{(1-Z_i)(Y_i - \\mu(0, \\mathbf{X_i})}{(1-h(\\mathbf{X_i}))} \\right]}{\\mathbb{E}\\left[e(1, \\mathbf{X_i}) - e(0, \\mathbf{X_i}) + \\frac{Z_i(T_i - e(1, \\mathbf{X_i}))}{h(\\mathbf{X_i})} - \\frac{(1-Z_i)(T_i - e(0, \\mathbf{X_i})}{(1-h(\\mathbf{X_i}))} \\right]}\\]"
  },
  {
    "objectID": "slides/07_unob_conf.html#interactive-aipw-iv-model-1",
    "href": "slides/07_unob_conf.html#interactive-aipw-iv-model-1",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "Interactive (AIPW) IV Model",
    "text": "Interactive (AIPW) IV Model\n\nNuisance parameters: \\(\\quad \\mu(Z_i, \\mathbf{X_i}) = \\mathbb{E}[Y_i \\mid Z_i, \\mathbf{X_i}] \\quad \\quad \\quad e(\\mathbf{Z_i, X_i}) = P[T_i \\mid Z_i, \\mathbf{X_i}] \\quad \\quad \\quad h(\\mathbf{X_i}) = P[Z_i \\mid \\mathbf{X_i}]\\)\n\n\n\nDML recipe: we need a moment condition of a Neyman-orthogonal score with the estimand as solution:\n\n\\[\n\\begin{align}\n\\mathbb{E}[\\psi_b] + \\mathbb{E}[\\psi_a] \\cdot \\tau_{\\text{LATE}} = &\\mathbb{E}\\bigg[\\mu(1, \\mathbf{X_i}) - \\mu(0, \\mathbf{X_i}) + \\frac{Z_i(Y_i - \\mu(1, \\mathbf{X_i}))}{h(\\mathbf{X_i})} - \\frac{(1-Z_i)(Y_i - \\mu(0, \\mathbf{X_i})}{(1-h(\\mathbf{X_i}))} \\bigg] \\\\\n&+ \\mathbb{E}\\bigg[(-1)\\left[e(1, \\mathbf{X_i}) - e(0, \\mathbf{X_i}) + \\frac{Z_i(T_i - e(1, \\mathbf{X_i}))}{h(\\mathbf{X_i})} - \\frac{(1-Z_i)(T_i - e(0, \\mathbf{X_i})}{(1-h(\\mathbf{X_i}))}\\right] \\bigg] \\cdot \\tau_{\\text{LATE}} = 0\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/07_unob_conf.html#iv-estimation-with-dml-aipw-example",
    "href": "slides/07_unob_conf.html#iv-estimation-with-dml-aipw-example",
    "title": "(7) Unobserved Confounding and Instrumental Variables",
    "section": "IV Estimation with DML-AIPW: Example",
    "text": "IV Estimation with DML-AIPW: Example\n\n\n\nAssess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.\nParticipation in 401(k) program is not random, but influenced by income together with unobserved saving preferences.\nEligibility for 401(k) program can serve as an instrument, but it is not purely random:\n\nEmployers differ in leniency to offer a 401(k) program to their employees.\nWealthy companies are more likely to offer a 401(k) program and pay higher income.\nEmployees have chosen their employer based on their income/saving preferences.\n\n\n\n\n# Load required packages\nlibrary(DoubleML)\nlibrary(mlr3)\nlibrary(mlr3learners)\nlibrary(data.table)\n\n# suppress messages during fitting\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n\n# load data as a data.table\ndata = fetch_401k(return_type = \"data.table\", instrument = TRUE)\n\n# Set up basic model: Specify variables for data-backend\nfeatures_base = c(\"age\", \"inc\", \"educ\", \"fsize\",\"marr\", \"twoearn\", \"db\", \"pira\", \"hown\")\n\n# Initialize DoubleMLData (data-backend of DoubleML)\ndata_dml_base = DoubleMLData$new(data,\n                                 y_col = \"net_tfa\", # outcome variable\n                                 d_cols = \"p401\", # treatment variable\n                                 x_cols = features_base, # covariates\n                                 z_cols = \"e401\") # instrument\n\n# Initialize Random Forrest Learner\nrandomForest = lrn(\"regr.ranger\")\nrandomForest_class = lrn(\"classif.ranger\")\n\n# Random Forest\nset.seed(123)\ndml_iivm_forest = DoubleMLIIVM$new(data_dml_base,\n                              ml_g = randomForest,\n                              ml_m = randomForest_class,\n                              ml_r = randomForest_class,\n                              n_folds = 3, \n                              score = \"LATE\", # only choice for Interactive IV models\n                              trimming_threshold = 0.01,\n                              subgroups = list(always_takers = FALSE, # not in sample: no participation w/o eligibility.\n                                               never_takers = TRUE))\n\n# Set nuisance-part specific parameters\ndml_iivm_forest$set_ml_nuisance_params(\n    \"ml_g0\", \"p401\", \n    list(max.depth = 6, mtry = 4, min.node.size = 7))  # mu(Z=0,X) = E[Y | Z=0, X]\ndml_iivm_forest$set_ml_nuisance_params(\n    \"ml_g1\", \"p401\", \n    list(max.depth = 6, mtry = 3, min.node.size = 5)) # mu(Z=1,X) = E[Y | Z=1, X]\ndml_iivm_forest$set_ml_nuisance_params(\n    \"ml_m\", \"p401\", \n    list(max.depth = 6, mtry = 3, min.node.size = 6)) # h(X) = P(Z=1 | X)\ndml_iivm_forest$set_ml_nuisance_params(\n    \"ml_r1\", \"p401\", \n    list(max.depth = 4, mtry = 7, min.node.size = 6)) # e(Z,X) = P(T=1 | Z, X)\n\ndml_iivm_forest$fit()\ndml_iivm_forest$summary()\n\nEstimates and significance testing of the effect of target variables\n     Estimate. Std. Error t value Pr(&gt;|t|)    \np401     11694       1603   7.294    3e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/05_dml.html#observed-confounding",
    "href": "slides/05_dml.html#observed-confounding",
    "title": "(5) Double Machine Learning",
    "section": "Observed Confounding",
    "text": "Observed Confounding\n\nWe need these assumptions:\n\n\n\n\nAssumption A1: “Conditional Exchangeability / Unconfoundedness / Ignorability / Independence”.\n\n\n\\(Y_i(t) \\perp\\!\\!\\!\\perp T_i \\mid \\mathbf{X_i = x}, \\forall t \\in \\{0,1,\\dots\\}, \\text{ and } \\mathbf{x} \\in \\mathbb{X}\\).\n\n\n\n\n\n\nAssumption A2: “Positivity / Overlap / Common Support”.\n\n\n\\(0 &lt; P(T_i = t|\\mathbf{X_i = x}), \\forall t \\in \\{0,1,\\dots\\}, \\text{ and } \\mathbf{x} \\in \\mathbb{X}\\).\n\n\n\n\n\n\nAssumption A3: “Stable Unit Treatment Value Assumption (SUTVA).”\n\n\n\\(Y_i = Y(T_i)\\)\n\n\n\n\n… to achieve identification of the ATE:\n\n\n\n\nTheorem: “Identification of the ATE”:\n\n\n\\(\\tau_{\\text{ATE}} = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mathbb{E_X}[\\mathbb{E}[Y_i|T_i=1,\\mathbf{X_i = x}] - \\mathbb{E}[Y_i|T_i=0, \\mathbf{X_i = x}]]\\)"
  },
  {
    "objectID": "slides/05_dml.html#types-of-parameters",
    "href": "slides/05_dml.html#types-of-parameters",
    "title": "(5) Double Machine Learning",
    "section": "Types of Parameters",
    "text": "Types of Parameters\nCausal Machine Learning methods force us to distinguish between two types of parameters:\n\n\nTarget parameter is motivated by the research question and defined under modelling assumption,\n\n\ne.g. effect of a treatment on some outcome.\n\n\nNuisance parameters are inputs that are required to obtain the target parameter, but are not relevant for our research question.\n\n\ne.g. propensity scores.\n\nFocus on the target parameter and do not get tempted to interpret every single coefficient from a regression."
  },
  {
    "objectID": "slides/05_dml.html#frisch-waugh-lovell-fwl-theorem",
    "href": "slides/05_dml.html#frisch-waugh-lovell-fwl-theorem",
    "title": "(5) Double Machine Learning",
    "section": "Frisch-Waugh-Lovell (FWL) Theorem",
    "text": "Frisch-Waugh-Lovell (FWL) Theorem\n\nWe can estimate \\(\\beta_T\\) in a standard linear regression \\(Y_i = \\beta_0 + \\beta_T T_i + \\mathbf{\\beta_{X}' X_i} + \\epsilon_i\\) in a three-stage procedure:\n\n\nRun a regression of the form \\(Y_i = \\beta_{Y0} + \\mathbf{\\beta_{Y \\sim X}' X_i} + \\epsilon_{Y_i \\sim X_i}\\) and extract the estimated residuals \\(\\hat\\epsilon_{Y_i \\sim X_i}\\).\nRun a regression of the form \\(T_i = \\beta_{T0} + \\mathbf{\\beta_{T \\sim X}' X_i} + \\epsilon_{T_i \\sim X_i}\\) and extract the estimated residuals \\(\\hat\\epsilon_{T_i \\sim X_i}\\).\nRun a residual-on-residual regression of the form \\(\\hat\\epsilon_{Y_i \\sim X_i} = \\beta_T \\hat\\epsilon_{T_i \\sim X_i} + \\epsilon_i\\) (no constant).\n\nThe resulting estimate \\(\\hat\\beta_T\\) is numerically identical to the estimate we would get if we just run the full OLS model."
  },
  {
    "objectID": "slides/05_dml.html#target-parameters",
    "href": "slides/05_dml.html#target-parameters",
    "title": "(5) Double Machine Learning",
    "section": "Target Parameters",
    "text": "Target Parameters\n\nAverage potential outcome (APO): \\(\\mu_t := \\mathbb{E}[Y_i(t)]\\).\n\nWhat is the expected outcome if everybody receives treatment t?\n\nAverage Treatment Effect (ATE): \\(\\tau_{\\text{ATE}} := \\mathbb{E}[Y_i(1)] -  \\mathbb{E}[Y_i(0)] = \\mu_1 - \\mu_0\\).\n\nWhat is the expected treatment effect in the population?\n\n\n\n\nNote that the target parameters are just different aggregations of the Conditional Average Potential Outcome (CAPO): \\(\\mathbb{E}[Y_i(t) \\mid  \\mathbf{X_i = x} ]\\)\n\n\\(\\mu_t := \\mathbb{E}[Y_i(t)] \\overset{LIE}{=} \\mathbb{E}[\\mathbb{E}[Y_i(t) \\mid \\mathbf{X_i = x}]]\\)\n\\(\\tau_{\\text{ATE}} := \\mathbb{E}[Y_i(1)] -  \\mathbb{E}[Y_i(0)] \\overset{LIE}{=} \\mathbb{E}[\\mathbb{E}[Y_i(1) \\mid  \\mathbf{X_i = x}]] - \\mathbb{E}[\\mathbb{E}[Y_i(0) \\mid  \\mathbf{X_i = x} ]]\\).\n\nIt suffices to show that the CAPO is identified."
  },
  {
    "objectID": "slides/05_dml.html#general-approach",
    "href": "slides/05_dml.html#general-approach",
    "title": "(5) Double Machine Learning",
    "section": "General Approach",
    "text": "General Approach\n\nCausal Machine Learning methods are mostly about rewriting stuff such that we are allowed to leverage supervised ML to estimate the nuisance parameters.\nImportantly, the target parameters of interest remain the same although the rewritten form can look quite different to the original/familiar model.\nThe methods usually boil down to running multiple supervised ML regressions and combining their predictions into a final OLS regression.\nSupervised ML holds the promise of data-driven model selection and complex non-linear relationships, and thus, getting (one of) the nuisance parameters right.\nThe crucial point is that the statistical inference in this final OLS regression is valid if we follow a particular recipe.\n\nRecipe of how to split the estimation of causal effects into prediction tasks."
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-methods-idea",
    "href": "slides/05_dml.html#doubly-robust-methods-idea",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Methods: Idea",
    "text": "Doubly Robust Methods: Idea\n\nGiven the three assumptions hold, we have seen two ways to identify the ATE: \\(\\tau_{\\text{ATE}} = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mu_1 - \\mu_0\\)\n\n\n\nConditional outcome regression:\n\n\\(\\tau_{\\text{ATE}} = \\mathbb{E_X}[\\mathbb{E}[Y_i | T_i = 1, \\mathbf{X_i = x}] - \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i = x}]]\\)\nSimplified notation with nuisance parameter \\(\\mu(t, \\mathbf{x}) = \\mathbb{E}[Y_i | T_i = t, \\mathbf{X_i = x}]\\) as conditional average potential outcome:\n\\(\\tau_{\\text{ATE}} = \\mathbb{E_X}[\\mu(t = 1, \\mathbf{x}) - \\mu(t=0,\\mathbf{x})]\\)\n\n\n\n\n\nInverse probability weighting:\n\n\\(\\tau_{\\text{ATE}} = \\mathbb{E}\\left[\\frac{T_i Y_i}{P(T_i = 1 \\mid \\mathbf{X_i = x})}\\right] - \\mathbb{E}\\left[\\frac{(1 - T_i) Y_i}{1 - P(T_i = 1 \\mid \\mathbf{X_i})}\\right]\\)\n\\(\\tau_{\\text{ATE}} = \\mathbb{E}\\left[\\frac{T_i Y_i}{PS(\\mathbf{X_i})}\\right] - \\mathbb{E}\\left[\\frac{(1 - T_i) Y_i}{1 - PS(\\mathbf{X_i})}\\right]\\)\nSimplified notation with nuisance parameter \\(e_t(\\mathbf{x}) = P(T_i = t \\mid \\mathbf{X_i = x})\\) as propensity score:\n\\(\\tau_{\\text{ATE}} = \\mathbb{E}\\left[\\frac{\\mathbb{1}(T_i = 1) Y_i}{e_{t=1}(\\mathbf{x})}\\right] - \\mathbb{E}\\left[\\frac{\\mathbb{1}(T_i = 0) Y_i}{e_{t=0}(\\mathbf{x})}\\right]\\)\n\n\n\n\n\nIdea of doubly robust methods:\n\nCombine both approaches, such that the ATE estimator is consistent, even if only one of the two models is correctly specified."
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-estimator-definition",
    "href": "slides/05_dml.html#doubly-robust-estimator-definition",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Estimator: Definition",
    "text": "Doubly Robust Estimator: Definition\n\nDoubly robust or Augmented Inverse Propensity Score Weighting (AIPW) estimator:\nConditional average potential outcome (CAPO) given by:\n\n\\[\n\\begin{align*}\n\\mu_t^{\\text{AIPW}}(\\mathbf{x}) := \\mathbb{E}[Y_i(t) | \\mathbf{X_i = x}] &\\overset{(A1,A3)}{=} \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i = x}] := \\mu(t, \\mathbf{x}) \\\\\n&\\text{(conditional outcome regression)} \\\\\n&\\overset{(2)}{=} \\mathbb{E}\\left[\\frac{\\mathbb{1}(T_i = t)Y_i}{e_t(x)} \\bigg| \\mathbf{X_i = x}\\right] \\\\\n&\\text{(inverse probability weighting)} \\\\\n&\\overset{(3)}{=} \\mathbb{E}\\bigg[\\mu(t, \\mathbf{x}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\mu(t, \\mathbf{x}))}{e_t(\\mathbf{x})} \\bigg| \\mathbf{X_i = x}\\bigg] \\\\\n&\\text{(augmenting outcome regression with IPW weights)} \\\\\n\\end{align*}\n\\]\n\n\nAverage potential outcome (APO) given by:\n\\[\\mu_t^{\\text{AIPW}} = \\mathbb{E_x}\\bigg[\\mathbb{E}\\bigg[\\mu(t, \\mathbf{x}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\mu(t, \\mathbf{x}))}{e_t(\\mathbf{x})} \\bigg| \\mathbf{X_i = x}\\bigg] \\bigg] = \\mathbb{E}\\bigg[\\mu(t, \\mathbf{x}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\mu(t, \\mathbf{x}))}{e_t(\\mathbf{x})} \\bigg] \\\\\\]"
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-estimator-proof",
    "href": "slides/05_dml.html#doubly-robust-estimator-proof",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Estimator: Proof",
    "text": "Doubly Robust Estimator: Proof\n\nProof for Equation (2):\n\n\\[\n\\begin{align*}\n\\mu_t(\\mathbf{x}) := \\mathbb{E}[Y_i(t) | \\mathbf{X_i = x}] &= \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i = x}]\\\\\n&= \\mathbb{E}[\\underbrace{\\mathbb{1}(T_i = t)}_{=1} Y_i \\mid T_i = t, \\mathbf{X_i = x}]\\\\\n&= \\mathbb{E}\\left[ \\mathbb{1}(T_i = t) \\frac{e_t(\\mathbf{x})}{e_t(\\mathbf{x})} \\mid {T_i = t, \\mathbf{X_i = x}}\\right] + (1 - e_t(\\mathbf{x})) \\mathbb{E}[\\underbrace{\\mathbb{1}(T_i = t)}_{=0} Y_i \\mid T_i \\neq t, \\mathbf{X_i = x}]/e_t(\\mathbf{x})\\\\\n&= \\frac{\\overbrace{e_t(\\mathbf{x}) \\mathbb{E}[\\mathbb{1}(T_i = t) Y_i \\mid T_i = t, \\mathbf{X_i = x}] + (1 - e_t(\\mathbf{x})) \\mathbb{E}[\\mathbb{1}(T_i = t) Y_i \\mid T_i \\neq t, \\mathbf{X_i = x}]}^{\\overset{LIE}{=}\\mathbb{E}[\\mathbb{1}(T_i = t) Y_i | \\mathbf{X_i = x}]}}{e_t(\\mathbf{x})} \\\\\n&= \\frac{\\mathbb{E}\\left[\\mathbb{1}(T_i = t)Y_i \\mid \\mathbf{X_i = x} \\right]}{e_t(\\mathbf{x})} = \\mathbb{E}\\left[\\frac{\\mathbb{1}(T_i = t)Y_i}{e_t(\\mathbf{x})} \\bigg| \\mathbf{X_i = x}\\right]\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-estimator-proof-1",
    "href": "slides/05_dml.html#doubly-robust-estimator-proof-1",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Estimator: Proof",
    "text": "Doubly Robust Estimator: Proof\n\nProof for Equation (3):\n\n\\[\n\\begin{align*}\n\\mu_t(\\mathbf{x}) := \\mathbb{E}[Y_i(t) | \\mathbf{X_i = x}] &= \\mathbb{E}\\left[\\mu(t, \\mathbf{x}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\mu(t, \\mathbf{x}))}{e_t(\\mathbf{x})} \\bigg| \\mathbf{X_i = x}\\right] \\\\\n&= \\mathbb{E}\\left[Y_i(t) - Y_i(t) + \\mu(t, \\mathbf{x}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\mu(t, \\mathbf{x}))}{e_t(\\mathbf{x})} \\bigg| \\mathbf{X_i = x}\\right] \\\\\n&= \\mathbb{E}\\left[Y_i(t) - Y_i(t) + \\mu(t, \\mathbf{x}) + \\frac{\\mathbb{1}(T_i = t)(Y_i(t) - \\mu(t, \\mathbf{x}))}{e_t(\\mathbf{x})} \\bigg| \\mathbf{X_i = x}\\right] \\\\\n&= \\mathbb{E}[Y_i(t) \\mid \\mathbf{X_i = x}] + \\mathbb{E} \\left[(Y_i(t) - \\mu(t, \\mathbf{x})) \\bigg(\\frac{\\mathbb{1}(T_i = t) - e_t(\\mathbf{x})}{e_t(\\mathbf{x})}\\bigg) \\bigg| \\mathbf{X_i = x} \\right] \\\\\n&\\overset{(4)}{=} \\mu_t(\\mathbf{x}) + \\underbrace{\\mathbb{E} \\left[ (Y_i(t) - \\mu(t, \\mathbf{x})) \\bigg(\\frac{\\mathbb{1}(T_i = t) - e_t(\\mathbf{x})}{e_t(\\mathbf{x})}\\bigg) \\bigg| \\mathbf{X_i = x} \\right]}_{\\text{needs to be 0 for the conditional APO to be identified}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-estimator-proof-2",
    "href": "slides/05_dml.html#doubly-robust-estimator-proof-2",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Estimator: Proof",
    "text": "Doubly Robust Estimator: Proof\n\nProof for Equation (4):\nLet \\(\\tilde{\\mu}(t,\\mathbf{x})\\) and \\(\\tilde{e}_{t}(\\mathbf{x})\\) be some candidate functions for the conditional outcome regression and the propensity score, respectively.\n\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ (Y_i(t) - \\tilde{\\mu}(t, \\mathbf{x})) \\bigg(\\frac{\\mathbb{1}(T_i = t) - \\tilde{e}_t(\\mathbf{x})}{\\tilde{e}_t(\\mathbf{x})}\\bigg) \\bigg| \\mathbf{X_i = x} \\right] &= \\mathbb{E} [ (Y_i(t) - \\tilde{\\mu}(t, \\mathbf{x})) \\mid \\mathbf{X_i = x}] \\mathbb{E} \\left[ \\bigg(\\frac{\\mathbb{1}(T_i = t) - \\tilde{e}_t(\\mathbf{x})}{\\tilde{e}_t(\\mathbf{x})}\\bigg) \\bigg| \\mathbf{X_i = x} \\right] \\\\\n&\\text{(ignorability allows to separate expectations)} \\\\\n&= (\\mathbb{E} [ Y_i(t) \\mid \\mathbf{X_i = x}] - \\tilde{\\mu}(t, \\mathbf{x}))   \\bigg(\\frac{\\mathbb{E} [\\mathbb{1}(T_i = t \\mid \\mathbf{X_i = x} ] - \\tilde{e}_t(\\mathbf{x})}{\\tilde{e}_t(\\mathbf{x})}\\bigg)  \\\\\n&= (\\mu_t(\\mathbf{x}) - \\tilde{\\mu}(t, \\mathbf{x})) \\frac{(e_t(\\mathbf{x}) - \\tilde{e}_t(\\mathbf{x}))}{\\tilde{e}_t(\\mathbf{x})} \\\\\n\\end{align*}\n\\]\n\n\nthe last expression becomes 0 if either \\(\\tilde{\\mu}(t, \\mathbf{x}) = \\mu_t(\\mathbf{x})\\) or \\(\\tilde{e}_t(\\mathbf{x}) = e_t(\\mathbf{x})\\)."
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-estimator-theorem",
    "href": "slides/05_dml.html#doubly-robust-estimator-theorem",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Estimator: Theorem",
    "text": "Doubly Robust Estimator: Theorem\n\nAugmentation leads to the following theoretical properties:\n\n\n\n\nTheorem 4.3: “Doubly Robust Estimator”.\n\n\nGiven \\(Y_i(t) \\perp\\!\\!\\!\\perp T_i \\mid \\mathbf{X_i = x}\\) (conditional unconfoundedness) and given \\(0 &lt; P(T_i = t|\\mathbf{X_i = x}), \\forall t\\) (positivity), then:\n\nIf either \\(\\tilde{e}_{t}(\\mathbf{x}) = e_t(\\mathbf{x})\\) or \\(\\tilde{\\mu}(t = 1,\\mathbf{x}) = \\mu_1(\\mathbf{x})\\), then \\(\\mu_{1} = \\mathbb{E}[Y_i(1)]\\)\nIf either \\(\\tilde{e}_{t}(\\mathbf{x}) = e_t(\\mathbf{x})\\) or \\(\\tilde{\\mu}(t = 0,\\mathbf{x}) = \\mu_0(\\mathbf{x})\\), then \\(\\mu_{0} = \\mathbb{E}[Y_i(0)]\\)\nIf either \\(\\tilde{e}_{t}(\\mathbf{x}) = e_t(\\mathbf{x})\\) or \\(\\tilde{\\mu}(t = 1,\\mathbf{x}) = \\mu_1(\\mathbf{x}), \\tilde{\\mu}(t = 0,\\mathbf{x}) = \\mu_0(\\mathbf{x})\\), then \\(\\mu_{1} - \\mu_{0} = \\tau_{\\text{ATE}}\\)\n\n\n\n\n\nwith \\(\\tilde{\\mu}(t,\\mathbf{x})\\) and \\(\\tilde{e}_{t}(\\mathbf{x})\\) being some candidate functions for the conditional outcome regression and the propensity score, respectively."
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-estimator-theorem-1",
    "href": "slides/05_dml.html#doubly-robust-estimator-theorem-1",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Estimator: Theorem",
    "text": "Doubly Robust Estimator: Theorem\n\nProof showing that \\(\\mu_{t} = \\mathbb{E}[Y_i(t)]\\):\n\n\\[\n\\begin{align*}\n\\tilde{\\mu}_{t} - \\mathbb{E}[Y_i(t)] &= \\mathbb{E}\\bigg[\\tilde{\\mu}(t, \\mathbf{x}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\tilde{\\mu}(t, \\mathbf{x}))}{\\tilde{e}_t(\\mathbf{x})} \\bigg] -  \\mathbb{E}[Y_i(t)] &\\text{(by defintion)} \\\\\n&= \\mathbb{E}\\bigg[\\frac{\\mathbb{1}(T_i = t)(Y_i - \\tilde{\\mu}(t, \\mathbf{x}))}{\\tilde{e}_t(\\mathbf{x})} - (Y_i(t) -  \\tilde{\\mu}(t, \\mathbf{x}))\\bigg] &\\text{(linearity of expectations)} \\\\\n&= \\mathbb{E}\\left[\\frac{\\mathbb{1}(T_i = t) - \\tilde{e}_t(\\mathbf{x})}{\\tilde{e}_t(\\mathbf{x})}(Y_i(t) - \\tilde{\\mu}(t, \\mathbf{x}))\\right] &\\text{(combining terms)} \\\\\n&= \\mathbb{E}\\left(\\mathbb{E}\\left[\\frac{\\mathbb{1}(T_i = t) - \\tilde{e}_t(\\mathbf{x})}{\\tilde{e}_t(\\mathbf{x})}(Y_i(t) - \\tilde{\\mu}(t, \\mathbf{x}) \\bigg| \\mathbf{X_i}\\right]\\right) &\\text{(law of iterated expectations)} \\\\\n&= \\mathbb{E}\\left(\\mathbb{E}\\left[\\frac{\\mathbb{1}(T_i = t) - \\tilde{e}_t(\\mathbf{x})}{\\tilde{e}_t(\\mathbf{x})} \\bigg| \\mathbf{X_i}\\right] \\cdot \\mathbb{E}\\left[Y_i(t) - \\tilde{\\mu}(t, \\mathbf{x})  \\bigg| \\mathbf{X_i}\\right]\\right) &\\text{(ignorability allows to separate expectations)} \\\\\n&= \\mathbb{E}\\left( \\frac{(e_t(\\mathbf{x}) - \\tilde{e}_t(\\mathbf{x}))}{\\tilde{e}_t(\\mathbf{x})}(\\mu_t(\\mathbf{x}) - \\tilde{\\mu}(t, \\mathbf{x}))\\right) \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-estimator-sample-version",
    "href": "slides/05_dml.html#doubly-robust-estimator-sample-version",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Estimator: Sample Version",
    "text": "Doubly Robust Estimator: Sample Version\n\nStep 1: obtain the fitted values of the propensity scores:\n\n\\(\\hat{e}_t(\\mathbf{X_i})\\)\n\nStep 2: obtain the fitted values of the outcome regressions:\n\n\\(\\hat{\\mu}(t, \\mathbf{X_i})\\).\n\nStep 3: construct the doubly robust estimator:\n\n\\(\\hat{\\tau}_{\\text{ATE}} = \\hat{\\mu}_{1} - \\hat{\\mu}_{0}\\) with\n\\(\\hat{\\mu}_{1} = \\frac{1}{n} \\sum_{i=1}^n \\left[\\hat{\\mu}(t= 1, \\mathbf{X_i}) + \\frac{\\mathbb{1}(T_i = 1)(Y_i - \\hat{\\mu}(t = 1, \\mathbf{ X_i})}{\\hat{e}_1(\\mathbf{X_i})}\\right]\\)\n\\(\\hat{\\mu}_{0} = \\frac{1}{n} \\sum_{i=1}^n \\left[\\hat{\\mu}(t= 0, \\mathbf{X_i}) + \\frac{\\mathbb{1}(T_i = 0)(Y_i - \\hat{\\mu}(t = 0, \\mathbf{ X_i})}{\\hat{e}_0(\\mathbf{X_i})}\\right]\\)"
  },
  {
    "objectID": "slides/05_dml.html#doubly-robust-estimator-example",
    "href": "slides/05_dml.html#doubly-robust-estimator-example",
    "title": "(5) Double Machine Learning",
    "section": "Doubly Robust Estimator: Example",
    "text": "Doubly Robust Estimator: Example\n\nAssess the impact of participating in the U.S. National Supported Work (NSW) training program targeted to 445 individuals with social and economic problems on their real earnings.\n\n\nlibrary(Matching)                       # load Matching package\ndata(lalonde)                           # load lalonde data\nattach(lalonde)                         # store all variables in own objects\nlibrary(drgee)                          # load drgee package\nT = treat                              # define treatment (training)\nY = re78                                # define outcome \nX = cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates\ndr = drgee(oformula = formula(Y ~ X), eformula = formula(T ~ X), elink=\"logit\") # DR reg\nsummary(dr)                             # show results\n\n\nCall:  drgee(oformula = formula(Y ~ X), eformula = formula(T ~ X), elink = \"logit\")\n\nOutcome:  Y \n\nExposure:  T \n\nCovariates:  Xage,Xeduc,Xnodegr,Xmarried,Xblack,Xhisp,Xre74,Xre75,Xu74,Xu75 \n\nMain model:  Y ~ T \n\nOutcome nuisance model:  Y ~ Xage + Xeduc + Xnodegr + Xmarried + Xblack + Xhisp + Xre74 + Xre75 + Xu74 + Xu75 \n\nOutcome link function:  identity \n\nExposure nuisance model:  T ~ Xage + Xeduc + Xnodegr + Xmarried + Xblack + Xhisp + Xre74 + Xre75 + Xu74 + Xu75 \n\nExposure link function:  logit \n\n  Estimate Std. Error z value Pr(&gt;|z|)  \nT   1674.1      672.4    2.49   0.0128 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Note: The estimated parameters quantify the conditional\nexposure-outcome association, given the covariates\nincluded in the nuisance models)\n\n 445  complete observations used"
  },
  {
    "objectID": "slides/05_dml.html#partially-linear-regression-model",
    "href": "slides/05_dml.html#partially-linear-regression-model",
    "title": "(5) Double Machine Learning",
    "section": "Partially Linear Regression Model",
    "text": "Partially Linear Regression Model\n\nObserved \\(Y_i\\) and \\(T_i\\) are a partially linear function of confounding variables \\(X_i\\): \\(\\begin{align}\\begin{aligned}Y_i = \\tau T_i + g(\\mathbf{X_i}) + \\epsilon_{Y_i}, & &\\mathbb{E}(\\epsilon_{Y_i} | T_i,\\mathbf{X_i}) = 0 \\\\T_i = m(\\mathbf{X_i}) + \\epsilon_{T_i}, & &\\mathbb{E}(\\epsilon_{T_i} | \\mathbf{X_i}) = 0\\end{aligned}\\end{align}\\)\n\n\n\nConditional average potential outcome:\n\n\\(\\mathbb{E}[Y_i(t) | \\mathbf{X_i}] \\overset{(A1, A3)}{=} \\mathbb{E}[Y_i | T_i = t, \\mathbf{X_i}] = \\tau t + g(\\mathbf{X_i})\\)\n\n\n\n\n\nTarget parameters:\n\n\\(\\tau_{\\text{CATE}} = \\mathbb{E}[Y_i | T_i = 1, \\mathbf{X_i}] - \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i}]\\)\n\\(\\tau_{\\text{CATE}} = (\\tau 1 + g(\\mathbf{X_i})) - (\\tau 0 + g(\\mathbf{X_i})) = \\tau\\)\n\\(\\tau_{\\text{ATE}} = \\mathbb{E_X}[\\beta_T] = \\tau\\)\n=&gt; homogeneous treatment effects"
  },
  {
    "objectID": "slides/05_dml.html#identification-under-partial-linearity",
    "href": "slides/05_dml.html#identification-under-partial-linearity",
    "title": "(5) Double Machine Learning",
    "section": "Identification under Partial Linearity",
    "text": "Identification under Partial Linearity\n\nFollowing Robinson (1988), we can write the partially linear regression model as a generalization of the Frisch-Waugh-Lovell theorem:\n\n\\(\\underbrace{Y_i - \\overbrace{\\mathbb{E}[Y_i \\mid \\mathbf{X_i}]}^{\\mu(\\mathbf{X_i})}}_{\\text{outcome residual}} = \\tau \\underbrace{( T_i - \\overbrace{\\mathbb{E}[T_i \\mid \\mathbf{X_i}]}^{e(\\mathbf{X_i})})}_{\\text{treatment residual}} + \\epsilon_{Y_i}\\)\n\n\n\n\n\\(\\tau_{\\text{ATE}}\\) is identified by a residual-on-residual regression without constant:\n\nPopulation estimand:\n\n\\(\\tau_{\\text{ATE}} = \\arg \\min_{\\tilde{\\tau}} \\mathbb{E}[( \\underbrace{ Y_i - \\mu(\\mathbf{X_i})}_{\\text{pseudo outcome}} - \\tilde{\\tau} \\underbrace{( T_i - e(\\mathbf{X_i}))}_{\\text{single regressor}})^2] = \\frac{\\text{Cov}[(Y_i - \\mu(\\mathbf{X_i})) (T_i - e(\\mathbf{X_i}))]}{\\text{Var}[T_i - e(\\mathbf{X_i})]}\\)\n\nSample estimator:\n\n\\(\\hat{\\tau}_{\\text{ATE}} = \\arg \\min_{\\tilde{\\tau}} \\frac{1}{N}\\sum_{i=1}^n ( \\underbrace{Y_i - \\mu(\\mathbf{X_i})}_{\\text{pseudo outcome}} - \\tilde{\\tau} \\underbrace{( T_i - e(\\mathbf{X_i}))}_{\\text{single regressor}})^2 = \\frac{\\sum_{i=1}^n (Y_i - \\mu(\\mathbf{X_i})) (T_i - e(\\mathbf{X_i}))}{\\sum_{i=1}^n (T_i - e(\\mathbf{X_i}))^2}\\)\n\n\n\n\n\n\nHowever, regression not feasible because nuisance parameters unknown: ML toolbox might be useful."
  },
  {
    "objectID": "slides/05_dml.html#double-machine-learning-under-partial-linearity",
    "href": "slides/05_dml.html#double-machine-learning-under-partial-linearity",
    "title": "(5) Double Machine Learning",
    "section": "Double Machine Learning under Partial Linearity",
    "text": "Double Machine Learning under Partial Linearity\n\nChernozhukov et al. (2018) propose a three step procedure:\n\nForm prediction model for the treatment: \\(\\hat{e}(\\mathbf{X_i})\\)\nForm prediction model for the outcome: \\(\\hat{\\mu}(\\mathbf{X_i})\\)\nRun feasible residual-on-residual regression:\n\n\n\\(\\hat{\\tau}_{\\text{ATE}} = \\arg \\min_{\\tilde{\\tau}} \\frac{1}{N}\\sum_{i=1}^n ( Y_i - \\hat{\\mu}(\\mathbf{X_i}) - \\tilde{\\tau} ( T_i - \\hat{e}(\\mathbf{X_i})))^2 = \\frac{\\sum_{i=1}^n (Y_i - \\hat{\\mu}(\\mathbf{X_i})) (T_i - \\hat{e}(\\mathbf{X_i}))}{\\sum_{i=1}^n (T_i - \\hat{e}(\\mathbf{X_i}))^2}\\)\n\n\n\n\nPredictions of nuisance parameters \\(\\hat{e}(\\mathbf{X_i})\\) and \\(\\hat{\\mu}(\\mathbf{X_i})\\) have to fulfill two conditions:\n\nHigh-quality: consistency and convergence rates faster than \\(N^{\\frac{1}{4}}\\).\nOut-of-sample: individual predictions formed without the observation itself.\n\n=&gt; standard (robust) OLS inference is valid (see Chernozhukov et al. (2018))."
  },
  {
    "objectID": "slides/05_dml.html#high-quality-predictions-in-dml",
    "href": "slides/05_dml.html#high-quality-predictions-in-dml",
    "title": "(5) Double Machine Learning",
    "section": "High Quality Predictions in DML",
    "text": "High Quality Predictions in DML\n\nConsistency: ML methods converge to the true nuisance parameters as \\(N \\to \\infty\\).\nConvergence rate:\n\nParametric models like OLS converge at the rate \\(N^{\\frac{1}{2}}\\):\n\nRMSE (\\(\\mathbb{E}[\\sqrt{(\\hat{\\mu}(\\mathbf{X_i}) - \\mu(\\mathbf{X_i}))^2}]\\)) expected to halve if sample increases by factor four\n\nML methods usually do not converge as quickly because they can not leverage the structural information of a parametric model.\nFor Double ML to work, it suffices that the RMSE more than halves if we increase sample size by factor 16 (convergence rate: \\(N^{\\frac{1}{4}}\\)).\nAchievable with popular ML methods like (Post-) LASSO, Random Forests, or Neural Networks ."
  },
  {
    "objectID": "slides/05_dml.html#out-of-sample-predictions-in-dml",
    "href": "slides/05_dml.html#out-of-sample-predictions-in-dml",
    "title": "(5) Double Machine Learning",
    "section": "Out-of-Sample Predictions in DML",
    "text": "Out-of-Sample Predictions in DML\n\n\n\nK-fold Cross-Fitting:\n\nSplit the sample into \\(K\\) folds.\nFor each fold \\(k\\), train a prediction model for the nuisance parameters on the remaining \\(K-1\\) folds.\nPredict the nuisance parameters for fold \\(k\\) using the model trained on the remaining \\(K-1\\) folds.\nRepeat for all \\(K\\) folds to obtain predictions for each individual observation in each fold.\nUse combined predictions for the residual-on-residual regression.\n\n\n\n\n\n\n\n\n\n\n\n=&gt; Predictions are formed without the observation itself, still no waste of information.\n=&gt; Nuisance parameters induce no bias by overfitting (Chernozhukov et al. (2018))."
  },
  {
    "objectID": "slides/05_dml.html#neyman-orthogonal-score-functions",
    "href": "slides/05_dml.html#neyman-orthogonal-score-functions",
    "title": "(5) Double Machine Learning",
    "section": "Neyman-orthogonal Score Functions",
    "text": "Neyman-orthogonal Score Functions\n\nPredicted nuisance parameters have to be used in a Neyman-orthogonal score function (score) \\(\\psi\\)!\n\\(\\psi\\) has to satisfy moment condition \\(\\mathbb{E}[\\psi(Y_i,T_i,\\hat{\\tau}, \\hat{\\mu}(\\mathbf{X_i}), \\hat{e}(\\mathbf{X_i}))] = 0\\) to identify the target parameter \\(\\tau_{\\text{ATE}}\\).\nIn PLR, \\(\\psi\\) is the solution to the minimization problem of the residual-on-residual regression - derivative w.r.t. \\(\\hat{\\tau}\\):\n\n\\[\\begin{align*}\n&\\frac{1}{N} \\sum_{i=1}^N \\underbrace{(Y_i - \\hat{\\mu}(\\mathbf{X_i}) - \\hat{\\tau}(T_i - \\hat{e}(\\mathbf{X_i}))) (T_i - \\hat{e}(X_i))}_{\\psi(Y_i, T_i, \\hat{\\tau}, \\hat{\\mu}(\\mathbf{X_i}), \\hat{e}(\\mathbf{X_i}))} = 0 \\\\\n\\Rightarrow \\hat{\\tau}_{\\text{ATE}} &= \\frac{\\sum_{i=1}^n (Y_i - \\hat{\\mu}(\\mathbf{X_i})) (T_i - \\hat{e}(\\mathbf{X_i}))}{\\sum_{i=1}^n (T_i - \\hat{e}(\\mathbf{X_i}))^2}\n\\end{align*}\\]\n\n\nNeyman-orthogonality of score \\(\\psi(Y_i,T_i,\\hat{\\tau}, \\hat{\\mu}(\\mathbf{X_i}), \\hat{e}(\\mathbf{X_i}))\\):\n\n(Gateaux) derivative of the score function with respect to the nuisance parameters is zero in expectation at the true value of the nuisance parameters:\n\n\\(\\partial_r \\mathbb{E}[\\psi(Y_i, T_i, \\hat{\\tau}, \\mu(\\mathbf{X_i}) + r(\\mu(\\mathbf{X_i}) - \\hat{\\mu}(\\mathbf{X_i})), e(\\mathbf{X_i}) + r(e(\\mathbf{X_i}) - \\hat{e}(\\mathbf{X_i})))]\\mid_{r=0} = 0\\)\n\nEnsures that the \\(\\hat{\\tau}\\) is robust against biases in the prediction of nuisance parameters (e.g. by regularization).\nNote (without proof): residual-on-residual regression fulfills this requirement!"
  },
  {
    "objectID": "slides/05_dml.html#overcoming-regularization-overfitting-bias",
    "href": "slides/05_dml.html#overcoming-regularization-overfitting-bias",
    "title": "(5) Double Machine Learning",
    "section": "Overcoming Regularization & Overfitting Bias",
    "text": "Overcoming Regularization & Overfitting Bias\n\nCompare a non-orthogonal score function, e.g. \\(\\hat{\\tau}_{\\text{ATE}} = \\frac{\\sum_{i=1}^n T_i (Y_i - \\hat{\\mu}(\\mathbf{X_i}))}{\\sum_{i=1}^n T_i^2}\\) to orthogonal one: \\(\\hat{\\tau}_{\\text{ATE}} = \\frac{\\sum_{i=1}^n (Y_i - \\hat{\\mu}(\\mathbf{X_i})) (T_i - \\hat{e}(\\mathbf{X_i}))}{\\sum_{i=1}^n (T_i - \\hat{e}(\\mathbf{X_i}))^2}\\).\n\n\n\n\nCompare with and without K-fold Cross-Fitting.\n\n\n\n\n\n\n\n\n\n\n\n\n# simulating the data\nlibrary(DoubleML)\nset.seed(1234)\nn_rep = 1000 # number samples\nn_obs = 500 # number of observations\nn_vars = 20 # number of covariates\nalpha = 0.5 # true treatment effect\n\n\ndata = list()\nfor (i_rep in seq_len(n_rep)) {\n# command to simulate Y_i and T_i based on true non-linear nuisance functions m(x) and e(x)\n  data[[i_rep]] = make_plr_CCDDHNR2018(alpha=alpha, n_obs=n_obs, dim_x=n_vars,\n                                       return_type=\"data.frame\")\n}\n\n# define custom (non-othogonal) score function\nnon_orth_score = function(y, d, l_hat, m_hat, g_hat, smpls) {\n  u_hat = y - g_hat\n  psi_a = -1*d*d\n  psi_b = d*u_hat\n  psis = list(psi_a = psi_a, psi_b = psi_b)\n  return(psis)\n}\n\nlibrary(mlr3)\nlibrary(mlr3learners)\n\n# define the ml prediction models from the mlr3 package:\nml_l = lrn(\"regr.ranger\", num.trees = 132, max.depth = 5, mtry = 12, min.node.size = 1) # learner for mu = E[Y|X]\nml_m = lrn(\"regr.ranger\", num.trees = 378, max.depth = 3, mtry = 20, min.node.size = 6) # learner for e = E[T|X]\n\n\n# run the simulation \nfor (i_rep in seq_len(n_rep)) {\n  df = data[[i_rep]]\n  obj_dml_data = double_ml_data_from_data_frame(df, y_col = \"y\", d_cols = \"d\")\n  # key function friom the DoubleML package\n  obj_dml_plr_nonorth = DoubleMLPLR$new(obj_dml_data, # suppy data\n                                        ml_l, ml_m, ml_g,# supply the machine learning methods\n                                        n_folds=2, # no cross fitting at first\n                                        score=non_orth_score, # supply custom score function\n                                        # score='partialling out' # built-in orthogonal score function PLM\n                                        apply_cross_fitting=TRUE) # no cross fitting at first\n  # extract and store estimates for each sample\n  obj_dml_plr_nonorth$fit()\n  this_theta = obj_dml_plr_nonorth$coef\n  this_se = obj_dml_plr_nonorth$se\n  print(abs(theta_nonorth[i_rep] - this_theta))\n  print(abs(se_nonorth[i_rep] - this_se))\n  theta_nonorth[i_rep] = this_theta\n  se_nonorth[i_rep] = this_se\n}"
  },
  {
    "objectID": "slides/05_dml.html#interactive-regression-model",
    "href": "slides/05_dml.html#interactive-regression-model",
    "title": "(5) Double Machine Learning",
    "section": "Interactive Regression Model",
    "text": "Interactive Regression Model\n\nMore general model that relaxes the homogeneous treatment assumption (binary \\(T_i\\) is not additively separable anymore): \\(\\begin{align}\\begin{aligned}Y_i = g(T_i, \\mathbf{X_i}) + \\epsilon_{Y_i}, & &\\mathbb{E}(\\epsilon_{Y_i} | T_i,\\mathbf{X_i}) = 0 \\\\T_i = m(\\mathbf{X_i}) + \\epsilon_{T_i}, & &\\mathbb{E}(\\epsilon_{T_i} | \\mathbf{X_i}) = 0\\end{aligned}\\end{align}\\)\n\n\n\nWe can use the identification results from the Doubly Robust / AIPW estimator:\n\nAverage potential outcome (APO):\n\n\\(\\mu_t^{\\text{AIPW}} = \\mathbb{E}[Y_i(t)] = \\mathbb{E}\\bigg[\\mu(t, \\mathbf{X_i}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\mu(t, \\mathbf{X_i}))}{e_t(\\mathbf{X_i})} \\bigg] \\\\\\)\n\nAverage treatment effect (ATE):\n\n\\(\\tau_{\\text{ATE}}^{\\text{AIPW}} = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}\\bigg[\\mu(1, \\mathbf{X_i}) - \\mu(0, \\mathbf{X_i}) + \\frac{T_i(Y_i - \\mu(1, \\mathbf{X_i}))}{e_1(\\mathbf{X_i})} - \\frac{(1-T_i)(Y_i - \\mu(0, \\mathbf{X_i})}{e_0(\\mathbf{X_i}))} \\bigg]\\)"
  },
  {
    "objectID": "slides/05_dml.html#double-machine-learning-under-aipw",
    "href": "slides/05_dml.html#double-machine-learning-under-aipw",
    "title": "(5) Double Machine Learning",
    "section": "Double Machine Learning under AIPW",
    "text": "Double Machine Learning under AIPW\n\nChernozhukov et al. (2018) propose a three step procedure:\n\nForm prediction model for the treatment: \\(\\hat{e}(\\mathbf{X_i})\\)\nForm prediction model for the outcome: \\(\\hat{\\mu}(T_i, \\mathbf{X_i})\\)\n\nEstimate the APO:\n\n\n\n\\(\\mu_t^{\\text{AIPW}} = \\frac{1}{N}\\sum_{i=1}^n \\bigg(\\hat{\\mu}(t, \\mathbf{X_i}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\hat{\\mu}(t, \\mathbf{X_i}))}{\\hat{e}_t(\\mathbf{X_i})} \\bigg) \\\\\\)\n\n\n\nEstimate the ATE:\n\n\n\n\\(\\tau_{\\text{ATE}}^{\\text{AIPW}} = \\frac{1}{N}\\sum_{i=1}^n \\bigg(\\hat{\\mu}(1, \\mathbf{X_i}) - \\hat{\\mu}(0, \\mathbf{X_i}) + \\frac{T_i(Y_i - \\hat{\\mu}(1, \\mathbf{X_i}))}{\\hat{e}_1(\\mathbf{X_i})} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}(0, \\mathbf{X_i})}{\\hat{e}_0(\\mathbf{X_i}))} \\bigg)\\)\n\n\n\n\nTo obtain a consistent, asymptotically normal and semi-parametrically efficient estimator that allows standard (robust) inference, we need the same three key ingredients:\n\nHigh-quality machine learning methods\nK-fold cross-validation\nNeyman-orthogonal score function: let’s proof this!"
  },
  {
    "objectID": "slides/05_dml.html#dml-aipw-score-function-1",
    "href": "slides/05_dml.html#dml-aipw-score-function-1",
    "title": "(5) Double Machine Learning",
    "section": "DML-AIPW Score Function (1)",
    "text": "DML-AIPW Score Function (1)\n\nAs the score defining the ATE is just the difference between APOs, it inherits ist Neyman orthogonality. Hence let’s focus on the AIPW score of the APO, which is:\n\n\\[\\begin{align*}\n&\\mathbb{E}\\bigg[ \\underbrace{\\mu(t, \\mathbf{X_i}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\mu(t, \\mathbf{X_i}))}{e_t(\\mathbf{X_i})} - \\mu_t^{\\text{AIPW}}}_{\\psi(Y_i, T_i, \\mu(t, \\mathbf{X_i}), e(\\mathbf{X_i}))}\\bigg] = 0 \\\\\n\\Rightarrow \\mu_t^{\\text{AIPW}} = & \\mathbb{E}\\bigg[\\mu(t, \\mathbf{X_i}) + \\frac{\\mathbb{1}(T_i = t)(Y_i - \\mu(t, \\mathbf{X_i}))}{e_t(\\mathbf{X_i})} \\bigg]\n\\end{align*}\\]\n\nNeyman-orthogonality of a score \\(\\psi\\) means that the Gateaux derivative with respect to the nuisance parameters is zero in expectation at the true nuisance parameters (NP). This means:\n\n\\[\\partial_r \\mathbb{E}\\left[\\psi(Y_i, T_i, \\mu + r(\\tilde{\\mu}-\\mu), e + r(\\tilde{e} - e)) \\mid \\mathbf{X_i = x}\\right] |_{r=0} = 0\\]\n\nwhere we suppress the dependencies of NPs and denote by, e.g., \\(\\tilde{\\mu}\\) a value of the outcome nuisance that is different to the true value \\(\\mu\\). We can show this equation holds with the following four steps."
  },
  {
    "objectID": "slides/05_dml.html#dml-aipw-score-function-2",
    "href": "slides/05_dml.html#dml-aipw-score-function-2",
    "title": "(5) Double Machine Learning",
    "section": "DML-AIPW Score Function (2)",
    "text": "DML-AIPW Score Function (2)\n\n\nAdd perturbations to the true nuisance parameters in the score:\n\n\n\\[\n\\begin{align*}\n\\psi&(Y_i, T_i, \\mu + r(\\tilde{\\mu} - \\mu), e + r(\\tilde{e} - e)) \\\\ &= (\\mu + r(\\tilde{\\mu} - \\mu)) + \\frac{ \\mathbb{1}(T_i = t) Y_i}{e + r(\\tilde{e} - e)} - \\frac{\\mathbb{1}(T_i = t) (\\mu + r(\\tilde{\\mu} - \\mu))}{e + r(\\tilde{e} - e)} - \\mu_t^{\\text{AIPW}}\n\\end{align*}\n\\]\n\n\nTake the conditional expectation:\n\n\n\\[\n\\begin{align*}\n&\\mathbb{E}\\left[ \\psi(Y_i, T_i, \\mu + r(\\tilde{\\mu} - \\mu), e + r(\\tilde{e} - e)) \\mid \\mathbf{X_i = x} \\right] \\\\ &= \\mathbb{E}\\left[ (\\mu + r(\\tilde{\\mu} - \\mu)) + \\frac{ \\mathbb{1}(T_i = t) Y_i}{e + r(\\tilde{e} - e)} - \\frac{\\mathbb{1}(T_i = t) (\\mu + r(\\tilde{\\mu} - \\mu))}{e + r(\\tilde{e} - e)} - \\mu_t^{\\text{AIPW}} \\bigg| \\mathbf{X_i = x} \\right] \\\\ &= (\\mu + r(\\tilde{\\mu} - \\mu)) + \\frac{ e\\mu}{e + r(\\tilde{e} - e)} - \\frac{e (\\mu + r(\\tilde{\\mu} - \\mu))}{e + r(\\tilde{e} - e)} - \\mu_t^{\\text{AIPW}}\n\\end{align*}\n\\] - where we use that \\(\\mathbb{E}[\\mathbb{1}(T_i = t)Y_i \\mid \\mathbf{X_i = x}] \\overset{(A3)}{=} \\mathbb{E}[\\mathbb{1}(T_i = t)Y_i(t) \\mid \\mathbf{X_i = x}] \\overset{(A1)}{=} e\\mu\\) and \\(\\mathbb{E}[\\mathbb{1}(T_i = t) \\mid \\mathbf{X_i = x}] = e\\)."
  },
  {
    "objectID": "slides/05_dml.html#dml-aipw-score-function-3",
    "href": "slides/05_dml.html#dml-aipw-score-function-3",
    "title": "(5) Double Machine Learning",
    "section": "DML-AIPW Score Function (3)",
    "text": "DML-AIPW Score Function (3)\n\n\nTake the derivative with respect to \\(r\\):\n\n\n\\[\n\\begin{align*}\n\\frac{\\partial}{\\partial r} &\\mathbb{E}[\\psi(Y_i, T_i, \\mu + r(\\tilde{\\mu} - \\mu), e + r(\\tilde{e} - e)) \\mid X_i = x] \\\\\n&= (\\tilde{\\mu} - \\mu) - \\frac{e\\mu(\\tilde{e} - e)}{(e + r(\\tilde{e} - e))^2} - \\frac{e(\\tilde{\\mu} - \\mu)(e+r(\\tilde{e} - e)) - e(\\mu + r(\\tilde{\\mu} - \\mu))(\\tilde{e} - e)}{(e + r(\\tilde{e} - e))^2}\n\\end{align*}\n\\]\n\n\nEvaluate at the true nuisance values, i.e. set \\(r = 0\\):\n\n\n\\[\n\\begin{align*}\n\\frac{\\partial}{\\partial r} &\\mathbb{E}[\\psi(Y_i, T_i, \\mu + r(\\tilde{\\mu} - \\mu), e + r(\\tilde{e} - e)) \\mid X_i = x] |_{r=0} \\\\\n&= (\\tilde{\\mu} - \\mu) - \\frac{e\\mu(\\tilde{e} - e)}{(e + 0(\\tilde{e} - e))^2} - \\frac{e(\\tilde{\\mu} - \\mu)(e+r(\\tilde{e} - e)) - e(\\mu + 0(\\tilde{\\mu} - \\mu))(\\tilde{e} - e)}{(e + 0(\\tilde{e} - e))^2} \\\\\n&= (\\tilde{\\mu} - \\mu) - \\frac{e\\mu(\\tilde{e} - e)}{e^2} - \\frac{e(\\tilde{\\mu} - \\mu)e - e\\mu(\\tilde{e} - e)}{e^2} \\\\\n&= (\\tilde{\\mu} - \\mu) - \\frac{e\\mu(\\tilde{e} - e)}{e^2} - \\frac{e^2}{e^2}(\\tilde{\\mu} - \\mu) + \\frac{e\\mu(\\tilde{e} - e)}{e^2}\\\\\n&= 0\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/05_dml.html#dml-aipw-example",
    "href": "slides/05_dml.html#dml-aipw-example",
    "title": "(5) Double Machine Learning",
    "section": "DML-AIPW: Example",
    "text": "DML-AIPW: Example\n\nAssess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.\n\n\n# Load required packages\nlibrary(DoubleML)\nlibrary(mlr3)\nlibrary(mlr3learners)\nlibrary(data.table)\n\n# suppress messages during fitting\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n\n# load data as a data.table\ndata = fetch_401k(return_type = \"data.table\", instrument = TRUE)\n\n# Set up basic model: Specify variables for data-backend\nfeatures_base = c(\"age\", \"inc\", \"educ\", \"fsize\",\"marr\", \"twoearn\", \"db\", \"pira\", \"hown\")\n\n# Initialize DoubleMLData (data-backend of DoubleML)\ndata_dml_base = DoubleMLData$new(data,\n                                 y_col = \"net_tfa\", # outcome variable\n                                 d_cols = \"e401\", # treatment variable\n                                 x_cols = features_base) # covariates\n\n# Initialize Random Forrest Learner\nrandomForest = lrn(\"regr.ranger\")\nrandomForest_class = lrn(\"classif.ranger\")\n\n# Random Forest\nset.seed(123)\ndml_irm_forest = DoubleMLIRM$new(data_dml_base,\n                                 ml_g = randomForest,\n                                 ml_m = randomForest_class,\n                                 score = \"ATE\",\n                                 trimming_threshold = 0.01,\n                                 apply_cross_fitting = TRUE,\n                                 n_folds = 5)\n\n# Set nuisance-part specific parameters\ndml_irm_forest$set_ml_nuisance_params(\n    \"ml_g0\", \"e401\", list(max.depth = 6, mtry = 4, min.node.size = 7)) # learner for outcome 0\ndml_irm_forest$set_ml_nuisance_params(\n    \"ml_g1\", \"e401\", list(max.depth = 6, mtry = 3, min.node.size = 5)) # learner for outcome 1\ndml_irm_forest$set_ml_nuisance_params( \n    \"ml_m\", \"e401\", list(max.depth = 6, mtry = 3, min.node.size = 6)) # learner for treatment\n\ndml_irm_forest$fit()\ndml_irm_forest$summary()\n\nEstimates and significance testing of the effect of target variables\n     Estimate. Std. Error t value Pr(&gt;|t|)    \ne401      8206       1106   7.421 1.16e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/05_dml.html#definitions",
    "href": "slides/05_dml.html#definitions",
    "title": "(5) Double Machine Learning",
    "section": "Definitions",
    "text": "Definitions\n\nData and parameters;\n\n\\(W\\) is a set of observed variables; e.g., \\(W = \\{Y, T, X\\}\\).\n\\(\\theta\\) is the target parameter.\n\\(\\eta\\) is a set of nuisance parameters; e.g., \\(\\eta = \\{\\mu(X), e(X)\\}\\).\n\n\n\n\nScore functions \\(\\psi(W, \\tilde{\\theta}, \\tilde{\\eta})\\) must satisfy two properties in Double ML:\n\n\\(\\mathbb{E}[\\psi(W, \\theta, \\eta)] = 0\\): i.e. moment condition with expectation zero if evaluated at true parameters.\n\\(\\partial_r\\mathbb{E}[\\psi(W, \\theta, \\eta + r(\\hat{\\eta} - \\eta))]|_{r=0} = 0\\): i.e. Neyman-orthogonality."
  },
  {
    "objectID": "slides/05_dml.html#examples",
    "href": "slides/05_dml.html#examples",
    "title": "(5) Double Machine Learning",
    "section": "Examples",
    "text": "Examples\n\nMoment condition of the residual-on-residual regression:\n\n\\(\\mathbb{E} \\left[ (Y - \\mu(X) - \\tau (T - e(X))) (T - e(X)) \\right] = 0\\)\n\\(W = (T, X, Y), \\quad \\theta = \\tau, \\quad \\eta = (\\mu(X), e(X))\\)\nwith \\(\\mu(X) := \\mathbb{E}[Y \\mid X]\\) and \\(e(X) := \\mathbb{E}[T \\mid X]\\)\n\n\n\n\nMoment condition of the AIPW-ATE:\n\n\\(\\mathbb{E} \\left[ \\mu(1, X) - \\mu(0, X) + \\frac{T(Y - \\mu(1,X))}{e(X)} - \\frac{(1 - T)(Y - \\mu(0, X))}{1 - e(X)} - \\tau_{ATE} \\right] = 0\\)\n\\(W = (T, X, Y), \\quad \\theta = \\tau_{\\text{ATE}}, \\quad \\eta = (\\mu(1, X), \\mu(0, X), e(X))\\)\nwith \\(\\mu(t,X) := \\mathbb{E}[Y \\mid T = t, X]\\) and \\(e(X) := \\mathbb{E}[T=1 \\mid X]\\)"
  },
  {
    "objectID": "slides/05_dml.html#linear-score-functions",
    "href": "slides/05_dml.html#linear-score-functions",
    "title": "(5) Double Machine Learning",
    "section": "Linear Score Functions",
    "text": "Linear Score Functions\n\nWe will focus on linear score functions that can be represented as follows:\n\n\\(\\psi(W, \\tilde{\\theta}, \\tilde{\\eta}) = \\tilde{\\theta}\\psi_a(W, \\tilde{\\eta}) + \\psi_b(W, \\tilde{\\eta})\\)\n\nsuch that the moment condition can be written as:\n\n\\(\\mathbb{E}[\\psi(W, \\theta, \\eta)] = \\theta \\mathbb{E}[\\psi_a(W, \\eta)] +  \\mathbb{E}[\\psi_b(W, \\eta)] = 0\\)\n\nand the solution is:\n\n\\(\\theta = - \\frac{\\mathbb{E}[\\psi_b(W, \\eta)]}{\\mathbb{E}[\\psi_a(W, \\eta)]}\\)"
  },
  {
    "objectID": "slides/05_dml.html#example-residual-on-residual-regression",
    "href": "slides/05_dml.html#example-residual-on-residual-regression",
    "title": "(5) Double Machine Learning",
    "section": "Example Residual-on-residual Regression",
    "text": "Example Residual-on-residual Regression\n\nMoment condition:\n\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ (Y - \\mu(X) - \\tau(T - e(X)))(T - e(X)) \\right] &= 0 \\\\\n\\mathbb{E} \\left[ (Y - \\mu(X))(T - e(X)) - \\tau(T - e(X))(T - e(X)) \\right] &= 0 \\\\\n\\tau \\mathbb{E} [ \\underbrace{-1(T - e(X))^2}_{\\psi_a} ] + \\mathbb{E} [ \\underbrace{(Y - \\mu(X))(T - e(X))}_{\\psi_b} ] &= 0 \\\\\n\\Rightarrow \\tau = - \\frac{\\mathbb{E}[\\psi_b(W; \\eta)]}{\\mathbb{E}[\\psi_a(W; \\eta)]} = \\frac{\\mathbb{E}[(Y - \\mu(X))(T - e(X))]}{\\mathbb{E}[(T - e(X))^2]}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/05_dml.html#example-aipw-ate",
    "href": "slides/05_dml.html#example-aipw-ate",
    "title": "(5) Double Machine Learning",
    "section": "Example AIPW-ATE",
    "text": "Example AIPW-ATE\n\nMoment condition:\n\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ \\mu(1, X) - \\mu(0, X) + \\frac{T(Y - \\mu(1, X))}{e(X)} - \\frac{(1 - T)(Y - \\mu(0, X))}{1 - e(X)} - \\tau_{\\text{ATE}} \\right] &= 0 \\\\\n\\tau_{\\text{ATE}} \\underbrace{(-1)}_{\\psi_a} + \\mathbb{E} \\bigg[ \\underbrace{\\mu(1, X) - \\mu(0, X) + \\frac{T(Y - \\mu(1, X))}{e(X)} - \\frac{(1 - T)(Y - \\mu(0, X))}{1 - e(X)}}_{\\psi_b} \\bigg] &= 0 \\\\\n\\Rightarrow \\tau_{\\text{ATE}} = -\\frac{\\mathbb{E}[\\psi_b(W; \\eta)]}{\\mathbb{E}[\\psi_a(W; \\eta)]} = \\mathbb{E} \\left[ \\mu(1, X) - \\mu(0, X) + \\frac{T(Y - \\mu(1, X))}{e(X)} - \\frac{(1 - T)(Y - \\mu(0, X))}{1 - e(X)} \\right]\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/05_dml.html#double-ml-recipe",
    "href": "slides/05_dml.html#double-ml-recipe",
    "title": "(5) Double Machine Learning",
    "section": "Double ML Recipe",
    "text": "Double ML Recipe\n\nFind Neyman-orthogonal score for your target parameter:\n\ncan be constructed (see Chernozhukov et al. (2018), Section 2)\n\nPredict nuisance parameters \\(\\hat{\\eta}\\) with cross-fitted high-quality ML.\nSolve empirical moment condition to estimate the target parameter:\n\n\\(\\theta = - \\frac{\\mathbb{E}[\\psi_b(W, \\eta)]}{\\mathbb{E}[\\psi_a(W, \\eta)]}\\)\n\nCalculate standard error:\n\n\\(\\hat{\\sigma}^2 = \\frac{N^{-1} \\sum_{i} \\psi(W_i; \\hat{\\theta}, \\hat{\\eta}_i)^2}{[N^{-1} \\sum_{i} \\psi_a(W_i; \\hat{\\eta}_i)]^2} \\quad \\Rightarrow \\quad \\text{se}(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\sigma}^2}{N}}\\)\nTo calculate t-values, confidence intervals, etc.\nCan be motivated by the concept of influence functions."
  },
  {
    "objectID": "slides/05_dml.html#standard-errors-in-dml",
    "href": "slides/05_dml.html#standard-errors-in-dml",
    "title": "(5) Double Machine Learning",
    "section": "Standard Errors in DML",
    "text": "Standard Errors in DML\n\nInfluence functions:\n\n\\(\\Psi(W; \\theta, \\eta) := - \\mathbb{E} \\left[ \\frac{\\partial \\psi}{\\partial \\theta} \\right]^{-1} \\psi(W; \\theta, \\eta) = - \\mathbb{E}[\\psi_a(W; \\eta)]^{-1} \\psi(W; \\theta, \\eta)\\)\nScaled version of the score with important characteristics:\n\n\\(\\Psi(W_i; \\theta, \\eta_i)\\) measures the influence of an estimator \\(\\theta\\) to infinitesimal changes in the distribution, i.e. of each observation \\(W_i\\)\n\\(\\mathbb{E}[\\Psi(W; \\theta, \\eta)] = \\mathbb{E}[ -\\mathbb{E}[\\psi_a(W; \\eta)]^{-1} \\psi(W; \\theta, \\eta)] = -\\mathbb{E}[\\psi_a(W; \\eta)]^{-1}  \\underbrace{\\mathbb{E}[\\psi(W; \\theta, \\eta)]}_{=0} = 0\\)\n\n\n\n\n\nEstimator distribution and influence function are closely linked:\n\n\\(\\sqrt{N}(\\hat{\\theta} - \\theta) = \\frac{1}{\\sqrt{N}} \\sum_{i} \\psi(W_i; \\theta, \\eta_i) + o_p(1) \\xrightarrow{d} N(0, \\underbrace{\\operatorname{Var}[\\psi(W; \\theta, \\eta)]}_{\\sigma^2})\\)\n\nEstimator variance (suppressing arguments for brevity):\n\n\\(\\sigma^2 = \\text{Var}[\\psi] = \\mathbb{E}[\\psi^2] - \\underbrace{\\mathbb{E}[\\psi]^2}_{=0} = \\mathbb{E}[\\psi^2] = \\mathbb{E}[(\\mathbb{E}[\\psi_a]^{-1} \\psi)^2] = \\mathbb{E}[\\psi_a]^{-2} \\mathbb{E}[\\psi^2] = \\frac{\\mathbb{E}[\\psi^2]}{\\mathbb{E}[\\psi_a]^2}\\)"
  },
  {
    "objectID": "slides/03_exper.html#randomizing",
    "href": "slides/03_exper.html#randomizing",
    "title": "(3) Randomized Experiments",
    "section": "Randomizing",
    "text": "Randomizing\n\n\nRandomized treatment assignment:\n\n\\(P(T_i = t) = \\frac{1}{k}\\) where \\(k\\) is the number of treatment groups / values\n\n\n\n\n\nDefinition 3.1: “Covariate Balance”\n\n\nWe have covariate balance if the distribution of covariates \\(\\mathbf{X}\\) is the same across treatment groups.\nFormally:\n\\(P(\\mathbf{X} | T = t) \\stackrel{d}{=} P(\\mathbf{X} | T = t')\\) for all \\(t, t'\\).\n\\(\\mathbf{X} \\perp\\!\\!\\!\\perp T\\).\n\n\n\n\n\nRandomization implies covariate balance, across all covariates, even unobserved ones."
  },
  {
    "objectID": "slides/03_exper.html#randomizing-association-becomes-causation",
    "href": "slides/03_exper.html#randomizing-association-becomes-causation",
    "title": "(3) Randomized Experiments",
    "section": "Randomizing: “Association becomes Causation”",
    "text": "Randomizing: “Association becomes Causation”\n\n\nPerspective 1a: \"Graphical Models: Backdoor Adjustment\"\n\nLet \\(\\mathbf{X}\\) be a sufficient adjustment including all (un-) observed confounders, hence:\n\n\\(P(Y | do(T = t)) = \\sum_x P(Y | T = t, \\mathbf{X} = \\mathbf{x})P(\\mathbf{X})\\)\n\nBy multiplying by \\(\\frac{P(T = t | \\mathbf{X} = \\mathbf{x})}{P(T = t | \\mathbf{X} = \\mathbf{x})}\\), we get the joint distribution in the numerator:\n\n\\(P(Y | do(T = t)) = \\sum_x \\frac{P(Y | T= t, \\mathbf{X} = \\mathbf{x})P(T = t | \\mathbf{X} = \\mathbf{x})P(x)}{P(T = t | \\mathbf{X} = \\mathbf{x})} = \\sum_x \\frac{P(Y, T, \\mathbf{X})}{P(T = t | \\mathbf{X} = \\mathbf{x})}\\)\n\nNow, we use the important result from randomization that \\(\\mathbf{X} \\perp\\!\\!\\!\\perp T\\):\n\n\\(P(Y | do(T = t)) = \\sum_x \\frac{P(Y, T, \\mathbf{X})}{P(T)}\\)\n\nBy definition of conditional probabilities and marginalization we obtain q.e.d.:\n\n\\(P(Y | do(T = t)) = \\sum_x P(Y, \\mathbf{X} | T = t) = P(Y | T = t)\\)"
  },
  {
    "objectID": "slides/03_exper.html#randomizing-association-becomes-causation-1",
    "href": "slides/03_exper.html#randomizing-association-becomes-causation-1",
    "title": "(3) Randomized Experiments",
    "section": "Randomizing: “Association becomes Causation”",
    "text": "Randomizing: “Association becomes Causation”\n\n\nPerspective 1b: \"Graphical Models: do-Operator\"\n\nall backdoor paths are blocked\ni.e. backdoor adjustment on empty set \\(\\emptyset\\) suffices\n\\(P(Y | \\text{do}(T = t)) = P(Y | T = t)\\)"
  },
  {
    "objectID": "slides/03_exper.html#randomizing-association-becomes-causation-2",
    "href": "slides/03_exper.html#randomizing-association-becomes-causation-2",
    "title": "(3) Randomized Experiments",
    "section": "Randomizing: “Association becomes Causation”",
    "text": "Randomizing: “Association becomes Causation”\n\n\nPerspective 2: \"Potential Outcomes\" (Review & Extension)\"\n\nCausation:\n\n\\(ATE_{cs} = \\mathbb{E}[Y_i(1) - Y_i(0)]\\)\n\nExtend by probability \\(p\\) of being in a subgroup:\n\n\\(ATE_{cs} = p\\underbrace{(\\mathbb{E}[Y_i(1) - Y_i(0)|T_i=1])}_{\\text{ATT}} + (1-p)\\underbrace{(\\mathbb{E}[Y_i(1) - Y_i(0)|T_i=0])}_{\\text{ATU}}\\)\n\\(ATE_{cs} = p\\mathbb{E}[Y_i(1)|T_i=1] - p\\mathbb{E}Y_i(0)|T_i=1] + (1-p)\\mathbb{E}[Y_i(1)|T_i=0] - (1-p)\\mathbb{E}Y_i(0)|T_i=0]\\)\n\\(ATE_{cs} = p\\mu_{11} - p\\mu_{01} + (1-p)\\mu_{10} - (1-p)\\mu_{00}\\)\n\nAssociation:\n\n\\(ATE_{as} = \\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0] = \\mathbb{E}[Y_i(1)|T_i=1] - \\mathbb{E}[Y_i(0)|T_i=0] = \\mu_{11} - \\mu_{00}\\)\n\nAdd & subtract ATE:\n\n\\(ATE_{as} = \\color{#00C1D4}{ATE} + \\mu_{11} - \\mu_{00} - \\color{#00C1D4}{p\\mu_{11} + p\\mu_{01} - (1-p)\\mu_{10} + (1-p)\\mu_{00}}\\)\n\nAdd & subtract \\((1-p)\\mu_{01}\\):\n\n\\(ATE_{as} = ATE + \\mu_{11} - \\mu_{00} - p\\mu_{11} + \\underbrace{p\\mu_{01} \\color{#00C1D4}{+ (1-p)\\mu_{01}}}_{=\\mu_{01}} - (1-p)\\mu_{10} + (1-p)\\mu_{00} \\color{#00C1D4}{- (1-p)\\mu_{01}}\\)"
  },
  {
    "objectID": "slides/03_exper.html#randomizing-association-becomes-causation-3",
    "href": "slides/03_exper.html#randomizing-association-becomes-causation-3",
    "title": "(3) Randomized Experiments",
    "section": "Randomizing: “Association becomes Causation”",
    "text": "Randomizing: “Association becomes Causation”\n\n\nPerspective 2: \"Potential Outcomes\" (Review & Extension)\"\n\nRearrange:\n\n\\(ATE_{as} = ATE + \\mu_{01} - \\mu_{00} +  \\underbrace{\\mu_{11} - p\\mu_{11}}_{=(1-p)\\mu_{11}} - (1-p)\\mu_{10} + (1-p)\\mu_{00} - (1-p)\\mu_{01}\\)\n\\(ATE_{as} = ATE + \\mu_{01} - \\mu_{00} +  (1-p)[\\underbrace{\\mu_{11} - \\mu_{01}}_{\\text{ATT}} - \\underbrace{(\\mu_{10} - \\mu_{00})}_{\\text{ATU}}]\\)\n\nTherefore:\n\n\n\n\n\\[\n\\begin{align}\nATE_{as} &= \\underbrace{\\mathbb{E}[Y_i(1) - Y_i(0)]}_{ATE_{cs}} \\\\ &+ \\underbrace{\\mathbb{E}[Y_i(0)|T_i=1] - \\mathbb{E}Y_i(0)|T_i=0]}_{\\text{Confounding Bias}} \\\\ &+ \\underbrace{(1-\\mathbb{E}[T_i])[\\underbrace{\\mathbb{E}[Y_i(1)|T_i=1] - \\mathbb{E}[Y_i(0)|T_i=1]}_{\\text{ATT}} - \\underbrace{(\\mathbb{E}[Y_i(1)|T_i=0] - \\mathbb{E}[Y_i(0)|T_i=0])}_{\\text{ATU}}]}_{\\text{Heterogeneity Bias}}\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/03_exper.html#randomizing-association-becomes-causation-4",
    "href": "slides/03_exper.html#randomizing-association-becomes-causation-4",
    "title": "(3) Randomized Experiments",
    "section": "Randomizing: “Association becomes Causation”",
    "text": "Randomizing: “Association becomes Causation”\n\n\nPerspective 2: \"Potential Outcomes - Exchangeability\" implies \\(\\{Y(1), Y(0)\\} \\perp\\!\\!\\!\\perp T\\).\n\nExchangeability before treatment: \\(\\color{#00C1D4}{\\mathbb{E}[Y_i(0)|T_i=0] = \\mathbb{E}[Y_i(0)|T_i=1] = \\mathbb{E}[Y_i(0)]}\\)\nExchangeability after treatment: \\(\\color{#FF7E15}{\\mathbb{E}[Y_i(1)|T_i=1] = \\mathbb{E}[Y_i(1)|T_i=0] = \\mathbb{E}[Y_i(1)]}\\)\n\n\n\n\n\\[\n\\begin{align}\nATE_{as} &= \\underbrace{\\mathbb{E}[Y_i(1) - Y_i(0)]}_{ATE_{cs}} \\\\ &+ \\underbrace{\\mathbb{E}[Y_i(0)|T_i=1] - \\mathbb{E}Y_i(0)|T_i=0]}_{\\color{#00C1D4}{\\text{Confounding Bias = 0}}} \\\\ &+ \\underbrace{(1-\\mathbb{E}[T_i])[\\underbrace{\\mathbb{E}[Y_i(1)|T_i=1] - \\mathbb{E}[Y_i(0)|T_i=1]}_{\\text{ATT}} - \\underbrace{(\\mathbb{E}[Y_i(1)|T_i=0] - \\mathbb{E}[Y_i(0)|T_i=0])}_{\\text{ATU}}]}_{\\color{#FF7E15}{\\text{Heterogeneity Bias = 0}}}\n\\end{align}\n\\]"
  },
  {
    "objectID": "slides/03_exper.html#identification-of-ate-in-experiments",
    "href": "slides/03_exper.html#identification-of-ate-in-experiments",
    "title": "(3) Randomized Experiments",
    "section": "Identification of ATE in Experiments",
    "text": "Identification of ATE in Experiments\n\nIdentification:\n\nexpressing the inherently unobservable ATE in terms of observable quantities.\nremove confounding and heterogeneity bias by randomization or addional assumptions.  \n\n\n\n\nUsing randomization of \\(T\\), the mean comparison identifies the ATE:\n\n\\(\\tau_{\\text{ATE}} = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]\\)\n\n\n\n\n\nMean comparison in a sample (rather than the population) is given by:\n\n\\(\\hat{\\tau}_{\\text{ATE}} = \\frac{1}{\\sum_i T_i} \\sum_i T_i Y_i - \\frac{1}{\\sum_i (1 - T_i)} \\sum_i (1 - T_i) Y_i\\)"
  },
  {
    "objectID": "slides/03_exper.html#identification-of-ate-in-experiments-example",
    "href": "slides/03_exper.html#identification-of-ate-in-experiments-example",
    "title": "(3) Randomized Experiments",
    "section": "Identification of ATE in Experiments: Example",
    "text": "Identification of ATE in Experiments: Example\n\nExperiment conducted between November 1994 and February 1996:\n\nRandomized access to Job Corps: education program financed by the U.S. Department of Labor that targets disadvantaged individuals aged 16 to 24.\n\n\n\nSource: Schochet, Burghardt, and Glazerman (2001); Schochet, Burghardt, and McConnell (2008).\n\n\nAssess the ATE of the program on the weekly earnings in the fourth year after the assignment among 9.240 individuals.\n\n\nlibrary(causalweight)             # load causalweight package that inclkudes the data\ndata(JC)                          # load JC data\nT=JC$assignment                   # define treatment (assignment to JC)\nY=JC$earny4                       # define outcome (earnings in fourth year)\nmean((Y[T==0]))                   # compute mean earnings in control group\n\n[1] 197.9258\n\nmean(Y[T==1])-mean(Y[T==0])       # compute the ATE \n\n[1] 16.05513"
  },
  {
    "objectID": "slides/03_exper.html#identification-of-cate-in-experiments",
    "href": "slides/03_exper.html#identification-of-cate-in-experiments",
    "title": "(3) Randomized Experiments",
    "section": "Identification of CATE in Experiments",
    "text": "Identification of CATE in Experiments\n\nAlso conditional independence holds in a properly randomized experiment:\n\n\\(\\{Y(1), Y(0)\\} \\perp\\!\\!\\!\\perp T | X\\)  \n\nHence, the Conditional Average Treatment Effect (CATE) is also identified:\n\n\\(\\tau_{\\text{CATE}}(x) = \\mathbb{E}[Y_i(1) - Y_i(0)|X_i=x] = \\mathbb{E}[Y_i|T_i=1, X_i=x] - \\mathbb{E}[Y_i|T_i=0, X_i=x]\\)\n\n\n\n\nNote that we condition on variables that are not affected by the treatment (e.g., pre-treatment covariates \\(X\\))\n\nThis is implied by writing \\(X\\) and not \\(X(T)\\).\n\nWe will learn about estimators of CATEs in an own session on Effect Heterogeneity."
  },
  {
    "objectID": "slides/03_exper.html#effect-identification-by-linear-regression",
    "href": "slides/03_exper.html#effect-identification-by-linear-regression",
    "title": "(3) Randomized Experiments",
    "section": "Effect Identification by Linear Regression",
    "text": "Effect Identification by Linear Regression\n\nATE as mean comparison can also be expressed as a linear regression problem:\nStart with the observed outcome for each i:\n\n\\(Y_i = Y_i(1) * T_i + Y_i(0) * (1 - T_i)\\)\n\\(Y_i = Y_i(0) + (Y_i(1) - Y_i(0)) * T_i\\)\n\n\n\n\nTake the conditional expectation of this expression given T in the population:\n\n\\(\\mathbb{E}[Y_i|T_i] = \\mathbb{E}[Y_i(0) + (Y_i(1) - Y_i(0)) * T_i]\\)\n\\(\\mathbb{E}[Y_i|T_i] = \\mathbb{E}[Y_i(0)|T_i] + ( \\mathbb{E}[Y_i(1)|T_i] - \\mathbb{E}[Y_i(0)|T_i] ) * T_i\\)\n\n\n\n\n\nWith ignorability/ exchangeability we obtain:\n\n\\(\\mathbb{E}[Y_i|T_i] = \\underbrace{\\mathbb{E}[Y_i|T_i = 0]}_{\\beta_0} + \\underbrace{( \\mathbb{E}[Y_i|T_i = 1] - \\mathbb{E}[Y_i|T_i = 0] )}_{\\beta_1} * T_i\\)"
  },
  {
    "objectID": "slides/03_exper.html#effect-identification-by-linear-regression-1",
    "href": "slides/03_exper.html#effect-identification-by-linear-regression-1",
    "title": "(3) Randomized Experiments",
    "section": "Effect Identification by Linear Regression",
    "text": "Effect Identification by Linear Regression\n\n\\(\\epsilon\\) is commonly referred to as error term or residual and formally defined as follows:\n\n\\(\\epsilon_i = Y_i - \\underbrace{(\\beta_0 + \\beta_1 * T_i)}_{\\mathbb{E}[Y_i|T_i]}\\)"
  },
  {
    "objectID": "slides/03_exper.html#estimation-by-linear-regression",
    "href": "slides/03_exper.html#estimation-by-linear-regression",
    "title": "(3) Randomized Experiments",
    "section": "Estimation By Linear Regression",
    "text": "Estimation By Linear Regression\n\nWe obtain the ATE based on linear regression by minimizing the sum of squared residuals in the sample:\n\n\\(\\hat{\\beta_0}, \\hat{\\beta_1} = \\arg \\min_{\\beta_0^*, \\beta_1^*} \\sum_{i=1}^{n} \\underbrace{(Y_i - \\beta_0^* - \\beta_1^* T_i)^2}_{\\epsilon_i}\\)\n\n\n\n\nSolving this minimization problem yields the following parameter estimates:\n\n\\(\\hat{\\beta_1} = \\frac{\\text{Cov}(Y_i, T_i)}{\\text{Var}(T_i)}, \\text{ where}\\)\n\\(\\text{Cov}(Y_i, T_i) = \\frac{1}{n - 1} \\sum_{i=1}^{n} \\left(Y_i - \\frac{1}{n}\\sum_{i=1}^{n}Y_i\\right)\\left(T_i - \\frac{1}{n}\\sum_{i=1}^{n}T_i\\right), \\text{and}\\)\n\\(\\text{Var}(T_i) = \\frac{1}{n - 1} \\sum_{i=1}^{n} \\left(T_i - \\frac{1}{n}\\sum_{i=1}^{n}T_i\\right)^2\\)\n\\(\\hat{\\beta_0} = -\\frac{1}{n}\\sum_{i=1}^{n} Y_i - \\hat{\\beta_1}\\frac{1}{n}\\sum_{i=1}^{n} T_i\\)"
  },
  {
    "objectID": "slides/03_exper.html#properties-of-regression-estimates",
    "href": "slides/03_exper.html#properties-of-regression-estimates",
    "title": "(3) Randomized Experiments",
    "section": "Properties of Regression Estimates",
    "text": "Properties of Regression Estimates\n\nUnbiased: on average, equal to the true parameter values across different samples:\n\n\\(\\mathbb{E}[\\hat{\\beta_1}] = \\beta_1, \\text{ and}\\)\n\\(\\mathbb{E}[\\hat{\\beta_0}] = \\beta_0\\)\n\nConsistent: converges in probability to the true parameter values as sample size increases:\n\n\\(\\hat{\\beta_1} \\xrightarrow{p} \\beta_1, \\text{ and}\\)\n\\(\\hat{\\beta_0} \\xrightarrow{p} \\beta_0\\)\n\nAsymptotically normally distributed: follows a normal distribution across suffciently large samples:\n\n\\(\\sqrt{n}(\\hat{\\beta_1} - \\beta_1) \\xrightarrow{d} \\mathcal{N}(0, \\sigma^2_{\\beta_1}), \\text{ and}\\)\n\\(\\sqrt{n}(\\hat{\\beta_0} - \\beta_0) \\xrightarrow{d} \\mathcal{N}(0, \\sigma^2_{\\beta_0})\\)\n\n\n\n\nNote: We skip the proofs here. They can be found in any introductory econometrics textbook such as Wooldridge (2010): Econometric Analysis of Cross Section and Panel Data (MIT Press) ."
  },
  {
    "objectID": "slides/03_exper.html#inference-goals",
    "href": "slides/03_exper.html#inference-goals",
    "title": "(3) Randomized Experiments",
    "section": "Inference Goals",
    "text": "Inference Goals\n\nQuantifying the precision or uncertainty of the parameter estimates:\n\nWith which error probability can we rule out that the ATE is equal to zero (or some other value we are interested in) in the population, given the ATE estimate in our sample?\nWhat is the range or interval of values that likely includes the ATE in the population, given the finndings in our sample?\nStandard errors (SE): measure the variability of the estimated ATE across different samples\nHypothesis tests: assess whether the estimated ATE is statistically different from zero\nConfidence intervals (CI): provide a range of plausible values for the true ATE"
  },
  {
    "objectID": "slides/03_exper.html#standard-errors",
    "href": "slides/03_exper.html#standard-errors",
    "title": "(3) Randomized Experiments",
    "section": "Standard Errors",
    "text": "Standard Errors\n\nAsymptotic variance of the ATE unknown as it relies on population parameters:\n\n\\(\\text{Var}(\\hat{\\beta_1}) = \\frac{\\mathbb{E}[\\epsilon^2 \\cdot (T_i - \\mathbb{E}[T_i])^2]}{n \\cdot (\\text{Var}(T_i))^2}\\)\n\nStart with a variance estimator of ATE in the sample:\n\n\\(\\widehat{\\text{Var}}(\\hat{\\beta_1}) = \\frac{\\frac{1}{n} \\sum_{i=1}^{n} \\hat{\\epsilon}_i^2 \\cdot \\left( T_i - \\frac{1}{n} \\sum_{i=1}^{n} T_i \\right)^2}{n \\cdot \\left( \\widehat{\\text{Var}}(T_i) \\right)^2}\\) with \\(\\hat{\\epsilon}_i = Y_i - \\hat{\\beta_0} - \\hat{\\beta_1} T_i\\)\n\nStandard error of the ATE estimate:\n\n\\(se(\\hat{\\beta_1}) = \\sqrt{\\widehat{\\text{Var}}(\\hat{\\beta_1})}\\)\n\nObtain the standard normal vs t distribution:\n\n\\(z_1 = \\frac{\\hat{\\beta_1} - \\beta_1}{sd(\\hat{\\beta_1})} \\xrightarrow{d} \\mathcal{N}(0, 1)\\) vs \\(t_1 = \\frac{\\hat{\\beta_1} - \\beta_1}{se(\\hat{\\beta_1})} \\sim t_{n-2}\\)"
  },
  {
    "objectID": "slides/03_exper.html#t-distribution",
    "href": "slides/03_exper.html#t-distribution",
    "title": "(3) Randomized Experiments",
    "section": "t-Distribution",
    "text": "t-Distribution\n\nThe t-distribution is a family of distributions indexed by the degrees of freedom (df):\n\n\\(t_{df} = \\frac{Z}{\\sqrt{V/df}}\\), where \\(Z \\sim \\mathcal{N}(0, 1)\\) and \\(V \\sim \\chi^2(df)\\)\n\nHow likely is a specific t-value computed from a sample if the true ATE in the population is zero?"
  },
  {
    "objectID": "slides/03_exper.html#hypothesis-testing",
    "href": "slides/03_exper.html#hypothesis-testing",
    "title": "(3) Randomized Experiments",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nStep 1: Define the null hypothesis \\(H_0\\) and alternative hypothesis \\(H_1\\): \n\nTwo-sided, undirected test:\n\n\\(H_0\\): \\(\\beta_1 = 0\\) and \\(H_1\\): \\(\\beta_1 \\neq 0\\)\n\nOne-sided, directed test:\n\n\\(H_0\\): \\(\\beta_1 \\leq 0\\) and \\(H_1\\): \\(\\beta_1 &gt; 0\\)\n\\(H_0\\): \\(\\beta_1 \\geq 0\\) and \\(H_1\\): \\(\\beta_1 &lt; 0\\)\n\n\n\n\n\nStep 2: Set the significance level \\(\\alpha\\):\n\nmaximally accepted type I error probability of incorrectly rejecting H0 and accepting H1\n\\(\\alpha = 0.05\\) implies that the error probability must not exceed 5%\nother conventional levels of significance are 0.01 (1%) or 0.1 (10%)"
  },
  {
    "objectID": "slides/03_exper.html#hypothesis-testing-1",
    "href": "slides/03_exper.html#hypothesis-testing-1",
    "title": "(3) Randomized Experiments",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nStep 3: Compute the critical value \\(c\\):\n\nQuantile in the t-distribution that corresponds to \\(\\alpha\\), given \\(H_0\\) is true\nTwo-sided, undirected test and \\(\\alpha = 0.05\\): \\(c = t_{\\alpha/2 = 0.025, 1000-2} = 1.96\\)\nOne-sided, directed test and \\(\\alpha = 0.05\\): \\(c = t_{\\alpha = 0.05, 1000-2} = 1.65\\)\n\n\n\n\nStep 4: Compute the t-statistic and p-value:\n\nTest statistic: \\(t_1 = \\frac{\\hat{\\beta_1} - 0}{se(\\hat{\\beta_1})}\\)\np-value: probability of observing a test statistic as extreme as \\(t_1\\) under the null hypothesis\n\nTwo-sided, undirected test: \\(p = Pr(|A| \\geq |t_1|)\\)\nOne-sided, directed test: \\(p = Pr(A \\geq t_1)\\) or \\(p = Pr(A \\leq t_1)\\)\n\nIn a two-sided, undirected test, verify that:\n\n\\(|t_1| &gt; c\\); \\(p &lt; \\alpha/2\\)\n\nIn a one-sided, directed test, verify that:\n\n\\(t_1 &gt; c\\) or \\(t_1 &lt; -c\\); \\(p &lt; \\alpha\\)"
  },
  {
    "objectID": "slides/03_exper.html#confidence-intervals",
    "href": "slides/03_exper.html#confidence-intervals",
    "title": "(3) Randomized Experiments",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nRange of ATE values such that the true ATE \\(\\beta_1\\) is included with probability \\(1-\\alpha\\), based on the estimated ATE \\(\\hat{\\beta_1}\\) and the standard error \\(se(\\hat{\\beta_1})\\) obtained in the sample\nConstructed in such a way that in the (hypothetical) case that we could draw many samples and construct confidence intervals in all those samples, a share of \\(1-\\alpha\\) confidence intervals would include the true \\(\\beta_1\\) \nTwo-sided confidence interval:\n\n\\(CI = \\hat{\\beta_1} \\pm c \\cdot se(\\hat{\\beta_1})\\)\ne.g. \\(CI = 0.3 \\pm 1.96 \\cdot 0.05 = [0.202, 0.398]\\)\n\nOne-sided confidence interval:\n\n\\(CI = \\hat{\\beta_1} + c \\cdot se(\\hat{\\beta_1})\\)\ne.g. \\(CI = 0.3 - 1.65 \\cdot 0.05 = [0.2175, \\infty]\\)"
  },
  {
    "objectID": "slides/03_exper.html#r-squared",
    "href": "slides/03_exper.html#r-squared",
    "title": "(3) Randomized Experiments",
    "section": "R-squared",
    "text": "R-squared\n\nIn general: percentage of variance in the outcome \\(Y\\) that is explained by all variables in the model:\n\n\\(R^2 = 1 - \\frac{SSR}{SST}\\)\n\\(SSR = \\sum_{i=1}^{n} (Y_i - \\hat{Y_i})^2\\)\n\\(SST = \\sum_{i=1}^{n} (Y_i - \\bar{Y})^2\\)\n\nSpecific case: just one binary treatment variable \\(T\\) in the model:\n\n\\(R^2 = r^2\\) where \\(r\\) is the correlation between \\(Y\\) and \\(T\\)\n\\(R^2 = \\left( \\frac{\\sum_{i=1}^{n} (Y_i - \\bar{Y})(T_i - \\bar{T})}{\\sqrt{\\sum_{i=1}^{n} (Y_i - \\bar{Y})^2} \\cdot \\sqrt{\\sum_{i=1}^{n}(T_i - \\bar{T})^2}} \\right)^2\\)"
  },
  {
    "objectID": "slides/03_exper.html#ate-in-experiments-regression-example",
    "href": "slides/03_exper.html#ate-in-experiments-regression-example",
    "title": "(3) Randomized Experiments",
    "section": "ATE in Experiments: Regression Example",
    "text": "ATE in Experiments: Regression Example\n\nAssess the ATE of the program on the weekly earnings in the fourth year after the assignment among 9.240 individuals.\n\n\nlibrary(causalweight)             # load causalweight package \nlibrary(sandwich)                 # load sandwich package\nlibrary(modelsummary)             # load modelsummary package)\ndata(JC)                          # load JC data\nT=JC$assignment                   # define treatment (assignment to JC)\nY=JC$earny4                       # define outcome (earnings in fourth year)\nols=lm(Y~T)                       # run OLS regression\n# display results\nmodelsummary(ols, vcov = sandwich::vcovHC, \n             estimate = \"est = {estimate} (se = {std.error}, t = {statistic}){stars}\", \n             statistic = \"p = {p.value}, CI = [{conf.low}, {conf.high}]\",\n             gof_map = c(\"r.squared\"))   \n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\nest = 197.926 (se = 3.073, t = 64.416)***\n\n\n\np =\n\n\nT\nest = 16.055 (se = 4.074, t = 3.941)***\n\n\n\np =\n\n\nR2\n0.002"
  },
  {
    "objectID": "slides/03_exper.html#bootstrapping",
    "href": "slides/03_exper.html#bootstrapping",
    "title": "(3) Randomized Experiments",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nBootstrap sampling: \\(B\\) randomly drawn samples of the same size as the original sample, with replacement\nCalculate the ATE in each bootstrap sample via regression\n\n\n\n\n\n\n\nSource: Huber, Martin (2023). Causal analysis: Impact evaluation and Causal Machine Learning with applications in R. MIT Press, 2023.\n\n\nCalculate the standard error by: \\(se(\\hat{\\beta_1}) = \\sqrt{\\frac{1}{B - 1} \\sum_{b=1}^{B} \\left(\\hat{\\beta_1^b} - \\frac{1}{B}\\sum_{b=1}^{B}\\hat{\\beta_1^b}\\right)^2}\\)"
  },
  {
    "objectID": "slides/03_exper.html#ate-in-experiments-bootstrapping-example",
    "href": "slides/03_exper.html#ate-in-experiments-bootstrapping-example",
    "title": "(3) Randomized Experiments",
    "section": "ATE in Experiments: Bootstrapping Example",
    "text": "ATE in Experiments: Bootstrapping Example\n\nAssess the ATE of the program on the weekly earnings in the fourth year after the assignment among 9.240 individuals.\n\n\nlibrary(causalweight)             # load causalweight package \nlibrary(boot)                     # load boot package\ndata(JC)                          # load JC data\nT=JC$assignment                   # define treatment (assignment to JC)\nY=JC$earny4                       # define outcome (earnings in fourth year)\nbootdata=data.frame(Y,T)          # data frame with Y,D for bootstrap procedure\nbs=function(data, indices) {      # defines function bs for bootstrapping\n  dat=data[indices,]              # creates bootstrap sample according to indices \n  coefficients=lm(dat)$coef       # estimates coefficients in bootstrap sample  \n  return(coefficients)            # returns coefficients\n}                                 # closes the function bs  \nset.seed(1)                       # set seed\nresults = boot(data=bootdata, statistic=bs, R=1999) # 1999 bootstrap estimations \nresults                           # displays the results \n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = bootdata, statistic = bs, R = 1999)\n\n\nBootstrap Statistics :\n     original      bias    std. error\nt1* 197.92584  0.02480312    3.013465\nt2*  16.05513 -0.02075945    3.954810\n\ntstat=results$t0[2]/sd(results$t[,2])  # compute the t-statistic\n2*pnorm(-abs(tstat))                   # compute the p-value asssuming standard normal distribution\n\n           T \n4.914718e-05"
  },
  {
    "objectID": "slides/03_exper.html#multivalued-treatments",
    "href": "slides/03_exper.html#multivalued-treatments",
    "title": "(3) Randomized Experiments",
    "section": "Multivalued Treatments",
    "text": "Multivalued Treatments\n\nTreatment can take on discrete values, which can be ordered or unordered:\n\n\\(T = 0, 1, 2, ...\\): 0 = 0 weeks of training, 1 = 1 week of training, 2 = 2 weeks of training, …\n\\(T = A, B, C, ...\\): A = no training, B = IT training, C = management training, …\n\n\n\n\nIndependence assumption can be adapted to hold for any treatment value:\n\n\\(Y_i(0), Y_i(1), Y_i(2), ..., Y_i(J) \\perp\\!\\!\\!\\perp T_i\\)\n\n\n\n\n\nAnalyze the ATEs of each non-zero treatment in a linear regression by including binary dummy variables for each:\n\n\\(\\mathbb{E}[Y_i | T_i] = \\underbrace{\\beta_0}_{E[Y_i | T_i=0]} + \\underbrace{\\beta_1}_{E[Y_i | T_i=1] - E[Y_i | T_i=0]} T_{i1} + \\underbrace{\\beta_2}_{E[Y_i |  T_i=2] - E[Y_i |  T_i=0]} T_{i2} + \\dots + \\underbrace{\\beta_J}_{E[Y_i | T_i=J] - E[Y_i | T_i=0]} T_{iJ}\\)\n\\(T_{ij} = 1\\) if \\(T_i = j\\) and \\(T_{ij} = 0\\) otherwise"
  },
  {
    "objectID": "slides/03_exper.html#multivalued-treatments-example",
    "href": "slides/03_exper.html#multivalued-treatments-example",
    "title": "(3) Randomized Experiments",
    "section": "Multivalued Treatments: Example",
    "text": "Multivalued Treatments: Example\n\nAssess wage expectations (measure in brackets of 500 EUR) of 804 university students based on two-level treatment:\n\ntreatmentinformation: Graph with information on monthly gross private sector earnings shown.\ntreatmentorder: Reversed order of questions about professional and personal preferences (“framing”).\n\n\n\nlibrary(causalweight)             # load causalweight package \ndata(wexpect)                     # load wexpect data\nT1=wexpect$treatmentinformation   # define first treatment (wage information)\nT2=wexpect$treatmentorder         # define second treatment (order of questions)\nY=wexpect$wexpect2                # define outcome (wage expectations) \nols=lm(Y~T1+T2)                   # run OLS regression\n# display results\nmodelsummary(ols, vcov = sandwich::vcovHC, estimate = \"est = {estimate} (se = {std.error}, t = {statistic}){stars}\", statistic = \"p = {p.value}, CI = [{conf.low}, {conf.high}]\", gof_map = c(\"r.squared\"))   \n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\nest = 9.408 (se = 0.159, t = 59.268)***\n\n\n\np =\n\n\nT1\nest = 0.345 (se = 0.243, t = 1.421)\n\n\n\np = 0.156, CI = [-0.132, 0.822]\n\n\nT2\nest = -0.173 (se = 0.234, t = -0.741)\n\n\n\np = 0.459, CI = [-0.633, 0.286]\n\n\nR2\n0.006"
  },
  {
    "objectID": "slides/03_exper.html#continuous-treatments",
    "href": "slides/03_exper.html#continuous-treatments",
    "title": "(3) Randomized Experiments",
    "section": "Continuous Treatments",
    "text": "Continuous Treatments\n\nTreatment can take on many (even infinitely) different values that respect cardinality.\n\ne.g. marketing expenditure in EUR, years of education, …\n\n\n\n\nIndependence assumption to hold for any values of the continuous treatment:\n\n\\(Y_i(t) \\perp\\!\\!\\!\\perp T_i\\)\n\n\n\n\n\nDiscretize a continuous treatment by generating binary indicators for (very small) brackets of values:\n\ne.g. \\(T_{i0} = 0\\) if \\(T_i \\leq 100\\), \\(T_{i1} = 1\\) if \\(100 &lt; T_i \\leq 200\\), …\n\n\n\n\n\nInclude \\(T_i\\) as a continuous variable in the regression model:\n\n\\(\\mathbb{E}[Y_i | T_i] = \\beta_0 + \\beta_1 T_i\\)\nFirst derivative of the expected value of \\(Y_i\\) with respect to \\(T_i\\) reflects the marginal effect of a one-unit increase in \\(T_i\\) on \\(Y_i\\):\n\\(ATE = \\frac{\\partial \\mathbb{E}[Y_i | T_i]}{\\partial T_i} = \\frac{\\partial \\mathbb{E}[Y_i(T_i)]}{\\partial T_i} = \\frac{\\partial \\mathbb{E}[Y_i]}{\\partial T_i} = \\beta_1\\)"
  },
  {
    "objectID": "slides/03_exper.html#continuous-treatments-non-linearity",
    "href": "slides/03_exper.html#continuous-treatments-non-linearity",
    "title": "(3) Randomized Experiments",
    "section": "Continuous Treatments: Non-Linearity",
    "text": "Continuous Treatments: Non-Linearity\n\nLinearity: \\(\\frac{\\partial \\mathbb{E}[Y_i(T_i = t')]}{\\partial T_i} = \\frac{\\partial \\mathbb{E}[Y_i(T_i = t)]}{\\partial T_i}\\) for any \\(t' \\neq t\\) which \\(T_i\\) can take on\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuadratic term in the regression model:\n\n\\(\\mathbb{E}[Y_i | T_i] = \\beta_0 + \\beta_1 T_i + \\beta_2 T_i^2\\)\n\\(ATE = \\frac{\\partial \\mathbb{E}[Y_i | T_i]}{\\partial T_i} = \\beta_1 + 2 \\beta_2 T_i\\)\n\nIncrease model flexibility with higher-order terms (e.g. cubic, …) or non-parametric splines or kernel regression"
  },
  {
    "objectID": "slides/03_exper.html#continuous-treatments-example",
    "href": "slides/03_exper.html#continuous-treatments-example",
    "title": "(3) Randomized Experiments",
    "section": "Continuous Treatments: Example",
    "text": "Continuous Treatments: Example\n\nAssess sales as a function of advertising spending in newspapers on a data set with 200 observations:\n\n\n\n\nlibrary(datarium)                 # load datarium package\nlibrary(np)                       # load np package\ndata(marketing)                   # load marketing data\nT=marketing$newspaper             # define treatment (newspaper advertising)\nY=marketing$sales                 # define outcome (sales)\nresults = npregbw(Y~T)             # kernel regression\n\n\nMultistart 1 of 1 |\nMultistart 1 of 1 |\nMultistart 1 of 1 |\nMultistart 1 of 1 /\nMultistart 1 of 1 |\nMultistart 1 of 1 |\n                   \n\nplot(results, plot.errors.method=\"asymptotic\") # plot regression function\n\n\n\n\n\n\n\n\n\n\nlibrary(datarium)                 # load datarium package\nlibrary(np)                       # load np package\ndata(marketing)                   # load marketing data\nT=marketing$newspaper             # define treatment (newspaper advertising)\nY=marketing$sales                 # define outcome (sales)\nresults = npregbw(Y~T)             # kernel regression\n\n\nMultistart 1 of 1 |\nMultistart 1 of 1 |\nMultistart 1 of 1 |\nMultistart 1 of 1 /\nMultistart 1 of 1 |\nMultistart 1 of 1 |\n                   \n\nplot(results, gradients=TRUE, plot.errors.method=\"asymptotic\") # plot effects"
  },
  {
    "objectID": "slides/03_exper.html#including-covariates",
    "href": "slides/03_exper.html#including-covariates",
    "title": "(3) Randomized Experiments",
    "section": "Including Covariates",
    "text": "Including Covariates\n\nGiven successful randomization, there is no need to include covariates in the estimation of the ATE.\nHowever, including covariates can reduce variance and thus uncertainty in the estimation of the ATE.\n\\(Y_i = \\underbrace{\\hat{\\beta_0} + \\hat{\\beta}_1 T_i + \\hat{\\beta}_{X_1} X_{i1} + \\dots + \\hat{\\beta}_{X_K} X_{iK}}_{\\hat{E}[Y_i | T_i, X_i]} + \\hat{\\epsilon}_i\\)\n\\(R^2 = \\frac{\\text{Var}(\\hat{E}[Y_i | T_i, X_i])}{\\text{Var}(Y_i)}\\) gets larger while \\(\\frac{\\text{Var}(\\hat{\\epsilon}_i)}{\\text{Var}(Y_i)}\\) gets smaller with the inclusion of covariates.\nThis further reduces the standard error of the ATE estimate \\(se(\\hat{\\beta}_1)\\)."
  },
  {
    "objectID": "slides/03_exper.html#including-covariates-1",
    "href": "slides/03_exper.html#including-covariates-1",
    "title": "(3) Randomized Experiments",
    "section": "Including Covariates",
    "text": "Including Covariates\n\n\n\nPre-treatment covariates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost-treatment covariates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nControlling for post-treatment covariates is a bad idea:\n\n\nthey condition away part of the treatment effect\n\n\nthey introduce association between \\(T\\) and \\(U\\) as colliders and thus harm randomization."
  },
  {
    "objectID": "slides/03_exper.html#including-covariates-example",
    "href": "slides/03_exper.html#including-covariates-example",
    "title": "(3) Randomized Experiments",
    "section": "Including Covariates: Example",
    "text": "Including Covariates: Example\n\nAssess the awareness about environmental issues of 522 university students after randomly receiving or not receiving a leaflet with information about the environmental and social implications of coffee production.\n\n\nlibrary(causalweight)             # load causalweight package \nlibrary(sandwich)                 # load sandwich package\ndata(coffeeleaflet)               # load coffeeleaflet data\nattach(coffeeleaflet)             # store all variables in own objects\nT=c(coffeeleaflet$treatment)         # define treatment (leaflet)\nY=c(coffeeleaflet$awarewaste)                      # define outcome (aware of waste production)\nX=cbind(coffeeleaflet$mumedu,coffeeleaflet$sex)               # define covariates (grade, gender, age)\nols=lm(Y~T+X)                     # run OLS regression\nmodelsummary(ols, vcov = sandwich::vcovHC, estimate = \"est = {estimate} (se = {std.error}, t = {statistic}){stars}\", statistic = \"p = {p.value}, CI = [{conf.low}, {conf.high}]\", gof_map = c(\"r.squared\"))  \n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\nest = 1.187 (se = 0.249, t = 4.770)***\n\n\n\np =\n\n\nT\nest = 0.332 (se = 0.096, t = 3.449)***\n\n\n\np =\n\n\nX1\nest = 0.272 (se = 0.090, t = 3.007)**\n\n\n\np = 0.003, CI = [0.094, 0.450]\n\n\nX2\nest = 0.137 (se = 0.100, t = 1.370)\n\n\n\np = 0.171, CI = [-0.060, 0.333]\n\n\nR2\n0.046"
  },
  {
    "objectID": "slides/01_intro.html#learning-goals",
    "href": "slides/01_intro.html#learning-goals",
    "title": "(1) Introduction to Causal Inference",
    "section": "Learning Goals",
    "text": "Learning Goals\n\n\nUnderstand the difference between “correlation” and “causation”\nUnderstand the shortcomings of current correlation-based approaches\nDevelop causal knowledge relevant for specific data-driven decisions\nFormalize intuition about causal relationships using a “language” of causality\nDerive causal hypotheses that can be tested with data\nDiscuss the conceptual ideas behind state-of-the-art causal data science tools and algorithms\nCarry out causal data analyses with state-of-the-art tools"
  },
  {
    "objectID": "slides/01_intro.html#map-of-causality",
    "href": "slides/01_intro.html#map-of-causality",
    "title": "(1) Introduction to Causal Inference",
    "section": "Map of Causality",
    "text": "Map of Causality\n\n\nSource: https://towardsdatascience.com (2023)."
  },
  {
    "objectID": "slides/01_intro.html#preliminary-schedule",
    "href": "slides/01_intro.html#preliminary-schedule",
    "title": "(1) Introduction to Causal Inference",
    "section": "Preliminary Schedule",
    "text": "Preliminary Schedule\n\n\n\nSession\nDate\nTopic\n\n\n\n\n1\nApril 15 & 16\nIntroduction to Causal Inference\n\n\n2\nApril 22 & 21\nGraphical Causal Models\n\n\n3\nApril 29 & 30\nRandomized Experiments\n\n\n4\nMay 6 & 7\nObserved Confounding\n\n\n5\nMay 13 & 14\nDouble Machine Learning\n\n\n-\nMay 20 & 21\nHoliday\n\n\n6\nMay 27 & 28\nEffect Heterogeneity\n\n\n7\nJune 3 & 4\nUnobserved Confounding & Instrumental Variables\n\n\n8\nJune 10 & 11\nDifference-in-Difference\n\n\n9\nJune 17 & 18\nSynthetic Control\n\n\n10\nJune 24 & 25\nRegression Discontinuity\n\n\n11\nJuly 1 & 2\nCausal Mediation\n\n\n12\nJuly 8 & 9\nFurther Topics in Causal Machine Learning"
  },
  {
    "objectID": "slides/01_intro.html#course-structure",
    "href": "slides/01_intro.html#course-structure",
    "title": "(1) Introduction to Causal Inference",
    "section": "Course Structure",
    "text": "Course Structure\n\nLecture - Causal Data Science: Monday, 11.30 - 13.00, Building D, Room D - 1.023\nLab - Business Analytics with Causal Data Science: Tuesday, 15.00 - 16.30, Building O, Room O - 0.007\n\n\n\nExamination: 10 challenges related to each topic documented in a lab journal\n\n\n\nContact: Oliver Mork (oliver.mork@tuhh.de)"
  },
  {
    "objectID": "slides/01_intro.html#course-literature",
    "href": "slides/01_intro.html#course-literature",
    "title": "(1) Introduction to Causal Inference",
    "section": "Course Literature",
    "text": "Course Literature\n\nPrimary:Secondary:\n\n\n\nDing, Peng (2023). A First Course in Causal Inference. arXiv preprint arXiv:2305.18793.\nFacure, Matheus (2023). Causal Inference in Python - Applying Causal Inference in the Tech Industry. O’Reilly Media.\nHuber, Martin (2023). Causal analysis: Impact evaluation and Causal Machine Learning with applications in R. MIT Press, 2023.\nNeal, Brady (2020). Introduction to causal inference from a Machine Learning Perspective. Course Lecture Notes (draft).\n\n\n\n\nAngrist, J. D., & Pischke, J. S. (2014). Mastering metrics: The path from cause to effect. Princeton university press.\nCunningham, Scott (2021). Causal Inference: The Mixtape, New Haven: Yale University Press.\nGertler, Paul J., et al. (2016). Impact evaluation in practice. World Bank Publications.\nHernán Miguel A., and Robins James M. (2020). Causal Inference: What If. Boca Raton: Chapman & Hall/CRC.\nHuntington-Klein, Nick (2021). The effect: An introduction to research design and causality. Chapman and Hall/CRC.\nImbens, G. W., & Rubin, D. B. (2015). Causal inference in statistics, social, and biomedical sciences. Cambridge University Press.\nMullainathan, Sendhil, and Jann Spiess. (2017). Machine Learning: An Applied Econometric Approach. Journal of Economic Perspectives, 31(2): 87–106.\nPearl, Judea, and Dana Mackenzie (2018). The Book of Why. Basic Books, New York, NY.\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell (2016). Causal Inference in Statistics: A Primer. John Wiley & Sons, Inc., New York, NY.\nPeters, Jonas, Dominik Janzing, and Bernhard Schölkopf (2017). Elements of causal inference: foundations and learning algorithms. The MIT Press."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation",
    "href": "slides/01_intro.html#causality-vs.-correlation",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\nCausality is central to human knowledge.\nTwo famous quotes from ancient Greeks:\n\n“I would rather discover one causal law than be King of Persia.” (Democritus)\n“We do not have knowledge of a thing until we grasped its cause.” (Aristotle) \n\nHowever:\n\nClassic statistics is about association rather than causation.\nMachine learning is about prediction rather than causation."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-1",
    "href": "slides/01_intro.html#causality-vs.-correlation-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\n“Correlation does not imply causation.”\n“You can not prove causality with statistics.” \nBut statistics is crucial for understanding causality:\n\nFormal language for causal inference.\nMethods to estimate causal effects."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-2",
    "href": "slides/01_intro.html#causality-vs.-correlation-2",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\n\nSource: https://hbr.org/2021/11/leaders-stop-confusing-correlation-with-causation."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-3",
    "href": "slides/01_intro.html#causality-vs.-correlation-3",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\n\nSource: https://www.tylervigen.com/spurious- correlations."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-4",
    "href": "slides/01_intro.html#causality-vs.-correlation-4",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\n\n\n\n\n\nSource: Peters, Jonas. 2015. Causality: Lecture Notes, ETH Zurich."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-5",
    "href": "slides/01_intro.html#causality-vs.-correlation-5",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\nCorrelation, or better association, is not (entirely) causation, if there is confounding association due to a common cause, i.e. a confounder.\nE.g. drinking the night before is a common cause of sleeping with shoes on and of waking up with a headache:\n\n \n\nSource: Neal, Brady (2020). Introduction to causal inference from a Machine Learning Perspective. Course Lecture Notes (draft)."
  },
  {
    "objectID": "slides/01_intro.html#causality-vs.-correlation-6",
    "href": "slides/01_intro.html#causality-vs.-correlation-6",
    "title": "(1) Introduction to Causal Inference",
    "section": "Causality vs. Correlation",
    "text": "Causality vs. Correlation\n\nCorrelation, or better association, is not (entirely) causation, if there is confounding association due to a common cause, i.e. a confounder.\nE.g. Consumers’ purchase intent is a common cause of the amount spent on search engine marketing (SEM) (esp. for branded vs. non-branded ads) and sales (especially for frequent consumers):\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\n\ncoord_dag &lt;- list(\n  x = c(SEM = 0, Intent = 1, Sales = 2),\n  y = c(SEM = 0, Intent = 1, Sales = 0)\n)\n\ndag &lt;- ggdag::dagify(SEM ~ Intent,\n                     Sales ~ SEM,\n                     Sales ~ Intent,\n                     coords = coord_dag)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(colour = \"grey\") +\n  geom_dag_edges() +\n  geom_dag_text(colour = \"black\", size = 5) +\n  theme_dag(legend.position = \"none\")\n\n\n\n\n(Source: Blake et al. (2015). Consumer heterogeneity and paid search effectiveness: A large‐scale field experiment. Econometrica, 83(1), 155-174.)"
  },
  {
    "objectID": "slides/01_intro.html#motivating-example-gender-pay-gap-1",
    "href": "slides/01_intro.html#motivating-example-gender-pay-gap-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Motivating Example: Gender Pay Gap (1)",
    "text": "Motivating Example: Gender Pay Gap (1)\n- Reported by The New York Times in March 2019:\n      “When Google conducted a study recently to determine whether\n      the company was underpaying women and minority groups, it found\n      that men were paid less money than women for doing similar work.”\n\n(Source: https://www.nytimes.com/2019/03/04/technology/google-gender-pay-gap.html)\n\n\nThe study led Google to increase the pay of its male employees to fight this blatant discrimination of men.\nWhat’s going on here? Wasn’t Google just recently accused of discriminating against women, not men?\n\n      “Department of Labor claims that Google systematically underpays its\n      female employees.”\n\n(Source: https://www.theverge.com/2017/4/8/15229688/department-of-labor-google-gender-pay-gap)"
  },
  {
    "objectID": "slides/01_intro.html#motivating-example-gender-pay-gap-2",
    "href": "slides/01_intro.html#motivating-example-gender-pay-gap-2",
    "title": "(1) Introduction to Causal Inference",
    "section": "Motivating Example: Gender Pay Gap (2)",
    "text": "Motivating Example: Gender Pay Gap (2)\n\nSuppose we collected data on wages payed to 100 women and 100 men in company X.\nWe observe the following average monthly salaries for women and men in management and non-management positions (case numbers in parentheses):\n\n\n\n\n\nWomen\nMen\n\n\n\n\n\nNon-management:\n$3,163.30 (87)\n$3,015.18 (59)\n\n\n\nManagement:\n$5,592.44 (13)\n$5,319.82 (41)\n\n\n\n\n\n\nOur goal is to estimate the magnitude of the gender pay gap in company X. How should we tackle this problem?"
  },
  {
    "objectID": "slides/01_intro.html#motivating-example-gender-pay-gap-3",
    "href": "slides/01_intro.html#motivating-example-gender-pay-gap-3",
    "title": "(1) Introduction to Causal Inference",
    "section": "Motivating Example: Gender Pay Gap (3)",
    "text": "Motivating Example: Gender Pay Gap (3)\n\nOn average, women earn less in this example: \\[\n   \\left(\\frac{87}{100} \\cdot \\$3163.30\\right) + \\left(\\frac{13}{100} \\cdot \\$5592.44\\right) -\n   \\left(\\frac{59}{100} \\cdot \\$3015.18\\right) + \\left(\\frac{41}{100} \\cdot \\$5319.82\\right) \\\\\n   \\approx -\\$481\n\\]\nBut in each subcategory women actually have higher salaries:\n\n  - Non- Management: \\(\\$3163.30 - \\$3015.18 = \\$148.12\\)\n  - Management: \\(\\$5592.44 - \\$5319.82 = \\$272.62\\)\n\nConditioning on job position gives the adjusted gender pay gap:\n\n\\[\n   \\left(\\frac{87 + 59}{200} \\cdot \\$148.12\\right) + \\left(\\frac{13 + 41}{200} \\cdot \\$272.62\\right) \\approx \\$181.74\n\\]\n\nWhich estimate gives us a more accurate picture of the gender pay gap?"
  },
  {
    "objectID": "slides/01_intro.html#motivating-example-gender-pay-gap-4",
    "href": "slides/01_intro.html#motivating-example-gender-pay-gap-4",
    "title": "(1) Introduction to Causal Inference",
    "section": "Motivating Example: Gender Pay Gap (4)",
    "text": "Motivating Example: Gender Pay Gap (4)\n\n\nShow code\ndata &lt;- data.frame(\n  Salary = c(5319.82, 3015.18, 5592.44, 3163.30, 3960.08, 3479.09),\n  Position = c(\"Management\", \"Non-Management\", \"Management\", \"Non-Management\", \"All Positions\", \"All Positions\"),\n  Gender = c(\"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Female\")\n)\n\nlibrary(ggplot2)\n\ndata |&gt; \n  ggplot(aes(x=Gender, y=Salary, group=Position, colour=Position)) +\n  geom_line() + geom_point() + \n  theme_bw()"
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-1",
    "href": "slides/01_intro.html#simpsons-paradox-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (1)",
    "text": "Simpson’s Paradox (1)\n\nThe phenomenon that a statistical association, which holds in a population, can be reversed in every subpopulation is named after the British statistician Edward Simpson.\nSimpson’s paradox well-known, for example, in epidemiology and labor economics.\nIn the gender pay gap example, the unadjusted gender pay (- $481) gap gives the right answer.\n\n\n\nBut what about this example?\n\n\n\n\n\nHealthy Lifestyle\nUnhealthy Lifestyle\n\n\n\n\n\nNon-management:\n$3,163.30 (87)\n$3,015.18 (59)\n\n\n\nManagement:\n$5,592.44 (13)\n$5,319.82 (41)"
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-2",
    "href": "slides/01_intro.html#simpsons-paradox-2",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (2)",
    "text": "Simpson’s Paradox (2)\n\n\nHere, we would correctly infer that people with a healthy lifestyle earn more on average ($181.74)."
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-3",
    "href": "slides/01_intro.html#simpsons-paradox-3",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (3)",
    "text": "Simpson’s Paradox (3)\n\nWhat is the difference between the two examples?\n\n\n\n\n\nShow code\nlibrary(ggdag)\n\ncoord_dag &lt;- list(\n  x = c(Gender = 0, Management = 1, Salary = 2),\n  y = c(Gender = 0, Management = 1, Salary = 0)\n)\n\ndag &lt;- ggdag::dagify(Management ~ Gender,\n                     Salary ~ Gender,\n                     Salary ~ Management,\n                     coords = coord_dag)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(colour = \"grey\") +\n  geom_dag_edges() +\n  geom_dag_text(colour = \"black\", size = 5) +\n  theme_dag(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nManagement as “mediator”\n\n\n\n\nShow code\nlibrary(ggdag)\n\ncoord_dag &lt;- list(\n  x = c(Lifestyle = 0, Management = 1, Salary = 2),\n  y = c(Lifestyle = 0, Management = 1, Salary = 0)\n)\n\ndag &lt;- ggdag::dagify(Lifestyle ~ Management,\n                     Salary ~ Lifestyle,\n                     Salary ~ Management,\n                     coords = coord_dag)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_point(colour = \"grey\") +\n  geom_dag_edges() +\n  geom_dag_text(colour = \"black\", size = 5) +\n  theme_dag(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nManagement as “confounder”"
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-4",
    "href": "slides/01_intro.html#simpsons-paradox-4",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (4)",
    "text": "Simpson’s Paradox (4)\n\nStatistics alone doesn’t help us to answer this question.\nNote that the joint distribution of salaries is the same in both cases.\nBoth problems are thus identical from a statistical point of view.\nInstead, we need to make causal assumptions in order to come to a conclusion here:\n\nGender affects both a person’s salary level and job position.\nWhereas lifestyle affects salaries, but is itself affected by a person’s job position.\n\nAfter the course you will know how to incorporate this kind of causal knowledge in your analysis in order to solve all sorts of practical problems of causal inference."
  },
  {
    "objectID": "slides/01_intro.html#simpsons-paradox-5",
    "href": "slides/01_intro.html#simpsons-paradox-5",
    "title": "(1) Introduction to Causal Inference",
    "section": "Simpson’s Paradox (5)",
    "text": "Simpson’s Paradox (5)\n\n\nSource: https://rpubs.com/lakenp/simpsonsparadox."
  },
  {
    "objectID": "slides/01_intro.html#experimentalists-view-of-causal-inference",
    "href": "slides/01_intro.html#experimentalists-view-of-causal-inference",
    "title": "(1) Introduction to Causal Inference",
    "section": "Experimentalists’ View of Causal Inference",
    "text": "Experimentalists’ View of Causal Inference\n\n“No causation without manipulation.” (Rubin, 1975; Holland, 1986)\n(Thought) Experiments with manipulation; also called intervention or treatment.\nTreatments can be binary, continuous, or multi-valued.\nExamples:\n\ntake a drug vs. don’t take a drug\nparticipate in a training program A vs B vs. don’t participate\namount of money spent on advertising\nchange race of job applicants? Resumes with African-American- or White-sounding names (Bertrand and Mullainathan, 2004).\nlevel of neuroticism?\n\nThe potential outcomes framework (Neyman, 1923; Rubin, 1974) is a way to formalize this idea."
  },
  {
    "objectID": "slides/01_intro.html#formal-notation-of-potential-outcomes",
    "href": "slides/01_intro.html#formal-notation-of-potential-outcomes",
    "title": "(1) Introduction to Causal Inference",
    "section": "Formal Notation of Potential Outcomes",
    "text": "Formal Notation of Potential Outcomes\n\n\\(n\\) experimental units indexed by \\(i = 1, . . . , n\\)\n\\(Y\\) is the outcome of interest.\n\\(T_i\\) is the (random) treatment variable for unit \\(i\\).\n\nAssume it can take two levels: \\(t_i = 1\\) for treatment and \\(t_i = 0\\) for control.\n\n\\(Y_i(1)\\) is the potential outcome for unit \\(i\\) if unit \\(i\\) receives treatment.\n\\(Y_i(0)\\) is the potential outcome for unit \\(i\\) if unit \\(i\\) does not receive treatment. \nThe Individual Treatment Effect (ITE) for unit \\(i\\) is defined as:\n\n\\(\\tau_i = Y_i(1) - Y_i(0) \\quad \\forall \\quad i = 1, . . . , n\\)."
  },
  {
    "objectID": "slides/01_intro.html#assumptions-in-the-po-framework-1",
    "href": "slides/01_intro.html#assumptions-in-the-po-framework-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Assumptions in the PO Framework (1)",
    "text": "Assumptions in the PO Framework (1)\nFor the potential outcomes and the ITE to be precisely defined, we need to make an initial set of assumptions:\n\n\n\nAssumption 1: “No Interference”\n\n\nUnit i’s potential outcomes do not depend on other units’ treatments.\n\\(Y_i(t_1,...,t_{i-1},t_i,t_{i+1},...t_n) = Y_i(t_i)\\)\n\n\n\n\n\n\nAssumption 2: “Consistency.”\n\n\nThere are no other versions of the treatment. Equivalently, we require that the treatment levels be well-defined, or have no ambiguity at least for the outcome of interest. If the treatment is \\(T\\), then the observed outcome \\(Y\\) is the potential outcome under treatment \\(T\\).\nFormally, \\(T = t  =&gt; Y = Y(t)\\) or equivalently \\(Y = Y(T)\\)\n\n\n\n\n\n\nAssumption 3: “Stable Unit Treatment Value Assumption (SUTVA).”\n\n\nBoth Assumptions 1 and 2 hold: \\(Y_i = Y(T_i)\\)"
  },
  {
    "objectID": "slides/01_intro.html#fundamental-problem-of-causal-inference",
    "href": "slides/01_intro.html#fundamental-problem-of-causal-inference",
    "title": "(1) Introduction to Causal Inference",
    "section": "Fundamental Problem of Causal Inference",
    "text": "Fundamental Problem of Causal Inference\n\nTypically, only one of those outcomes is actually observed for unit \\(i\\):\n\n\\(Y_i = T_iY_i(1) + (1 − T_i)Y_i(0)\\).\n\nThe other one remains unobserved or counterfactual.\nThis makes calculating the ITE \\(\\tau_i\\) impossible.\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i\\)\n\\(Y_i(1)\\)\n\\(Y_i(0)\\)\n\\(Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n0\n0\n?\n0\n?\n\n\n2\n1\n1\n1\n?\n?\n\n\n3\n1\n0\n0\n?\n?\n\n\n4\n0\n0\n?\n0\n?\n\n\n5\n0\n1\n?\n1\n?\n\n\n6\n1\n1\n1\n?\n?"
  },
  {
    "objectID": "slides/01_intro.html#getting-around-the-fundamental-problem",
    "href": "slides/01_intro.html#getting-around-the-fundamental-problem",
    "title": "(1) Introduction to Causal Inference",
    "section": "Getting Around the Fundamental Problem",
    "text": "Getting Around the Fundamental Problem\n\nDoes the Average Treatment Effect (ATE) help?\nDefined in terms of expectations:\n\n\\(\\tau = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]\\)\n\nDefined in terms of averages:\n\n\\(\\tau = \\frac{1}{n} \\sum_{i=1}^{n} [\\tau_i] = \\frac{1}{n} \\sum_{i=1}^{n} [Y_i(1) - Y_i(0)] = \\frac{1}{n} \\sum_{i=1}^{n} [Y_i(1)] - \\frac{1}{n} \\sum_{i=1}^{n} [Y_i(0)]\\)\n\n\n\n\nStill not computable, because we don’t know the counterfactuals."
  },
  {
    "objectID": "slides/01_intro.html#assumptions-in-the-po-framework-2",
    "href": "slides/01_intro.html#assumptions-in-the-po-framework-2",
    "title": "(1) Introduction to Causal Inference",
    "section": "Assumptions in the PO Framework (2)",
    "text": "Assumptions in the PO Framework (2)\n\nWe need to make further assumptions to make progress.\n\n\n\n\nAssumption 4: “Ignorability / Exchangeability”.\n\n\nIgnorability (of how people selected their treatment) is equivalent to random assignment into treatments.\nExchangeability means that observations in treatment and control group could be swapped, and one would still obtain the same outcomes. This implies that observations in groups are the same in all relevant aspects other than the treatment.\nFormally, \\((Y(1), Y(0)) \\perp\\!\\!\\!\\perp T\\)."
  },
  {
    "objectID": "slides/01_intro.html#ate-identification---intuition",
    "href": "slides/01_intro.html#ate-identification---intuition",
    "title": "(1) Introduction to Causal Inference",
    "section": "ATE Identification - Intuition",
    "text": "ATE Identification - Intuition\n\nUsing assumptions 4 and 2, we obtain the following simplification:\n\n\\(\\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mathbb{E}[Y_i(1)|T_i=1] - \\mathbb{E}[Y_i(0)|T_i=0] = \\mathbb{E}[Y_i|T_i=1] - \\mathbb{E}[Y_i|T_i=0]\\)\n\nThis implies the ATE to be obtainable as associational difference:\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i\\)\n\\(Y_i(1)\\)\n\\(Y_i(0)\\)\n\n\n\n\n1\n0\n0\n?\n0\n\n\n4\n0\n0\n?\n0\n\n\n5\n0\n1\n?\n1\n\n\n2\n1\n1\n1\n?\n\n\n3\n1\n0\n0\n?\n\n\n6\n1\n1\n1\n?\n\n\n\n\nWe can then estimate \\(\\mathbb{E}[Y_i|T_i=1] = 0.66\\) and \\(\\mathbb{E}[Y_i|T_i=0] = 0.33\\) and use these values to replace the missing counterfactuals.\nATE is now identifiable in the sense that it can be computed from a purely statistical quantity."
  },
  {
    "objectID": "slides/01_intro.html#assumptions-in-the-po-framework-3",
    "href": "slides/01_intro.html#assumptions-in-the-po-framework-3",
    "title": "(1) Introduction to Causal Inference",
    "section": "Assumptions in the PO Framework (3)",
    "text": "Assumptions in the PO Framework (3)\n\nLet’s make exchangeability more realistic, i.e. conditional on covariates, so that subgroups will be exchangable.\n\n\n\n\nAssumption 5: “Conditional Exchangeability / Unconfoundedness”.\n\n\nFormally, \\((Y(1), Y(0)) \\perp\\!\\!\\!\\perp T \\, | \\, X\\)."
  },
  {
    "objectID": "slides/01_intro.html#assumptions-in-the-po-framework-4",
    "href": "slides/01_intro.html#assumptions-in-the-po-framework-4",
    "title": "(1) Introduction to Causal Inference",
    "section": "Assumptions in the PO Framework (4)",
    "text": "Assumptions in the PO Framework (4)\n\nConditioning on many covariates can also be detrimental, because we might end up conditioning on a zero probability event for some subgroups / values of X (division by zero)\n\n\n\n\nAssumption 6: “Positivity / Overlap / Common Support”.\n\n\nFor all values of covariates \\(x\\) present in the population of interest (i.e. \\(x\\) such that \\(P(X=x) &gt; 0\\)), we have \\(0 &lt; P(T=1|X=x) &lt; 1\\).\n\n\n\n\nThere is a trade-off between positivity and unconfoundedness.\nSome models might be forced to extrapolate to regions without sufficient support by using their parametric assumptions."
  },
  {
    "objectID": "slides/01_intro.html#derivation-of-the-average-treatment-effect-ate",
    "href": "slides/01_intro.html#derivation-of-the-average-treatment-effect-ate",
    "title": "(1) Introduction to Causal Inference",
    "section": "Derivation of the Average Treatment Effect (ATE)",
    "text": "Derivation of the Average Treatment Effect (ATE)\n\nWith the assumptions of conditional unconfoundedness, positivity, consistency, and no interference, we can identify the ATE as:\n\n\n\n\nTheorem 1: “Identification of the ATE”:\n\n\n\\(\\tau = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mathbb{E_X}[\\mathbb{E}[Y_i|T_i=1, X_i] - \\mathbb{E}[Y_i|T_i=0, X_i]]\\)"
  },
  {
    "objectID": "slides/01_intro.html#derivation-of-the-average-treatment-effect-ate-1",
    "href": "slides/01_intro.html#derivation-of-the-average-treatment-effect-ate-1",
    "title": "(1) Introduction to Causal Inference",
    "section": "Derivation of the Average Treatment Effect (ATE)",
    "text": "Derivation of the Average Treatment Effect (ATE)\n\nProof:\n\n\\[\\begin{align*}\n\\tau = \\mathbb{E}[\\tau_i] &= \\mathbb{E}[Y_i(1) - Y_i(0)] \\\\\n&= \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] \\\\\n& \\text{(linearity of expectation)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i(1) \\mid X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i(0) \\mid X_i]] \\\\\n&\\text{(law of iterated expectations)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i(1) \\mid T_i = 1, X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i(0) \\mid T_i = 0, X_i]] \\\\\n&\\text{(unconfoundedness and positivity)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i \\mid T_i = 1, X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i \\mid T_i = 0, X_i]] \\\\\n&\\text{(consistency)}\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/01_intro.html#other-causal-quantities",
    "href": "slides/01_intro.html#other-causal-quantities",
    "title": "(1) Introduction to Causal Inference",
    "section": "Other Causal Quantities",
    "text": "Other Causal Quantities\n\nThe ATE is just one of many causal quantities that can be estimated using the PO framework.\n\n\n\n\n“Average Treatment Effect on the Treated” (ATT):\n\n\n\\(ATT = \\mathbb{E}[Y_i(1)|T_i=1] - \\mathbb{E}[Y_i(0)|T_i=1]\\)\n\n\n\n\n\n\n“Conditional Average Treatment Effect” (CATE):\n\n\n\\(CATE = \\mathbb{E}[Y_i(1)|X_i=x] - \\mathbb{E}[Y_i(0)|X_i=x]\\)"
  },
  {
    "objectID": "slides/02_graphs.html#graphs",
    "href": "slides/02_graphs.html#graphs",
    "title": "(2) Graphical Causal Models",
    "section": "Graphs",
    "text": "Graphs\n\n\nGraph theory provides a useful mathematical language to think about causality.\nA graph consists of vertices (or nodes) V and edges (or links) E. Vertices represent variables in the model and edges the connections between them.\nEdges can either be undirected or directed."
  },
  {
    "objectID": "slides/02_graphs.html#directed-graphs",
    "href": "slides/02_graphs.html#directed-graphs",
    "title": "(2) Graphical Causal Models",
    "section": "Directed Graphs",
    "text": "Directed Graphs\n\n\nCausal relationships are generally seen as asymmetric:\n\nIf ‘A causes B’ is true, then ‘B causes A’ must be false.\nTherefore we’ll work with directed graphs most of the times.\n\nWe’ll sometimes use terminology of kinship:\n\nA is parent of B.\nB is child of A.\nA is ancestor of D.\nD is descendant of A.\n\nA path is a sequence of edges connecting two vertices:\n\n\\(B \\gets A \\to C \\to D\\) is a path from B to D.\nA path can go either along or against arrowheads.\nA path along the arrows is called directed: \\(A \\to C \\to D\\)."
  },
  {
    "objectID": "slides/02_graphs.html#directed-acyclic-graphs-dags",
    "href": "slides/02_graphs.html#directed-acyclic-graphs-dags",
    "title": "(2) Graphical Causal Models",
    "section": "Directed Acyclic Graphs (DAGs)",
    "text": "Directed Acyclic Graphs (DAGs)\n\n\nA directed path from a node to itself is called directed cycle or feedback loop: \\(B \\to C \\to D \\to B\\).\nGraph with feedback loops is called cyclic, with no feedback loops acyclic.\nWe focus on directed acyclic graphs (DAGs) in this course:\n\nexclude variables that influence themselves.\nEconometricians speak of recursive models that can be given a causal interpretation."
  },
  {
    "objectID": "slides/02_graphs.html#bayesian-networks",
    "href": "slides/02_graphs.html#bayesian-networks",
    "title": "(2) Graphical Causal Models",
    "section": "Bayesian Networks",
    "text": "Bayesian Networks\n\nProbabilistic graphical models (not causal):\n\nModelling the joint data distribution by factorizing with the chain rule of probability: \\(P(x_1, x_2, \\ldots, x_n) = P(x_1) \\prod_{i} P(x_i \\mid x_{i-1}, \\ldots, x_1)\\)\nn = 4: \\(P(x_1, x_2, x_3, x_4) = P(x_1)P(x_2 \\mid x_1)P(x_3 \\mid x_2, x_1)P(x_4 \\mid x_3, x_2, x_1)\\)\n\\(P(x_4 \\mid x_3, x_2, x_1)\\) alone requires \\(2^3 - 1 = 8\\) parameters = &gt; Focus on local dependencies:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(P_{joint} = P(x_1)P(x_2 \\mid x_1)P(x_3 \\mid x_2, x_1)P(x_4 \\mid x_3)\\)\n\n\n\n\n\n\n\n\n\n\n\\(P_{joint} = P(x_1)P(x_2)P(x_3 \\mid x_1)P(x_4 \\mid x_3)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#bayesian-networks-assumptions",
    "href": "slides/02_graphs.html#bayesian-networks-assumptions",
    "title": "(2) Graphical Causal Models",
    "section": "Bayesian Networks: Assumptions",
    "text": "Bayesian Networks: Assumptions\nGiven a probability distribution and a corresponding DAG, we can formalize the specification of local (in-) dependencies with:\n\n\n\nAssumption 2.1: “Local Markov Assumption”\n\n\nGiven its parents in the DAG, a node X is independent of all its non-descendants.\n\n\n\nIt follows:\n\n\n\nDefinition 2.1: “Bayesian Network Factorization”\n\n\nGiven a probability distribution \\(P\\) and a DAG \\(G\\), \\(P\\) factorizes according to \\(G\\) if:  \\(P(x_1, x_2, \\ldots, x_n) = \\prod_{i} P(x_i \\mid pa_i)\\)  with \\(pa_i\\) denoting the parents of node \\(i\\) in \\(G\\).\n\n\n\nThen \\(P\\) and \\(G\\) are called Markov compatible.\n\n\n\nAssumption 2.2: “Minimality Assumption”\n\n\n\nGiven its parents in the DAG, a node - is independent of all its non-descendants.\nAdjacent nodes in the DAG are dependent."
  },
  {
    "objectID": "slides/02_graphs.html#causal-graph-assumption",
    "href": "slides/02_graphs.html#causal-graph-assumption",
    "title": "(2) Graphical Causal Models",
    "section": "Causal Graph: Assumption",
    "text": "Causal Graph: Assumption\nWe need a further assumption to go from associations to causal relationships in a DAG:\n\n\n\nDefinition 2.2: “What is a cause?”\n\n\nA variable X is said to be a cause of a variable Y if Y can change in response to changes in X.\n\n\n\nAn outcome variable Y listens to X.\n\n\n\nAssumption 2.3: “(Strict) Causal Edge Assumption”\n\n\nIn a directed graph, every parent is a direct cause of all its children.\n\n\n\nThis assumption is “strict” in the sense that every edge is active, just like in DAGs that satisfy minimality."
  },
  {
    "objectID": "slides/02_graphs.html#graph-building-blocks-1",
    "href": "slides/02_graphs.html#graph-building-blocks-1",
    "title": "(2) Graphical Causal Models",
    "section": "Graph Building Blocks",
    "text": "Graph Building Blocks\n\nUnderstanding the flow of association and causation in DAGs based on minimal building blocks:\n\n\n\n\nTwo unconnected nodes: \\(P(x_1, x_2) = P(x_1) P(x_2)\\)\n\n\n\n\n\n\n\n\n\n\n\n\nTwo connected nodes: \\(P(x_1, x_2) = P(x_1) P(x_2 \\mid x_1)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChain:\n\n\n\n\n\n\n\n\n\n\n\n\nFork:\n\n\n\n\n\n\n\n\n\n\n\n\nImmorality:"
  },
  {
    "objectID": "slides/02_graphs.html#chains",
    "href": "slides/02_graphs.html#chains",
    "title": "(2) Graphical Causal Models",
    "section": "Chains",
    "text": "Chains\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x_1\\) and \\(x_3\\) are associated through \\(x_2\\)\n\nflow of association is symmetric whereas the flow of causality is directed\n\n\"Local Markov Assumption\": we can block the associative path by conditioning on the parent \\(x_2\\)\n\n\\(x_1 \\perp\\!\\!\\!\\perp x_3 | x_2\\)\n=&gt; \\(P(x_1, x_3 | x_2) = P(x_1 | x_2) P(x_3 | x_2)\\)\nProof?"
  },
  {
    "objectID": "slides/02_graphs.html#chains-proof",
    "href": "slides/02_graphs.html#chains-proof",
    "title": "(2) Graphical Causal Models",
    "section": "Chains: Proof",
    "text": "Chains: Proof\n\n\"Bayesian network factorization\" of chains:\n\n\\(P(x_1, x_2, x_3) = P(x_1) P(x_2 | x_1) P(x_3 | x_2)\\)\n\n\"Bayes' rule\":\n\n\\(P(x_1, x_3 | x_2) = \\frac{P(x_1, x_2, x_3)}{P(x_2)}\\)\n\nSo that:\n\n\\(P(x_1, x_3 | x_2) = \\frac{P(x_1) P(x_2 | x_1) P(x_3 | x_2)}{P(x_2)}\\)\n\n\"Bayes' rule\" twice more:\n\n\\(P(x_2 | x_1) = \\frac{P(x_1, x_2)}{P(x_1)}\\) and \\(P(x_1 | x_2) = \\frac{P(x_1, x_2)}{P(x_2)}\\)\n\nSo that we finally obtain q.e.d.:\n\n\\(P(x_1, x_3 | x_2) = \\frac{P(x_1, x_2)}{P(x_2)} P(x_3 | x_2) = P(x_1 | x_2) P(x_3 | x_2)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#forks",
    "href": "slides/02_graphs.html#forks",
    "title": "(2) Graphical Causal Models",
    "section": "Forks",
    "text": "Forks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x_1\\) and \\(x_3\\) are associated through \\(x_2\\) as common cause or confounder\n\"Local Markov Assumption\": we can block the associative path by conditioning on parent \\(x_2\\)\n\n\\(x_1 \\perp\\!\\!\\!\\perp x_3 | x_2\\)\n=&gt; \\(P(x_1, x_3 | x_2) = P(x_1 | x_2) P(x_3 | x_2)\\)\n\nProof? Do try this sh.. at home!"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders",
    "href": "slides/02_graphs.html#immoralities-and-colliders",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders",
    "text": "Immoralities and Colliders\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nno association in the first place: \\(x_1 \\perp\\!\\!\\!\\perp x_3\\)\n\nno common cause (“confounder” like in a fork)\nneither is \\(x_3\\) a descendant of \\(x_1\\) (like in a chain)\n\\(x_1\\) and \\(x_3\\) are unrelated things contributing to \\(x_2\\)\n\\(x_2\\) acts as a \"collider\" that blocks the path between \\(x_1\\) and \\(x_3\\)\n\nbut only if we do not condition on \\(x_2\\)"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders-proof",
    "href": "slides/02_graphs.html#immoralities-and-colliders-proof",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders: Proof",
    "text": "Immoralities and Colliders: Proof\n\n\"Bayesian network factorization\" of immoralities:\n\n\\(P(x_1, x_2, x_3) = P(x_1)P(x_3)P(x_2 \\mid x_1, x_3)\\)\n\nMarginalizing out \\(x_2\\) (assuming discrete variables):\n\n\\(P(x_1, x_3) = \\sum_{x_2}P(x_1)P(x_3)P(x_2 \\mid x_1, x_3) = P(x_1)P(x_3) \\sum_{x_2}P(x_2 \\mid x_1, x_3)\\)\n\nSince summing over all possible values of the conditional probability \\(P(x_2 \\mid x_1, x_3)\\) equals 1, we obtain q.e.d.:\n\n\\(P(x_1, x_3) = P(x_1)P(x_3)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders-example",
    "href": "slides/02_graphs.html#immoralities-and-colliders-example",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders: Example",
    "text": "Immoralities and Colliders: Example\n\nLooks and talent are independent of each other in the general population\n\nbut both contribute to success (e.g. being casted as an actor, getting funding as founder, being in a relationship)\nin a selected sample of (un-) successful actors, looks and talent become negatively associated\nconditioning on success (by selecting a subsample) creates a selection bias (or Berkson's paradox)"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders-numerical-example",
    "href": "slides/02_graphs.html#immoralities-and-colliders-numerical-example",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders: Numerical Example",
    "text": "Immoralities and Colliders: Numerical Example\n\nData generating process (dgp): \\(x_1 \\sim N(0, 1), \\quad x_3 \\sim N(0,1), \\quad x_2 = x_1 + x_3\\)\nCovariance in the population:\n\n\\[\\begin{align*}\n\\text{Cov}(x_1, x_3) &= \\mathbb{E}[(x_1 - \\mathbb{E}[x_1])(x_3 - \\mathbb{E}[x_3])] \\\\\n&= \\mathbb{E}[x_1x_3] \\quad (\\text{zero mean})\\\\\n&= \\mathbb{E}[x_1]\\mathbb{E}[x_3] \\quad (\\text{independent}) \\\\\n&= 0\n\\end{align*}\\]\n\n\nConditional covariance is the expected value of the product \\(x_1x_3\\), conditioned on \\(x_2\\) being equal to some value \\(x\\):\n\n\\[\\begin{align*}\n\\text{Cov}(x_1, x_3 | x_2 = x)\n&= \\mathbb{E}[x_1x_3 | x_2 = x] \\\\\n&= \\mathbb{E}[x_1(x - x_1)] \\quad (\\text{substituting x_3 by x - x_1 as per dgp}) \\\\\n&= x\\mathbb{E}[x_1] - \\mathbb{E}[x_1^2] \\quad (\\text{x is constant and expectations linear}) \\\\\n&= -1 \\quad (\\text{E(x_1) = 0 and E(x_1*x_1) = Var(x_1) = 1})\n\\end{align*}\\]"
  },
  {
    "objectID": "slides/02_graphs.html#immoralities-and-colliders-numerical-example-1",
    "href": "slides/02_graphs.html#immoralities-and-colliders-numerical-example-1",
    "title": "(2) Graphical Causal Models",
    "section": "Immoralities and Colliders: Numerical Example",
    "text": "Immoralities and Colliders: Numerical Example\n\n\nShow code\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggpubr) \n\n# simulate data\nset.seed(123) # for reproducibility\nlooks &lt;- rnorm(1000)\ntalent &lt;- rnorm(1000)\nx &lt;- talent + looks\ngroup &lt;- 1 * (x &gt; quantile(x, c(.75)))\n\n# create a dataframe\ndf &lt;- data.frame(looks, talent, group) %&gt;%\n  mutate(group = if_else(group == 1, \"With Job\", \"Without Job\")) %&gt;%\n  add_row(looks = Inf, talent = -Inf, group = \"Overall\")\n\n# plot\nggplot(df, aes(x = looks, y = talent)) +\n  geom_point(aes(color = group)) + \n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ x, aes(color = \"Overall\")) + # Regression line for all data\n  geom_smooth(data = subset(df, group == \"With Job\"), method = \"lm\", se = FALSE, formula = y ~ x, aes(color = \"With Job\")) +\n  geom_smooth(data = subset(df, group == \"Without Job\"), method = \"lm\", se = FALSE, formula = y ~ x, aes(color = \"Without Job\")) +\n  stat_regline_equation(aes(label = ..eq.label.., color = as.factor(group)), formula = y ~ x) +\n  stat_regline_equation(aes(label = ..eq.label.., color = \"Overall\"), formula = y ~ x) +\n  labs(color = \"Group\") +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "slides/02_graphs.html#descendants-of-colliders",
    "href": "slides/02_graphs.html#descendants-of-colliders",
    "title": "(2) Graphical Causal Models",
    "section": "Descendants of Colliders",
    "text": "Descendants of Colliders"
  },
  {
    "objectID": "slides/02_graphs.html#d-separation-1",
    "href": "slides/02_graphs.html#d-separation-1",
    "title": "(2) Graphical Causal Models",
    "section": "d-Separation",
    "text": "d-Separation\n\nSo far we only looked at graphs containing three variables. Can we somehow generalize these criteria?\n\n\n\n\nDefinition 2.3: “Blocked Path”\n\n\nA path \\(p\\) between nodes \\(X\\) and \\(Y\\) is blocked by a (potentially empty) conditioning set \\(Z\\) if either of the following is true:\n\n\\(p\\) contains a chain of nodes \\(... \\rightarrow W \\rightarrow ...\\) or a fork \\(... \\leftarrow W \\rightarrow ...\\), and \\(W\\) is conditioned, i.e. \\(W \\in Z\\).\n\\(p\\) contains an immorality \\(... \\rightarrow W \\leftarrow ...\\), and the collider \\(W\\) is not conditioned, i.e. \\(W \\notin Z\\).\n\n\n\n\n\n\n\nDefinition 2.4: “d-Separation”\n\n\nTwo nodes \\(X\\) and \\(Y\\) are d-separated by a set of nodes \\(Z\\) if all of the paths between \\(X\\) and \\(Y\\) are blocked by \\(Z\\)."
  },
  {
    "objectID": "slides/02_graphs.html#d-separation-2",
    "href": "slides/02_graphs.html#d-separation-2",
    "title": "(2) Graphical Causal Models",
    "section": "d-Separation",
    "text": "d-Separation\n\nIf two nodes are d-separated, and not d-connected, the variables they represent are independent.\n\n\n\n\nTheorem 2: “Global Markov Assumption”\n\n\nGiven that \\(P\\) is Markov compatible with respect to \\(G\\) (satisfies the local Markov assumption), if \\(X\\) and \\(Y\\) are d-separated in \\(G\\) conditioned on \\(Z\\), then \\(X\\) and \\(Y\\) are independent in \\(P\\) conditioned on \\(Z\\).\nFormally, \\(X \\perp\\!\\!\\!\\perp_{G} Y \\,|\\, Z \\implies X \\perp\\!\\!\\!\\perp_{P} Y \\,|\\, Z\\)."
  },
  {
    "objectID": "slides/02_graphs.html#d-separation-practice-1",
    "href": "slides/02_graphs.html#d-separation-practice-1",
    "title": "(2) Graphical Causal Models",
    "section": "d-Separation Practice 1",
    "text": "d-Separation Practice 1\n\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\ndag &lt;- dagify(\n  # relationship for each node\n  W ~ Z,\n  W ~ X,\n  Y ~ X,\n  U ~ W,\n # Location of each node\n  coords = list(\n    x = c(Z = 0, W = 1, X = 2, Y = 3, U = 1),\n    y = c(Z = 0, W = -0.5, X = 0, Y = 0, U = -1)\n  )\n)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y,\n             xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\") +\n  geom_dag_edges() +\n  geom_dag_point(shape = 1) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\n\\(Z\\) and \\(Y\\) d-separated conditional on\n\n\\(\\emptyset\\) ? 2. \\(\\{W\\}\\) ? 3. \\(\\{U\\}\\) ? 4. \\(\\{W, X\\}\\) ?\n\n\n\n\n\n1:\n\n\nlibrary(dagitty)\ndag &lt;- dagify(\n  W ~ Z,\n  W ~ X,\n  Y ~ X,\n  U ~ W\n)\ndseparated(dag, X=\"Z\", Y=\"Y\", Z = c())\n\n[1] TRUE\n\n\n\n2:\n\n\n\n[1] FALSE\n\n\n\n3:\n\n\n\n[1] FALSE\n\n\n\n4:\n\n\n\n[1] TRUE"
  },
  {
    "objectID": "slides/02_graphs.html#d-separation-practice-2",
    "href": "slides/02_graphs.html#d-separation-practice-2",
    "title": "(2) Graphical Causal Models",
    "section": "d-Separation Practice 2",
    "text": "d-Separation Practice 2\n\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\ndag &lt;- dagify(\n  Y ~ M2 + X3 + W3,\n  W3 ~ W2,\n  W1 ~ W2,\n  T ~ W1,\n  M1 ~ T,\n  M2 ~ M1,\n  X1 ~ T,\n  X3 ~ Y,\n  X2 ~ X1 + X3,\n  coords = list(\n    x = c(T = 0, W1 = 1, W2 = 1.5, W3 = 2, M1 = 1, M2 = 2, Y = 3, X1 = 1, X2 = 1.5, X3 = 2),\n    y = c(T = -1, W1 = 0, W2 = 0.5, W3 = 0, M1 = -1, M2 = -1, Y = -1, X1 = -2, X2 = -2.5, X3 = -2)\n  )\n)\n\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y,\n             xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\") +\n  geom_dag_edges() +\n  geom_dag_point(shape = 1) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\n\\(T\\) and \\(Y\\) d-separated conditional on\n\n\\(\\emptyset\\) ? 2. \\(\\{W_2\\}\\) ? 3. \\(\\{W_2, M_1\\}\\) ?\n\\(\\{W_1, M_2\\}\\) ? 5. \\(\\{W_1, M_2, X_2 \\}\\) ? 6. \\(\\{W_1, M_2, X_2, X_3 \\}\\) ?\n\n\n\n\n\n1:\n\n\n\n[1] FALSE\n\n\n\n2:\n\n\n\n[1] FALSE\n\n\n\n3:\n\n\n\n[1] TRUE\n\n\n\n4:\n\n\n\n[1] TRUE\n\n\n\n5:\n\n\n\n[1] FALSE\n\n\n\n6:\n\n\n\n[1] TRUE"
  },
  {
    "objectID": "slides/02_graphs.html#flow-of-association-and-causation---summary",
    "href": "slides/02_graphs.html#flow-of-association-and-causation---summary",
    "title": "(2) Graphical Causal Models",
    "section": "Flow of Association and Causation - Summary",
    "text": "Flow of Association and Causation - Summary\n\nTotal association between two variables flows along all unblocked paths in a causal graph.\n\nAssociation that flows along directed, unblocked paths is causal association.\nThe remaining association is non-causal association, e.g. selection bias or confounding association.\nCausal association is asymmetric, non-causal association is symmetric.\nCausal association is a subcategory of total association.\n\nd-separation can imply “Association is Causation`\n\nIgnoring the causal paths, are X and Y d-separated otherwise?"
  },
  {
    "objectID": "slides/02_graphs.html#structural-causal-models",
    "href": "slides/02_graphs.html#structural-causal-models",
    "title": "(2) Graphical Causal Models",
    "section": "Structural Causal Models",
    "text": "Structural Causal Models\n\n\n\nA DAG represents an underlying structural causal model:\n\\(f_i\\)’s can be arbitrary, non-parametric functions\n\nas opposed to structural equation models (SEM) in econometrics\n\n\\(\\epsilon_i\\)’s are unobserved error terms\n\nMarkovian model: all errors are assumed to be jointly independent and hence not shown in the graph.\nsemi-Markovian model: some errors are correlated and shown in the graph; e.g. \\(u\\) in the example.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(Y = f_1(T, \\epsilon_1)\\)\n\\(T = f_2(X_1, X_2, \\epsilon_2)\\)\n\\(X_1 = f_3(u, \\epsilon_3)\\)\n\\(X_2 = f_4(u, \\epsilon_4)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#conditioning-vs-intervention",
    "href": "slides/02_graphs.html#conditioning-vs-intervention",
    "title": "(2) Graphical Causal Models",
    "section": "Conditioning vs Intervention",
    "text": "Conditioning vs Intervention\n\n\n\n\n\n\nNeal, Brady (2020). Introduction to causal inference from a Machine Learning Perspective. Course Lecture Notes (draft)."
  },
  {
    "objectID": "slides/02_graphs.html#interventions-and-the-do-operator",
    "href": "slides/02_graphs.html#interventions-and-the-do-operator",
    "title": "(2) Graphical Causal Models",
    "section": "Interventions and the do-Operator",
    "text": "Interventions and the do-Operator\n\nInterventions in causal models are defined by the do-operator.\nNotation: \\(P(Y|do(T = t))\\) stands for:\n\n“probability distribution of \\(Y\\) if we fix \\(T\\) to the specific value \\(t\\)”.\nInterventional distributions are not the same as conditional or observational distributions.\n\nWe can also write the ATE with it: \\[\\text{ATE} = \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)] = \\mathbb{E}[Y|do(T = 1)] - \\mathbb{E}[Y|do(T = 0)]\\]\nMany (if not most) questions we try to answer with data involve some form of intervention, treatment, or action:\n\nP(Performance | do(Training))\nP(Sales | do(Incentive))\nP(Click-through Rate | do(Advertising))\nP(Churn | do(Call Center))"
  },
  {
    "objectID": "slides/02_graphs.html#interventions-and-the-do-operator-1",
    "href": "slides/02_graphs.html#interventions-and-the-do-operator-1",
    "title": "(2) Graphical Causal Models",
    "section": "Interventions and the do-Operator",
    "text": "Interventions and the do-Operator\n\nIn graphical models, intervening on a variable X is similar to a kind of surgery in which we remove all edges into that variable:\n\n\n\n\nPre-Intervention\n\n\n\n\n\n\n\n\n\n\n\n\\(Y = f_y(T, X, \\epsilon_y)\\)\n\\(T = f_2(X, \\epsilon_T)\\)\n\\(X = f_3(\\epsilon_X)\\)\n\n\n\nPost-Intervention\n\n\n\n\n\n\n\n\n\n\n\n\\(Y = f_y(T, X, \\epsilon_y)\\)\n\\(T = t\\)\n\\(X = f_3(\\epsilon_X)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#interventions-and-the-do-operator-2",
    "href": "slides/02_graphs.html#interventions-and-the-do-operator-2",
    "title": "(2) Graphical Causal Models",
    "section": "Interventions and the do-Operator",
    "text": "Interventions and the do-Operator\n\nBayesian network factorization of the pre-intervention DAG:\n\n\\(P(Y, T, X) = P(X)P(T|X)P(Y|T,X)\\)\n\nIf we intervene on \\(T\\) and set it to \\(t\\), the factorization changes:\n\n\\(P(Y, X | do(T = t)) = P(X)P(Y|T = t, X)\\)\n\nMarginalizing out \\(X\\) gives the interventional distribution of \\(Y\\):\n\n\\(P(Y | do(T = t)) = \\sum_{x} P(Y|T = t, X = x)P(X = x)\\)\n\nTo obtain the causal effect, we condition on the values of \\(X\\) and average over the distribution.\nWe only obtain the associational counterpart \\(P(Y|T = t)\\) if \\(P(X)\\) would have to be replaced by \\(P(X|T = t)\\).\n\nThen: \\(\\sum_{x} P(Y|T = t, X = x)P(X|T = t) = \\sum_{x} P(Y, X|T = t) = P(Y| T= t)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#interventions-and-the-do-operator-3",
    "href": "slides/02_graphs.html#interventions-and-the-do-operator-3",
    "title": "(2) Graphical Causal Models",
    "section": "Interventions and the do-Operator",
    "text": "Interventions and the do-Operator\n\nCarrying out an intervention ourselves, in a randomized control trial, is not always feasible (too expensive, impractical, or unethical).\nHow can we then identify the effect of interventions purely from observational data?\n\nWe want to know \\(P(Y|do(T = t))\\) but all we have is data \\(P(Y,X,T)\\).\nAnd we know that \\(P(Y|do(T = t) \\neq P(Y|T))\\) (i.e. “correlation is not causation”).\nNo fancy machine learning algorithm will ever (?) solve this problem.\n\nOne way is to find a way to transform \\(P(Y|do(T = t))\\) into an expression that only contains observed, “do-free” quantities."
  },
  {
    "objectID": "slides/02_graphs.html#backdoor-adjustment-1",
    "href": "slides/02_graphs.html#backdoor-adjustment-1",
    "title": "(2) Graphical Causal Models",
    "section": "Backdoor Adjustment",
    "text": "Backdoor Adjustment\n\nThe backdoor criterion is a graphical condition that allows us to identify causal effects from observational data.\n\n\n\n\nDefinition 2.5: “Backdoor Criterion”\n\n\nA set of variables \\(W\\) satisfies the backdoor criterion relative to \\(T\\) and \\(Y\\) if the following are true:\n\n\\(W\\) blocks all backdoor paths between \\(T\\) and \\(Y\\) that contains an arrow into \\(T\\).\n\\(W\\) does not contain any descendants of \\(T\\).\n\n\n\n\n\nIf a set of variables \\(W\\) satisfies the backdoor criterion for \\(T\\) and \\(Y\\), then the causal effect is given by: \\(P(Y|\\text{do}(T = t)) = \\sum_{W} P(Y|T = t, W = w)P(W = w)\\).\n\ni.e. condition on the values of \\(W\\) and average over their joint distribution"
  },
  {
    "objectID": "slides/02_graphs.html#backdoor-adjustment-proof",
    "href": "slides/02_graphs.html#backdoor-adjustment-proof",
    "title": "(2) Graphical Causal Models",
    "section": "Backdoor Adjustment: Proof",
    "text": "Backdoor Adjustment: Proof\n\nConditioning on the variables \\(W\\) and marginalizing them out:\n\n\\(P(Y|\\text{do}(T = t)) = \\sum_{W} P(Y|\\text{do}(T = t), W = w)P(W| \\text{do}(T = t))\\)\n\nGet rid of the first “do” by using the definition of the do-operator - “all backdoor paths blocked”:\n\n\\(\\sum_{W} P(Y|\\text{do}(T = t), W = w)P(W| \\text{do}(T = t)) = \\sum_{W} P(Y|T = t, W = w)P(W| \\text{do}(T = t))\\)\n\nGet rid of the second “do” by using the definition of the do-operator - “no descendants of T in W”:\n\n\\(\\sum_{W} P(Y|T = t, W = w)P(W| \\text{do}(T = t)) = \\sum_{W} P(Y|T = t, W = w)P(W)\\)"
  },
  {
    "objectID": "slides/02_graphs.html#backdoor-adjustment-example",
    "href": "slides/02_graphs.html#backdoor-adjustment-example",
    "title": "(2) Graphical Causal Models",
    "section": "Backdoor Adjustment: Example",
    "text": "Backdoor Adjustment: Example\n\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\ndag &lt;- dagify(\n  T ~ X1 + X2,\n  X6 ~ T,\n  X2 ~ X3,\n  X1 ~ X3 + X4,\n  X5 ~ X4,\n  Y ~ X1 + X5 + X6,\n  exposure = \"T\", outcome = \"Y\",\n  coords = list(\n    x = c(T = 0, X1 = 1, X2 = 0, X3 = 0, X4 = 2, X5 = 2, X6 = 1, Y = 2),\n    y = c(T = 0, X1 = 1, X2 = 1, X3 = 2, X4 = 2, X5 = 1, X6 = 0, Y = 0)\n  )\n)\n\ndag %&gt;%\n  ggplot(aes(x = x, y = y,\n             xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\") +\n  geom_dag_edges() +\n  geom_dag_point(shape = 1) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\n\nMinimum sufficient adjustment sets?\n\n\n\n\nShow code\nlibrary(ggdag)\nlibrary(ggplot2)\ndag &lt;- dagify(\n  T ~ X1 + X2,\n  X6 ~ T,\n  X2 ~ X3,\n  X1 ~ X3 + X4,\n  X5 ~ X4,\n  Y ~ X1 + X5 + X6,\n  exposure = \"T\", outcome = \"Y\",\n  coords = list(\n    x = c(T = 0, X1 = 1, X2 = 0, X3 = 0, X4 = 2, X5 = 2, X6 = 1, Y = 2),\n    y = c(T = 0, X1 = 1, X2 = 1, X3 = 2, X4 = 2, X5 = 1, X6 = 0, Y = 0)\n  )\n)\n\nadjustmentSets(dag)\n\n\n{ X1, X5 }\n{ X1, X4 }\n{ X1, X3 }\n{ X1, X2 }"
  },
  {
    "objectID": "slides/02_graphs.html#relation-to-the-potential-outcomes-framework",
    "href": "slides/02_graphs.html#relation-to-the-potential-outcomes-framework",
    "title": "(2) Graphical Causal Models",
    "section": "Relation to the Potential Outcomes Framework",
    "text": "Relation to the Potential Outcomes Framework\n\nATE in the PO framework:\n\n\\(\\tau = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mathbb{E_X}[\\mathbb{E}[Y_i|T_i=1, X_i] - \\mathbb{E}[Y_i|T_i=0, X_i]]\\)\n\ndo-notation \\(\\mathbb{E}(Y|do(T = t))\\) just another notation for the potential outcomes \\(\\mathbb{E}[Y(t)]\\).\n\nExpectations and discrete treatement vs. probability weighted averages and continuous/ multi-valued treatments.\n\nThe backdoor criterion is a graphical condition to identify valid adjustment sets for the potential outcomes framework.\n\nBut we had no way of knowing how to choose \\(W\\) such that it gives us conditional exchangeability.\nThe backdoor criterion is a graphical condition to choose a valid \\(W\\).\nIt is neither necessary nor suffcient to condition on all variables in the data and model.\nCan even be harmful to condition on a (collider) variable.\n\nOnce we have found an admissible adjustment set, we can estimate the causal effect by matching, inverse probability weighting, or linear regression (if you’re willing to assume linearity)."
  },
  {
    "objectID": "slides/04_ob_conf.html#what-to-do-without-randomized-experiment",
    "href": "slides/04_ob_conf.html#what-to-do-without-randomized-experiment",
    "title": "(4) Observed Confounding",
    "section": "What to do without randomized experiment?",
    "text": "What to do without randomized experiment?\n\n\nIn many business settings, randomization of treatments is not possible.\n\nWe need to find ways to work with so-called observational data.\n\nIdentification strategy to adjust for all confounders has many names:\n\nIgnorability\nUnconfoundedness\nSelection-on-observables\nConditional independence\nBackdoor adjustment\nMeasured confounding\nObserved Confounding"
  },
  {
    "objectID": "slides/04_ob_conf.html#assumption-1-conditional-independence",
    "href": "slides/04_ob_conf.html#assumption-1-conditional-independence",
    "title": "(4) Observed Confounding",
    "section": "Assumption 1: Conditional Independence",
    "text": "Assumption 1: Conditional Independence\n\nPotential outcomes are conditionally independent of \\(T\\) after controlling for covariates \\(\\mathbf{X}\\).\n\n\\(T\\) is as good as randomly assigned among subjects with the same values in \\(\\mathbf{X}\\).\n\n\n\n\n\nAssumption: “Conditional Exchangeability / Unconfoundedness / Ignorability / Independence”.\n\n\nFormally, \\((Y(1), Y(0)) \\perp\\!\\!\\!\\perp T \\, | \\, \\mathbf{X}\\).\n\n\n\n\n\nThis entails the somewhat weaker, but sufficient formulation of conditional exchangeability in terms of means:\n\nbefore treatment: \\(\\mathbb{E}[Y_i(0)|T_i=0, \\mathbf{X_i = x_i}] = \\mathbb{E}[Y_i(0)|T_i=1, \\mathbf{X_i = x_i}]\\)\nafter treatment: \\(\\mathbb{E}[Y_i(1)|T_i=1, \\mathbf{X_i = x_i}] = \\mathbb{E}[Y_i(1)|T_i=0, \\mathbf{X_i = x_i}]\\)\ndifferences in mean potential outcomes across treatment and control groups are entirely due to differences in observed covariates."
  },
  {
    "objectID": "slides/04_ob_conf.html#backdoor-adjustement",
    "href": "slides/04_ob_conf.html#backdoor-adjustement",
    "title": "(4) Observed Confounding",
    "section": "Backdoor Adjustement",
    "text": "Backdoor Adjustement\n\n\n\nall confounders observed, measured and controlled for\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsome confounders remain unobserved\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMinimal adjustment set of confounders to be observed: not testable.\nSensitivity analysis can be used to assess the robustness of the results to unobserved confounding (later session)."
  },
  {
    "objectID": "slides/04_ob_conf.html#observed-confounder-selection",
    "href": "slides/04_ob_conf.html#observed-confounder-selection",
    "title": "(4) Observed Confounding",
    "section": "Observed Confounder Selection",
    "text": "Observed Confounder Selection\n\nCredible identification demands to define the adjustment set of variables that makes conditional independence assumption credible to hold.\nThis requires good theoretical or practical knowledge about the treatment assignment mechanism.\nDAGs provide a principled framework to structure that knowledge and to disentangle good and bad controls:\n\nNo post-treatment variables, etc …\nSee Cinelly, Forley and Pearl (2022) for a nice overview."
  },
  {
    "objectID": "slides/04_ob_conf.html#assumption-2-common-support",
    "href": "slides/04_ob_conf.html#assumption-2-common-support",
    "title": "(4) Observed Confounding",
    "section": "Assumption 2: Common Support",
    "text": "Assumption 2: Common Support\n\nConditioning on many covariates can also be detrimental, because we might end up conditioning on a zero probability event for some subgroups / values of X (division by zero)\n\n\n\n\nAssumption: “Positivity / Overlap / Common Support”.\n\n\nFor all values of covariates \\(x\\) present in the population of interest (i.e. \\(x\\) such that \\(P(X=x) &gt; 0\\)), we have \\(0 &lt; P(T=1|X=x) &lt; 1\\).\n\n\n\n\n\nThere is a trade-off between positivity and conditional independence.\nSome models might be forced to extrapolate to regions without sufficient support by using their parametric assumptions.\n\nParametric instead of non-parametric identification."
  },
  {
    "objectID": "slides/04_ob_conf.html#common-support-extrapolation",
    "href": "slides/04_ob_conf.html#common-support-extrapolation",
    "title": "(4) Observed Confounding",
    "section": "Common Support & Extrapolation",
    "text": "Common Support & Extrapolation"
  },
  {
    "objectID": "slides/04_ob_conf.html#ate-under-observed-confounding",
    "href": "slides/04_ob_conf.html#ate-under-observed-confounding",
    "title": "(4) Observed Confounding",
    "section": "ATE under Observed Confounding",
    "text": "ATE under Observed Confounding\n\nWith the assumptions of conditional unconfoundedness & positivity (together with consistency, and no interference), we can identify the ATE as:\n\n\n\n\nTheorem: “Identification of the ATE”:\n\n\n\\(\\tau_{\\text{ATE}} = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] = \\mathbb{E_X}[\\mathbb{E}[Y_i|T_i=1, X_i] - \\mathbb{E}[Y_i|T_i=0, X_i]]\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#ate-under-observed-confounding-1",
    "href": "slides/04_ob_conf.html#ate-under-observed-confounding-1",
    "title": "(4) Observed Confounding",
    "section": "ATE under Observed Confounding",
    "text": "ATE under Observed Confounding\n\nProof:\n\n\\[\n\\begin{align*}\n\\tau_{\\text{ATE}} = \\mathbb{E}[\\tau_i] &= \\mathbb{E}[Y_i(1) - Y_i(0)] \\\\\n&= \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)] \\\\\n&\\text{(linearity of expectation)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i(1) \\mid X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i(0) \\mid X_i]] \\\\\n&\\text{(law of iterated expectations)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i(1) \\mid T_i = 1, X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i(0) \\mid T_i = 0, X_i]] \\\\\n&\\text{(conditional ignorability and positivity)} \\\\\n&= \\mathbb{E}_X [\\mathbb{E}[Y_i \\mid T_i = 1, X_i]] - \\mathbb{E}_X [\\mathbb{E}[Y_i \\mid T_i = 0, X_i]] \\\\\n&\\text{(consistency)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/04_ob_conf.html#identification-with-linear-regression",
    "href": "slides/04_ob_conf.html#identification-with-linear-regression",
    "title": "(4) Observed Confounding",
    "section": "Identification with Linear Regression",
    "text": "Identification with Linear Regression\n\nMost direct approach is to run a linear regression conditional on covariates:\n\n\\(Y_i = \\beta_0 + \\beta_T T_i + \\beta_{X_1} X_{i1} + \\dots + \\beta_{X_K} X_{iK} + \\epsilon_i\\)\n\\(Y_i = \\beta_0 + \\beta_T T_i + \\mathbf{\\beta_{X}' X_i} + \\epsilon_i\\)\n\\(\\mathbb{E}[Y_i | T_i, \\mathbf{X_i}] = \\beta_0 + \\beta_T T_i + \\mathbf{\\beta_{X}' X_i}\\)\n\n\n\n\nIf this linear model is correct, then (given \\(T_i\\) is binary):\n\n\\(\\tau_{\\text{CATE}} = \\mathbb{E}[Y_i | T_i = 1, \\mathbf{X_i}] - \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i}]\\)\n\\(\\tau_{\\text{CATE}} = (\\beta_0 + \\beta_T \\cdot 1  + \\mathbf{\\beta_{X}' X_i}) - (\\beta_0 + \\beta_T \\cdot 0 + \\mathbf{\\beta_{X}' X_i}) = \\beta_T\\)\n\\(\\tau_{\\text{ATE}} = \\mathbb{E_X}[\\beta_T] = \\beta_T\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#frisch-waugh-lovell-fwl-theorem",
    "href": "slides/04_ob_conf.html#frisch-waugh-lovell-fwl-theorem",
    "title": "(4) Observed Confounding",
    "section": "Frisch-Waugh-Lovell (FWL) Theorem",
    "text": "Frisch-Waugh-Lovell (FWL) Theorem\n\nWe can estimate \\(\\beta_T\\) in a standard linear regression \\(Y_i = \\beta_0 + \\beta_T T_i + \\mathbf{\\beta_{X}' X_i} + \\epsilon_i\\) in a three-stage procedure:\n\n\nRun a regression of the form \\(Y_i = \\beta_{Y0} + \\mathbf{\\beta_{Y \\sim X}' X_i} + \\epsilon_{Y_i \\sim X_i}\\) and extract the estimated residuals \\(\\hat\\epsilon_{Y_i \\sim X_i}\\).\nRun a regression of the form \\(T_i = \\beta_{T0} + \\mathbf{\\beta_{T \\sim X}' X_i} + \\epsilon_{T_i \\sim X_i}\\) and extract the estimated residuals \\(\\hat\\epsilon_{T_i \\sim X_i}\\).\nRun a residual-on-residual regression of the form \\(\\hat\\epsilon_{Y_i \\sim X_i} = \\beta_T \\hat\\epsilon_{T_i \\sim X_i} + \\epsilon_i\\) (no constant).\n\nThe resulting estimate \\(\\hat\\beta_T\\) is numerically identical to the estimate we would get if we just run the full OLS model."
  },
  {
    "objectID": "slides/04_ob_conf.html#controlling-for-covariates-fwl-theorem-logic",
    "href": "slides/04_ob_conf.html#controlling-for-covariates-fwl-theorem-logic",
    "title": "(4) Observed Confounding",
    "section": "Controlling for Covariates: FWL Theorem Logic",
    "text": "Controlling for Covariates: FWL Theorem Logic"
  },
  {
    "objectID": "slides/04_ob_conf.html#identification-with-linear-regression-1",
    "href": "slides/04_ob_conf.html#identification-with-linear-regression-1",
    "title": "(4) Observed Confounding",
    "section": "Identification with Linear Regression",
    "text": "Identification with Linear Regression\n\nOLS estimate of \\(\\hat{\\beta_T}\\) is now given by:\n\n\\(Y_i = \\hat{\\beta_0} + \\hat{\\beta}_T T_i + \\mathbf{\\hat{\\beta}_{X}' X_i} + \\hat{\\epsilon}_i\\)\n\\(\\hat{\\beta_T} = \\frac{\\text{Cov}(Y_i, T_i | \\mathbf{X_i})}{\\text{Var}(T_i | \\mathbf{X_i})}\\)\nDifference to randomized experiments: \\(\\mathbf{X_i}\\) may affect \\(T_i\\), i.e. \\(\\text{Cov}(T_i, \\mathbf{X_i}) \\neq 0\\)\n\n\n\n\nTwo possible implications:\n\n\n\\(se(\\hat{\\beta_T})\\) may be larger than in randomized experiments.\n\n\nif the linear model is misspecified, \\(\\hat{\\beta_T}\\) may be biased and inconsistent.\n\n\nif the relation between \\(Y_i\\) and \\(\\mathbf{X_i}\\) is in fact non-linear, this spills over to the estimation of \\(\\hat{\\beta_T}\\) via the correlation of \\(T_i\\) and \\(\\mathbf{X_i}\\)."
  },
  {
    "objectID": "slides/04_ob_conf.html#identification-with-linear-regression-2",
    "href": "slides/04_ob_conf.html#identification-with-linear-regression-2",
    "title": "(4) Observed Confounding",
    "section": "Identification with Linear Regression",
    "text": "Identification with Linear Regression\n\nPossible misspecifications: Omission of …\n\n\nMultiplicative interactions between covariates: e.g. \\(X_{i1} \\cdot X_{i2}\\).\n\n\nHigher order terms: e.g. \\(X_{i1} \\cdot X_{i1} = X_{i1}^2\\).\n\n\nInteractions between treatment and covariates to allow for effect heterogeneity: e.g. \\(T_i \\cdot X_{i1}\\).\n\n\n\n\n\nMore flexible model:\n\n\\(\\mathbb{E}[Y_i | T_i, \\mathbf{X_i}] = \\beta_0 + \\beta_T T_i + \\mathbf{\\beta_{X}' X_i} + \\mathbf{\\beta_{TX}' X_i}T_i + \\beta_{X^2_1} X^2_{i1} + \\dots + \\beta_{X_1X_2} X_{i1} X_{i2} + \\dots\\)\n\\(\\tau_{\\text{CATE}} = \\mathbb{E}[Y_i | T_i = 1, \\mathbf{X_i}] - \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i}]\\)\n\\(\\tau_{\\text{CATE}} = \\beta_T + \\mathbf{\\beta_{TX}' X_i}\\)\n\\(\\tau_{\\text{ATE}} = \\mathbb{E_X}[\\tau_{\\text{CATE}}] = \\mathbb{E_X}[\\beta_T + \\mathbf{\\beta_{TX}' X_i}] = \\beta_T + \\beta_{TX}'\\mathbb{E_X}[\\mathbf{X_i}] = \\beta_T + \\mathbf{\\beta_{TX}'\\overline{X}}\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#identification-with-linear-regression-3",
    "href": "slides/04_ob_conf.html#identification-with-linear-regression-3",
    "title": "(4) Observed Confounding",
    "section": "Identification with Linear Regression",
    "text": "Identification with Linear Regression\n\nAlternatively, estimate two separate models for treated and control group:\n\n\\(\\mathbb{E}[Y_i | T_i = 1, \\mathbf{X_i}] = \\beta_{0,1} + \\mathbf{\\beta_{X,1}' X_i} + \\beta_{X^2_1,1} X^2_{i1} + \\dots + \\beta_{X_1X_2,1} X_{i1} X_{i2} + \\dots\\)\n\\(\\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i}] = \\beta_{0,0} + \\mathbf{\\beta_{X,0}' X_i} + \\beta_{X^2_1,0} X^2_{i1} + \\dots + \\beta_{X_1X_2,0} X_{i1} X_{i2} + \\dots\\)\n\\(\\tau_{\\text{CATE}} = \\mathbb{E}[Y_i | T_i = 1, \\mathbf{X_i}] - \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i}]\\)\n\nThen averaging:\n\n\\(\\tau_{\\text{ATE}} = \\mathbb{E_X}[\\tau_{\\text{CATE}}] = \\mathbb{E_X}[\\mathbb{E}[Y_i | T_i = 1, \\mathbf{X_i}] - \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i}]]\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#conditional-outcome-regression-example",
    "href": "slides/04_ob_conf.html#conditional-outcome-regression-example",
    "title": "(4) Observed Confounding",
    "section": "Conditional Outcome Regression: Example",
    "text": "Conditional Outcome Regression: Example\n\nAssess the impact of participating in the U.S. National Supported Work (NSW) training program targeted to 445 individuals with social and economic problems on their real earnings.\n\n\nlibrary(Matching)                       # load Matching package for the data\nlibrary(Jmisc)                          # load Jmisc package with demean function\nlibrary(lmtest)                         # load lmtest package\nlibrary(sandwich)                       # load sandwich package\nlibrary(modelsummary)                   # load modelsummary package\ndata(lalonde)                           # load lalonde data\nattach(lalonde)                         # store all variables in own objects\nT = treat                                 # define treatment (training)\nY = re78                                  # define outcome \nX = cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates\nDXdemeaned = T * demean(X)                  # interaction of D and demeaned X \nols = lm(Y ~ T + X + DXdemeaned)                # run OLS regression\nmodelsummary(ols, vcov = sandwich::vcovHC, estimate = \"est = {estimate} (se = {std.error}, t = {statistic}){stars}\", statistic = \"p = {p.value}, CI = [{conf.low}, {conf.high}]\", gof_map = c(\"r.squared\"), coef_omit = \"X\")  \n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\nest = 7161.163 (se = 3975.959, t = 1.801)+\n\n\n\np = 0.072, CI = [-653.935, 14976.260]\n\n\nT\nest = 1583.468 (se = 711.171, t = 2.227)*\n\n\n\np = 0.027, CI = [185.600, 2981.336]\n\n\nR2\n0.104"
  },
  {
    "objectID": "slides/04_ob_conf.html#matching-idea",
    "href": "slides/04_ob_conf.html#matching-idea",
    "title": "(4) Observed Confounding",
    "section": "Matching Idea",
    "text": "Matching Idea"
  },
  {
    "objectID": "slides/04_ob_conf.html#matching-methods",
    "href": "slides/04_ob_conf.html#matching-methods",
    "title": "(4) Observed Confounding",
    "section": "Matching Methods",
    "text": "Matching Methods\n\nIdea: find and match treated and nontreated observations with similar (or ideally identical) covariate values.\n\ncreate a sample of treated and nontreated groups that are comparable in terms of covariate distributions, just as it would be the case in a successful experiment.\nWith or without replacement.\n1:1 or 1:M matching.\n\nMethods:\n\nNearest Neighbor Matching\nRadius (Caliper) Matching\nPropensity Score Matching"
  },
  {
    "objectID": "slides/04_ob_conf.html#nearest-neighbor-matching",
    "href": "slides/04_ob_conf.html#nearest-neighbor-matching",
    "title": "(4) Observed Confounding",
    "section": "Nearest Neighbor Matching",
    "text": "Nearest Neighbor Matching\n\nFor each treated unit, find the one nearest nontreated unit in terms of covariate values (1:1 matching):\n\nAverage treatment effect on the treated (ATT):\n\\(\\hat{\\tau}_{\\text{ATT}} = \\frac{1}{n_1} \\sum_{i:T_i=1} \\left( Y_i - \\sum_{j:T_j=0} I( \\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert = \\min_{l:T_l=0} \\lVert \\mathbf{X_l} - \\mathbf{X_i} \\rVert) Y_j) \\right)\\)\nAverage treatment effect on the untreated (ATU):\n\\(\\hat{\\tau}_{\\text{ATU}} = \\frac{1}{n_0} \\sum_{i:T_i=0} \\left( Y_i - \\sum_{j:T_j=1} I( \\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert = \\min_{l:T_l=1} \\lVert \\mathbf{X_l} - \\mathbf{X_i} \\rVert) Y_j) \\right)\\)\nAverage treatment effect (ATE):\n\\(\\hat{\\tau}_{\\text{ATE}} = \\frac{n_1}{n} \\hat{\\tau}_{\\text{ATT}} +  \\frac{n_0}{n} \\hat{\\tau}_{\\text{ATU}}\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#distance-measures",
    "href": "slides/04_ob_conf.html#distance-measures",
    "title": "(4) Observed Confounding",
    "section": "Distance Measures",
    "text": "Distance Measures\n\nEuclidean Distance:\n\n\\(\\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert = \\sqrt{ \\sum_{k=1}^{K} (X_{jk} - X_{ik})^2 }\\)\nStandardized version by normalizing based on the variance of the covariates:\n\\(\\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert = \\sqrt{ \\sum_{k=1}^{K} \\frac{(X_{jk} - X_{ik})^2}{\\hat{\\text{Var}}(X_k)} }\\)\n\nMahalanobis Distance:\n\nIn addition, normalizing based on covariance with remaining covariates:\n\\(\\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert = \\sqrt{\\sum_{k=1}^{K} \\sum_{l=1}^{K} \\frac{(X_{jk} - X_{ik}) (X_{jl} - X_{il})}{\\hat{\\text{Cov}}(X_k, X_l)}}\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#m-matching",
    "href": "slides/04_ob_conf.html#m-matching",
    "title": "(4) Observed Confounding",
    "section": "1:M Matching",
    "text": "1:M Matching\n\n1:M matching with fixed M:\n\n\\(\\hat{\\tau}_{\\text{ATT}} = \\frac{1}{n_1} \\sum_{i:T_i=1} \\left[ Y_i - \\hat{\\mu_0}(\\mathbf{X_i}) \\right]\\) with \\(\\hat{\\mu}_{0}(\\mathbf{X_i}) = \\frac{1}{M} \\sum_{j \\in J(i:T_i=1)} Y_j\\)\n\\(\\hat{\\tau}_{\\text{ATU}} = \\frac{1}{n_0} \\sum_{i:T_i=0} \\left[ Y_i - \\hat{\\mu_1}(\\mathbf{X_i}) \\right]\\) with \\(\\hat{\\mu}_{1}(\\mathbf{X_i}) = \\frac{1}{M} \\sum_{j \\in J(i:T_i=0)} Y_j\\)\n\\(\\hat{\\tau}_{\\text{ATE}} = \\frac{n_1}{n} \\hat{\\tau}_{\\text{ATT}} +  \\frac{n_0}{n} \\hat{\\tau}_{\\text{ATU}}\\)\n\n\n\n\nRegression-based correction for the bias which comes from not finding fully comparable matches for a reference observation:\n\n\\(\\hat{\\mu}_{0}(\\mathbf{X_i}) = \\frac{1}{M} \\sum_{j \\in J(i:T_i=1)} [Y_j - (\\tilde{\\mu}_{0}(\\mathbf{X_j}) - \\tilde{\\mu}_{0}(\\mathbf{X_i}))]\\)\n\\(\\hat{\\mu}_{1}(\\mathbf{X_i}) = \\frac{1}{M} \\sum_{j \\in J(i:T_i=0)} [Y_j - (\\tilde{\\mu}_{1}(\\mathbf{X_j}) - \\tilde{\\mu}_{1}(\\mathbf{X_i}))]\\)\nwhere \\(\\tilde{\\mu}_{0}(\\mathbf{X_i})\\) (respectively, \\(\\tilde{\\mu}_{1}(\\mathbf{X_i})\\)) is the predicted value of \\(Y\\) for observation \\(i\\) from a regression of \\(Y\\) on \\(X\\) among the untreated (respectively, treated) group."
  },
  {
    "objectID": "slides/04_ob_conf.html#radius-caliper-matching",
    "href": "slides/04_ob_conf.html#radius-caliper-matching",
    "title": "(4) Observed Confounding",
    "section": "Radius (Caliper) Matching",
    "text": "Radius (Caliper) Matching\n\nCaliper \\(C\\) (implies a variable M):\n\n\\(\\hat{\\mu}_{0/1}(\\mathbf{X_i}) = \\frac{\\sum_{j : T_j = 0/1} I\\left(\\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert \\leq C \\right) \\cdot Y_i}{\\sum_{j : T_j = 0/1} I\\left(\\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert \\leq C \\right)}\\)\nWith a kernel function \\(\\kappa\\):\n\\(\\hat{\\mu}_{0/1}(\\mathbf{X_i}) = \\frac{\\sum_{j : T_j = 0/1} \\kappa\\left(\\frac{\\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert}{C}\\right) \\cdot Y_i}{\\sum_{j : T_j = 0/1} \\kappa\\left(\\frac{\\lVert \\mathbf{X_j} - \\mathbf{X_i} \\rVert}{C}\\right)}\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#covariate-matching-example",
    "href": "slides/04_ob_conf.html#covariate-matching-example",
    "title": "(4) Observed Confounding",
    "section": "Covariate Matching: Example",
    "text": "Covariate Matching: Example\n\nAssess the impact of participating in the U.S. National Supported Work (NSW) training program targeted to 445 individuals with social and economic problems on their real earnings.\n\n\nlibrary(Matching)                       # load Matching package for the data\ndata(lalonde)                           # load lalonde data\nattach(lalonde)                         # store all variables in own objects\nT = treat                               # define treatment (training)\nY = re78                                # define outcome \nX = cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates\npairmatching = Match(Y=Y, Tr=T, X=X)    # pair matching\nsummary(pairmatching)              # matching output\n\n\nEstimate...  1686.1 \nAI SE......  866.4 \nT-stat.....  1.9461 \np.val......  0.051642 \n\nOriginal number of observations..............  445 \nOriginal number of treated obs...............  185 \nMatched number of observations...............  185 \nMatched number of observations  (unweighted).  267 \n\npairmatching = Match(Y=Y, Tr=T, X=X, M=3, BiasAdjust = TRUE, estimand = \"ATE\", caliper = NULL)    # pair matching\nsummary(pairmatching)              # matching output\n\n\nEstimate...  1396.3 \nAI SE......  712.09 \nT-stat.....  1.9609 \np.val......  0.049893 \n\nOriginal number of observations..............  445 \nOriginal number of treated obs...............  185 \nMatched number of observations...............  445 \nMatched number of observations  (unweighted).  1525"
  },
  {
    "objectID": "slides/04_ob_conf.html#propensity-score-matching",
    "href": "slides/04_ob_conf.html#propensity-score-matching",
    "title": "(4) Observed Confounding",
    "section": "Propensity Score Matching",
    "text": "Propensity Score Matching\n\nCurse of dimensionality as caveat of covariate matching:\n\nDirectly controlling for and matching observations based on \\(\\mathbf{X}\\) in a flexible, non-parametric way increasingly difficult with many covariates.\nProbability to find matches with similar values in all covariates decays rapidly.\n\n\n\n\n\n\nInstead controlling for the Propensity Score:\n\nConditional treatment probability given the covariates, denoted by\n\\(PS(\\mathbf{X_i}) = P(T_i = 1 | \\mathbf{X_i})\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#propensity-score",
    "href": "slides/04_ob_conf.html#propensity-score",
    "title": "(4) Observed Confounding",
    "section": "Propensity Score",
    "text": "Propensity Score\n\nWe need the following theorem to hold:\n\n\n\n\nTheorem 4.1: “Propensity Score”.\n\n\nUnconfoundedness given \\(\\mathbf{X}\\) implies unconfoundedness given the propensity score \\(PS(\\mathbf{X})\\).\nFormally, \\((Y(1), Y(0)) \\perp\\!\\!\\!\\perp T \\, | \\, \\mathbf{X} \\implies (Y(1), Y(0)) \\perp\\!\\!\\!\\perp PS(\\mathbf{X})\\).\n\n\n\n\n\\(PS(\\mathbf{X_i})\\) can be viewed as dimension reduction tool\n\ncontrolling for a one-dimensional scalar instead of \\(\\mathbf{X}\\).\n\nIf theorem holds, then we can state for the treatments assignment mechanism: \\(P(T_i = 1 | Y_i(1), Y_i(0), PS(\\mathbf{X_i})) = P(T_i = 1 | PS(\\mathbf{X_i}))\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#propensity-score-1",
    "href": "slides/04_ob_conf.html#propensity-score-1",
    "title": "(4) Observed Confounding",
    "section": "Propensity Score",
    "text": "Propensity Score\n\nProof:\n\n\\[\n\\begin{align*}\nP(T_i = 1 | Y_i(1), Y_i(0), PS(\\mathbf{X_i})) &= \\mathbb{E}[T_i | Y_i(1), Y_i(0), PS(\\mathbf{X_i})] \\\\\n&\\text{(T is binary: turn probability into expectation)} \\\\\n&= \\mathbb{E}[\\mathbb{E}[T_i | Y_i(1), Y_i(0), PS(\\mathbf{X_i}), \\mathbf{X_i}] | Y_i(1), Y_i(0), PS(\\mathbf{X_i})] \\\\\n&\\text{(law of iterated expectations: introduce X)} \\\\\n&= \\mathbb{E}[\\mathbb{E}[T_i | Y_i(1), Y_i(0), \\mathbf{X_i}] | Y_i(1), Y_i(0), PS(\\mathbf{X_i})] \\\\\n&\\text{(remove PS(X) from inner expectation, because it is redundant if we have X)} \\\\\n&= \\mathbb{E}[\\mathbb{E}[T_i | \\mathbf{X_i}] | Y_i(1), Y_i(0), PS(\\mathbf{X_i})] \\\\\n&\\text{(apply original unconfoundedness and eliminate Y_i(t))} \\\\\n&= \\mathbb{E}[P(T_i = 1 | \\mathbf{X_i}) | Y_i(1), Y_i(0), PS(\\mathbf{X_i})] \\\\\n&\\text{(T is binary: turn expectation into probability)} \\\\\n&= \\mathbb{E}[PS(\\mathbf{X_i}) | Y_i(1), Y_i(0), PS(\\mathbf{X_i})] \\\\\n&\\text{(conditioning on itself makes addional info from Y_i(t) superfluous)} \\\\\n&= PS(\\mathbf{X_i}) = P(T_i = 1 | \\mathbf{X_i})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/04_ob_conf.html#propensity-score-estimation-and-use",
    "href": "slides/04_ob_conf.html#propensity-score-estimation-and-use",
    "title": "(4) Observed Confounding",
    "section": "Propensity Score Estimation and Use",
    "text": "Propensity Score Estimation and Use\n\nTrue \\(PS(\\mathbf{X_i})\\) for each observation \\(i\\) is unknown and needs to be estimated.\nTypically a parametric binary choice model is used of the form:\n\n\\(PS(\\mathbf{X_i}) = P(T_i = 1 | \\mathbf{X_i}) = \\Lambda(\\beta_0 + \\beta_1 X_{i1} + \\ldots + \\beta_k X_{ik})\\)\nNon-linear link function \\(\\Lambda\\):\n\nNormal distribution function: Probit regression model\nLogistic distribution function: Logit regression model\n\n\n\n\n\nParameters \\(\\mathbf{\\hat{\\beta}}\\) are estimated by maximum likelihood estimation (MLE):\n\n\\(\\mathbf{\\hat{\\beta}} = \\arg\\max_{\\beta} \\sum_{i=1}^n \\left[ T_i \\ln \\Lambda(\\beta_0 + \\beta_1 X_{i1} + \\ldots + \\beta_k X_{ik}) + (1 - T_i) \\ln (1 - \\Lambda(\\beta_0 + \\beta_1 X_{i1} + \\ldots + \\beta_k X_{ik})) \\right]\\)\n\n\\(\\hat{PS}(\\mathbf{X_i})\\) is then computed based on the following prediction:\n\n\\(\\hat{PS}(\\mathbf{X_i}) = \\Lambda(\\hat{\\beta}_0 + \\hat{\\beta}_1 X_{i1} + \\ldots + \\hat{\\beta}_k X_{ik})\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#propensity-score-use",
    "href": "slides/04_ob_conf.html#propensity-score-use",
    "title": "(4) Observed Confounding",
    "section": "Propensity Score Use",
    "text": "Propensity Score Use\n\nPropensity scores \\(\\hat{PS}(\\mathbf{X_i})\\) can then be used as a single scalar covariate in:\n\n\nConditional outcome regression\n\n\nCovariate matching\n\n\nInverse probability weighting (IPW)\n\n\nInference needs to take into account the estimation uncertainty of \\(\\hat{PS}(\\mathbf{X_i})\\) via:\n\n\nBias correction in variance estimation\n\n\nBootstrapping"
  },
  {
    "objectID": "slides/04_ob_conf.html#propensity-score-matching-example",
    "href": "slides/04_ob_conf.html#propensity-score-matching-example",
    "title": "(4) Observed Confounding",
    "section": "Propensity Score Matching: Example",
    "text": "Propensity Score Matching: Example\n\nAssess the impact of participating in the U.S. National Supported Work (NSW) training program targeted to 445 individuals with social and economic problems on their real earnings.\n\n\n\n\nlibrary(Matching)                       # load Matching package for the data\ndata(lalonde)                           # load lalonde data\nattach(lalonde)                         # store all variables in own objects\nT = treat                               # define treatment (training)\nY = re78                                # define outcome \nX = cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates\nps = glm(T ~ X, family=binomial)$fitted # estimate the propensity score by logit\npsmatching=Match(Y=Y, Tr=T, X=ps, BiasAdjust = TRUE, estimand = \"ATE\") # propensity score matching\nsummary(psmatching)              # matching output\n\n\nEstimate...  1590.7 \nAI SE......  700.77 \nT-stat.....  2.2699 \np.val......  0.023211 \n\nOriginal number of observations..............  445 \nOriginal number of treated obs...............  185 \nMatched number of observations...............  445 \nMatched number of observations  (unweighted).  709 \n\n\n\n\nlibrary(Matching)                       # load Matching package\nlibrary(boot)                           # load boot package\ndata(lalonde)                           # load lalonde data\nattach(lalonde)                         # store all variables in own objects\nT=treat                                 # define treatment (training)\nY=re78                                  # define outcome \nX=cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates\nbs=function(data, indices) {            # defines function bs for bootstrapping\n  dat=data[indices,]                    # bootstrap sample according to indices \n  ps=glm(dat[,2:ncol(dat)],data=dat,family=binomial)$fitted # propensity score\n  effect=Match(Y=dat[,1], Tr=dat[,2], X=ps, BiasAdjust = TRUE, estimand = \"ATE\")$est # ATET \n  return(effect)                        # returns the estimated ATET\n}                                       # closes the function bs   \nbootdata=data.frame(Y,T,X)              # data frame for bootstrap procedure\nset.seed(1)                             # set seed\nresults = boot(data=bootdata, statistic=bs, R=999) # 999 bootstrap estimations \nresults                                 # displays the results\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = bootdata, statistic = bs, R = 999)\n\n\nBootstrap Statistics :\n    original  bias    std. error\nt1*  1590.71 41.8785    771.4947\n\ntstat=results$t0/sd(results$t)          # compute the t-statistic\n2*pnorm(-abs(tstat))                    # compute the p-value\n\n           [,1]\n[1,] 0.03922158"
  },
  {
    "objectID": "slides/04_ob_conf.html#inverse-probability-weighting-idea",
    "href": "slides/04_ob_conf.html#inverse-probability-weighting-idea",
    "title": "(4) Observed Confounding",
    "section": "Inverse Probability Weighting: Idea",
    "text": "Inverse Probability Weighting: Idea\n\nCreating a pseudo-population where the treatment assignment is independent of the observed covariates:\n\nWeighting each observation by the inverse of the estimated propensity score.\n\nThis idea can be expressed in the following theorem:\n\n\n\n\nTheorem 4.2: “Inverse Propensity Score Weighting”.\n\n\nGiven \\((Y(1), Y(0)) \\perp\\!\\!\\!\\perp T \\, | \\, \\mathbf{X}\\) (conditional unconfoundedness) and given \\(0 &lt; PS(\\mathbf{X_i}) &lt; 1\\) for all \\(i\\) (positivity), then:\n\\[\\tau_{\\text{ATE}} = \\mathbb{E}[Y_i(1) - Y_i(0)] = \\mathbb{E}[\\frac{T_iY_i}{PS(\\mathbf{X_i})}] - \\mathbb{E}[\\frac{(1-T_i)Y_i}{1-PS(\\mathbf{X_i})}]\\]"
  },
  {
    "objectID": "slides/04_ob_conf.html#inverse-propensity-score-weighting",
    "href": "slides/04_ob_conf.html#inverse-propensity-score-weighting",
    "title": "(4) Observed Confounding",
    "section": "Inverse Propensity Score Weighting",
    "text": "Inverse Propensity Score Weighting\n\nProof for \\(\\mathbb{E}[Y_i(1)]\\):\n\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[\\frac{T_iY_i}{PS(\\mathbf{X_i})}\\right] = \\mathbb{E}\\left[\\frac{T_iY_i(1)}{PS(\\mathbf{X_i})}\\right] &= \\mathbb{E}\\left[\\mathbb{E}\\left[\\frac{T_iY_i(1)}{PS(\\mathbf{X_i})} \\bigg| \\mathbf{X_i}\\right]\\right] \\\\\n&\\text{(law of iterated expectations: introduce X)} \\\\\n&= \\mathbb{E}\\left[\\frac{1}{PS(\\mathbf{X_i})} \\mathbb{E}[T_iY_i(1) | \\mathbf{X_i}]\\right] \\\\\n&\\text{(1/PS(X) is non-random given X, so it can be moved outside)} \\\\\n&= \\mathbb{E}\\left[\\frac{1}{e(X)} \\mathbb{E}(Z | X) \\mathbb{E}(Y_i(1) | \\mathbf{X_i})\\right] \\\\\n&\\text{(condional ignorability between T and Y(1) allows to separate expectations)} \\\\\n&= \\mathbb{E}\\left[\\frac{1}{PS(\\mathbf{X_i})} PS(\\mathbf{X_i}) \\mathbb{E}[Y_i(1) | \\mathbf{X_i}]\\right] \\\\\n&\\text{(E(Z∣X)=PS(X) by definition, terms cancel out)} \\\\\n&= \\mathbb{E}\\left[\\mathbb{E}[Y_i(1) | \\mathbf{X_i}]\\right] = \\mathbb{E}[Y_i(1)] \\\\\n&\\text{(law of iterated expectations)} \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/04_ob_conf.html#ipw-estimators",
    "href": "slides/04_ob_conf.html#ipw-estimators",
    "title": "(4) Observed Confounding",
    "section": "IPW Estimators",
    "text": "IPW Estimators\n\nTheorem 4.2 motivates the following estimator for ATE:\n\n\\(\\hat{\\tau}_{ATE} = \\frac{1}{n} \\sum_{i=1}^n \\frac{T_i Y_i}{\\hat{PS}(\\mathbf{X_i})} - \\frac{1}{n} \\sum_{i=1}^n \\frac{(1 - T_i) Y_i}{1 - \\hat{PS}(\\mathbf{X_i})}\\)\n\nNormalize the weights so that they sum up to one within the treatment groups:\n\n\\(\\hat{\\tau}_{ATE} = \\frac{\\sum_{i=1}^n \\frac{T_i Y_i}{\\hat{PS}(\\mathbf{X_i})}}{\\sum_{i=1}^n \\frac{T_i}{\\hat{PS}(\\mathbf{X_i})}} - \\frac{\\sum_{i=1}^n \\frac{(1 - T_i) Y_i}{1 - \\hat{PS}(\\mathbf{X_i})}}{\\sum_{i=1}^n \\frac{1 - T_i}{1 - \\hat{PS}(\\mathbf{X_i})}}\\)\n\n\n\n\nIPW variant Empirical Likelihood (EL) estimator:\n\nEstimating the propensity score parameters while enforcing a moment condition (e.g., equal covariate means, variances etc. across treatment groups):\n\\(\\sum_{i=1}^n \\frac{1}{n} \\left[ \\tilde{X}_i \\cdot T_i - \\frac{ \\tilde{X}_i \\cdot (1 - T_i) \\cdot \\tilde{PS}(\\mathbf{X_i})}{1 - \\tilde{PS}(\\mathbf{X_i})} \\right] = 0\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#inverse-probability-weighting-example",
    "href": "slides/04_ob_conf.html#inverse-probability-weighting-example",
    "title": "(4) Observed Confounding",
    "section": "Inverse Probability Weighting: Example",
    "text": "Inverse Probability Weighting: Example\n\nAssess the impact of participating in the U.S. National Supported Work (NSW) training program targeted to 445 individuals with social and economic problems on their real earnings.\n\n\n\n\nNormalized IPW estimator:\n\n\nlibrary(causalweight)                   # load causalweight package\nlibrary(Matching)                       # load Matching package for the data\ndata(lalonde)                           # load lalonde data\nattach(lalonde)                         # store all variables in own objects\nT = treat                               # define treatment (training)\nY = re78                                # define outcome \nX = cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates\nset.seed(1)                             # set seed\nipw=treatweight(y=Y,d=T,x=X, boot=999)  # run IPW with 999 bootstraps \nipw$effect                              # show ATE\n\n[1] 1640.468\n\nipw$se                                  # show standard error\n\n[1] 678.4239\n\nipw$pval                                # show p-value\n\n[1] 0.01560364\n\n\n\n\nEmpirical Likelihood (EL) estimator to ensure mean covariate balance:\n\n\nlibrary(Matching)                       # load Matching package\ndata(lalonde)                           # load lalonde data\nattach(lalonde)                         # store all variables in own objects\nlibrary(CBPS)                           # load CBPS package\nlibrary(lmtest)                         # load lmtest package\nlibrary(sandwich)                       # load sandwich package\nT = treat                              # define treatment (training)\nY = re78                                # define outcome \nX = cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates\ncbps = CBPS(T ~ X, ATT = 0)                 # covariate balancing for ATE estimation\nresults = lm(Y ~ T, weights = cbps$weights)   # weighted regression\ncoeftest(results, vcov = vcovHC)        # show results\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4582.71     353.65 12.9582  &lt; 2e-16 ***\nT            1699.74     705.11  2.4106  0.01633 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/04_ob_conf.html#doubly-robust-methods-idea",
    "href": "slides/04_ob_conf.html#doubly-robust-methods-idea",
    "title": "(4) Observed Confounding",
    "section": "Doubly Robust Methods: Idea",
    "text": "Doubly Robust Methods: Idea\n\nUnder conditional unconfoundedness (\\(Y(1), Y(0)) \\perp\\!\\!\\!\\perp T \\, | \\, \\mathbf{X}\\)) and positivity (\\(0 &lt; PS(\\mathbf{X_i}) &lt; 1\\)) we have seen two ways to identify the ATE:\n\nConditional outcome regression:\n\n\\(\\tau_{\\text{ATE}} = \\mathbb{E}[\\mathbb{E}[Y_i | T_i = 1, \\mathbf{X_i}] - \\mathbb{E}[Y_i | T_i = 0, \\mathbf{X_i}]] = \\mathbb{E}[\\mu_1(\\mathbf{X_i}) - \\mu_0(\\mathbf{X_i})]\\)\n\nInverse probability weighting:\n\n\\(\\tau_{\\text{ATE}} = \\mathbb{E}\\left[\\frac{T_i Y_i}{PS(\\mathbf{X_i})} - \\frac{(1 - T_i) Y_i}{1 - PS(\\mathbf{X_i})}\\right]\\)\n\n\n\n\n\nIdea of doubly robust methods:\n\nCombine both approaches, such that the ATE estimator is consistent, even if only one of the two models is correctly specified."
  },
  {
    "objectID": "slides/04_ob_conf.html#doubly-robust-estimator-definition",
    "href": "slides/04_ob_conf.html#doubly-robust-estimator-definition",
    "title": "(4) Observed Confounding",
    "section": "Doubly Robust Estimator: Definition",
    "text": "Doubly Robust Estimator: Definition\n\nDoubly robust estimator is also called the Augmented Inverse Propensity Score Weighting (AIPW) estimator.\nAugmenting the outcome regression model with IPW weights:\n\n\\(\\tilde{\\mu}_{1}^{\\text{dr}} = \\mathbb{E}\\left[\\frac{T_i(Y_i - \\mu_1(X_i, \\beta_1))}{PS(\\mathbf{X_i, \\beta_{PS}})} + \\mu_1(\\mathbf{X_i,\\beta_1})\\right]\\)\n\\(\\tilde{\\mu}_{0}^{\\text{dr}} = \\mathbb{E}\\left[\\frac{(1-T_i)(Y_i - \\mu_0(X_i, \\beta_0))}{1 - PS(\\mathbf{X_i, \\beta_{PS}})} + \\mu_0(\\mathbf{X_i,\\beta_0})\\right]\\)\n\nOr rewrite, to augment the IPW estimator with outcome regression model:\n\n\\(\\tilde{\\mu}_{1}^{\\text{dr}} = \\mathbb{E}\\left[\\frac{T_iY_i}{PS(\\mathbf{X_i, \\beta_{PS}})} - \\frac{T_i - PS(\\mathbf{X_i, \\beta_{PS}})}{PS(\\mathbf{X_i, \\beta_{PS}})}\\mu_1(\\mathbf{X_i,\\beta_1})\\right]\\)\n\\(\\tilde{\\mu}_{0}^{\\text{dr}} = \\mathbb{E}\\left[\\frac{(1-T_i)Y_i}{1-PS(\\mathbf{X_i, \\beta_{PS}})} - \\frac{PS(\\mathbf{X_i, \\beta_{PS}}) - T_i}{1-PS(\\mathbf{X_i, \\beta_{PS}})}\\mu_0(\\mathbf{X_i,\\beta_0})\\right]\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#doubly-robust-estimator-theorem",
    "href": "slides/04_ob_conf.html#doubly-robust-estimator-theorem",
    "title": "(4) Observed Confounding",
    "section": "Doubly Robust Estimator: Theorem",
    "text": "Doubly Robust Estimator: Theorem\n\nAugmentation leads to the following theoretical properties:\n\n\n\n\nTheorem 4.3: “Doubly Robust Estimator”.\n\n\nGiven \\((Y(1), Y(0)) \\perp\\!\\!\\!\\perp T \\, | \\, \\mathbf{X}\\) (conditional unconfoundedness) and given \\(0 &lt; PS(\\mathbf{X_i}) &lt; 1\\) for all \\(i\\) (positivity), then:\n\nIf either \\(PS(\\mathbf{X_i, \\beta_{PS}}) = PS(\\mathbf{X_i})\\) or \\(\\mu_1(\\mathbf{X_i,\\beta_1}) = \\mu_1(\\mathbf{X_i})\\), then \\(\\tilde{\\mu}_{1}^{\\text{dr}} = \\mathbb{E}[Y_i(1)]\\)\nIf either \\(PS(\\mathbf{X_i, \\beta_{PS}}) = PS(\\mathbf{X_i})\\) or \\(\\mu_0(\\mathbf{X_i,\\beta_0}) = \\mu_0(\\mathbf{X_i})\\), then \\(\\tilde{\\mu}_{0}^{\\text{dr}} = \\mathbb{E}[Y_i(0)]\\)\nIf either \\(PS(\\mathbf{X_i, \\beta_{PS}}) = PS(\\mathbf{X_i})\\) or \\(\\{\\mu_1(\\mathbf{X_i,\\beta_1}) = \\mu_1(\\mathbf{X_i}), \\mu_0(\\mathbf{X_i,\\beta_0}) = \\mu_0(\\mathbf{X_i})\\}\\), then \\(\\tilde{\\mu}_{1}^{\\text{dr}} - \\tilde{\\mu}_{0}^{\\text{dr}} = \\tau_{\\text{ATE}}^{\\text{dr}}\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#doubly-robust-estimator-theorem-1",
    "href": "slides/04_ob_conf.html#doubly-robust-estimator-theorem-1",
    "title": "(4) Observed Confounding",
    "section": "Doubly Robust Estimator: Theorem",
    "text": "Doubly Robust Estimator: Theorem\n\nProof for \\(\\tilde{\\mu}_{1}^{\\text{dr}} = \\mathbb{E}[Y_i(1)]\\):\n\n\\[\n\\begin{align*}\n\\tilde{\\mu}_{1}^{\\text{dr}} - \\mathbb{E}[Y_i(1)] &= \\mathbb{E}\\left[\\frac{T_i(Y_i(1) - \\mu_1(X_i, \\beta_1))}{PS(\\mathbf{X_i, \\beta_{PS}})} - (Y_i(1) - \\mu_1(\\mathbf{X_i,\\beta_1}))\\right] \\\\\n&\\text{(by definition)} \\\\\n&= \\mathbb{E}\\left[\\frac{T_i - PS(\\mathbf{X_i, \\beta_{PS}})}{PS(\\mathbf{X_i, \\beta_{PS}})}(Y_i(1) - \\mu_1(\\mathbf{X_i,\\beta_1}))\\right] \\\\\n&\\text{(combining terms)} \\\\\n&= \\mathbb{E}\\left(\\mathbb{E}\\left[\\frac{T_i - PS(\\mathbf{X_i, \\beta_{PS}})}{PS(\\mathbf{X_i, \\beta_{PS}})}(Y_i(1) - \\mu_1(\\mathbf{X_i,\\beta_1})) \\bigg| \\mathbf{X_i}\\right]\\right) \\\\\n&\\text{(law of iterated expectations)} \\\\\n&= \\mathbb{E}\\left(\\mathbb{E}\\left[\\frac{T_i - PS(\\mathbf{X_i, \\beta_{PS}})}{PS(\\mathbf{X_i, \\beta_{PS}})} \\bigg| \\mathbf{X_i}\\right] \\cdot \\mathbb{E}\\left[Y_i(1) - \\mu_1(\\mathbf{X_i,\\beta_1})) \\bigg| \\mathbf{X_i}\\right]\\right) \\\\\n&\\text{(ignorability allows to separate expectations)} \\\\\n&= \\mathbb{E}\\left(\\frac{PS(\\mathbf{X_i}) - PS(\\mathbf{X_i, \\beta_{PS}})}{PS(\\mathbf{X_i, \\beta_{PS}})}  \\cdot \\left(\\mu_1(\\mathbf{X_i}) - \\mu_1(\\mathbf{X_i,\\beta_1})) \\right)\\right) \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "slides/04_ob_conf.html#doubly-robust-estimator-sample-version",
    "href": "slides/04_ob_conf.html#doubly-robust-estimator-sample-version",
    "title": "(4) Observed Confounding",
    "section": "Doubly Robust Estimator: Sample Version",
    "text": "Doubly Robust Estimator: Sample Version\n\nStep 1: obtain the fitted values of the propensity scores:\n\n\\(PS(\\mathbf{X_i, \\hat{\\beta}_{PS}})\\).\n\nStep 2: obtain the fitted values of the outcome regressions:\n\n\\(\\mu_1(\\mathbf{X_i,\\hat{\\beta_1}})\\) and \\(\\mu_0(\\mathbf{X_i,\\hat{\\beta_0}})\\).\n\nStep 3: construct the doubly robust estimator:\n\n\\(\\hat{\\tau}_{\\text{ATE}}^{\\text{dr}} = \\hat{\\mu}_{1}^{\\text{dr}} - \\hat{\\mu}_{0}^{\\text{dr}}\\) with (definition of augmented outcome model)\n\\(\\hat{\\mu}_{1}^{\\text{dr}} = \\frac{1}{n} \\sum_{i=1}^n \\left[\\frac{T_i(Y_i - \\mu_1(X_i, \\hat{\\beta_1)})}{PS(\\mathbf{X_i, \\hat{\\beta}_{PS}})} + \\mu_1(\\mathbf{X_i,\\hat{\\beta_1}})\\right]\\)\n\\(\\hat{\\mu}_{0}^{\\text{dr}} = \\frac{1}{n} \\sum_{i=1}^n \\left[\\frac{(1-T_i)(Y_i - \\mu_0(X_i, \\hat{\\beta_0)})}{1- PS(\\mathbf{X_i, \\hat{\\beta}_{PS}})} + \\mu_0(\\mathbf{X_i,\\hat{\\beta_0}})\\right]\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#doubly-robust-estimator-sample-version-1",
    "href": "slides/04_ob_conf.html#doubly-robust-estimator-sample-version-1",
    "title": "(4) Observed Confounding",
    "section": "Doubly Robust Estimator: Sample Version",
    "text": "Doubly Robust Estimator: Sample Version\n\nBy definition of the augmented IPW estimator, we can also write:\n\n\\(\\hat{\\mu}_{1}^{\\text{dr}} = \\mathbb{E}\\left[\\frac{T_iY_i}{PS(\\mathbf{X_i, \\hat{\\beta}_{PS}})} - \\frac{T_i - PS(\\mathbf{X_i, \\hat{\\beta_{PS}}})}{PS(\\mathbf{X_i, \\hat{\\beta_{PS}}})}\\mu_1(\\mathbf{X_i,\\hat{\\beta_1}})\\right]\\)\n\\(\\hat{\\mu}_{0}^{\\text{dr}} = \\mathbb{E}\\left[\\frac{(1-T_i)Y_i}{1-PS(\\mathbf{X_i, \\hat{\\beta_{PS}}})} - \\frac{PS(\\mathbf{X_i, \\hat{\\beta_{PS}}}) - T_i}{1-PS(\\mathbf{X_i, \\hat{\\beta_{PS}}})}\\mu_0(\\mathbf{X_i,\\hat{\\beta_0}})\\right]\\)\n\n\n\n\nFinally, in augmentation perspective:\n\n\\(\\hat{\\tau}_{\\text{ATE}}^{\\text{dr}} = \\hat{\\tau}_{\\text{ATE}}^{\\text{reg}} + \\frac{1}{n} \\sum_{i=1}^n \\frac{T_i(Y_i - \\mu_1(X_i, \\hat{\\beta_1)})}{PS(\\mathbf{X_i, \\hat{\\beta}_{PS}})} - \\frac{1}{n} \\sum_{i=1}^n \\frac{(1-T_i)(Y_i - \\mu_0(X_i, \\hat{\\beta_0)})}{1 - PS(\\mathbf{X_i, \\hat{\\beta}_{PS}})}\\)\n\\(\\hat{\\tau}_{\\text{ATE}}^{\\text{dr}} = \\hat{\\tau}_{\\text{ATE}}^{\\text{ipw}} - \\frac{1}{n} \\sum_{i=1}^n \\frac{T_i - PS(\\mathbf{X_i, \\hat{\\beta_{PS}}})}{PS(\\mathbf{X_i, \\hat{\\beta_{PS}}})}\\mu_1(\\mathbf{X_i,\\hat{\\beta_1}}) + \\frac{1}{n} \\sum_{i=1}^n \\frac{PS(\\mathbf{X_i, \\hat{\\beta_{PS}}}) - T_i}{1-PS(\\mathbf{X_i, \\hat{\\beta_{PS}}})}\\mu_0(\\mathbf{X_i,\\hat{\\beta_0}})\\)"
  },
  {
    "objectID": "slides/04_ob_conf.html#doubly-robust-estimator-example",
    "href": "slides/04_ob_conf.html#doubly-robust-estimator-example",
    "title": "(4) Observed Confounding",
    "section": "Doubly Robust Estimator: Example",
    "text": "Doubly Robust Estimator: Example\n\nAssess the impact of participating in the U.S. National Supported Work (NSW) training program targeted to 445 individuals with social and economic problems on their real earnings.\n\n\nlibrary(Matching)                       # load Matching package\nlibrary(drgee)                          # load drgee package\nT = treat                              # define treatment (training)\nY = re78                                # define outcome \nX = cbind(age,educ,nodegr,married,black,hisp,re74,re75,u74,u75) # covariates\ndr = drgee(oformula = formula(Y ~ X), eformula = formula(T ~ X), elink=\"logit\") # DR reg\nsummary(dr)                             # show results\n\n\nCall:  drgee(oformula = formula(Y ~ X), eformula = formula(T ~ X), elink = \"logit\")\n\nOutcome:  Y \n\nExposure:  T \n\nCovariates:  Xage,Xeduc,Xnodegr,Xmarried,Xblack,Xhisp,Xre74,Xre75,Xu74,Xu75 \n\nMain model:  Y ~ T \n\nOutcome nuisance model:  Y ~ Xage + Xeduc + Xnodegr + Xmarried + Xblack + Xhisp + Xre74 + Xre75 + Xu74 + Xu75 \n\nOutcome link function:  identity \n\nExposure nuisance model:  T ~ Xage + Xeduc + Xnodegr + Xmarried + Xblack + Xhisp + Xre74 + Xre75 + Xu74 + Xu75 \n\nExposure link function:  logit \n\n  Estimate Std. Error z value Pr(&gt;|z|)  \nT   1674.1      672.4    2.49   0.0128 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Note: The estimated parameters quantify the conditional\nexposure-outcome association, given the covariates\nincluded in the nuisance models)\n\n 445  complete observations used"
  },
  {
    "objectID": "slides/06_hte.html#treatment-effect-heterogeneity-motivation",
    "href": "slides/06_hte.html#treatment-effect-heterogeneity-motivation",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Treatment Effect Heterogeneity: Motivation",
    "text": "Treatment Effect Heterogeneity: Motivation\n\nMore comprehensive evaluation:\n\nwho wins or loses and by how much?\n\nThis is useful along at least two dimensions:\n\nInforms action:\n\nMore efficient allocation of public and private resources via targeting in the future:\n\nPersonalized policies, ads, medicine, …\n\n\nUnderstanding:\n\nHeterogeneous effects can be suggestive for underlying mechanisms"
  },
  {
    "objectID": "slides/06_hte.html#treatment-effect-heterogeneity-definition",
    "href": "slides/06_hte.html#treatment-effect-heterogeneity-definition",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Treatment Effect Heterogeneity: Definition",
    "text": "Treatment Effect Heterogeneity: Definition\n\nExpected treatment effect in the target subpopulation with characteristics \\(\\mathbf{X_i}\\) given by Conditional Average Treatment Effect (CATE):\n\n\\(\\tau(\\mathbf{x}) = \\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{X_i = x}]\\)\n\n\n\n\n\\(\\mathbf{X_i} = \\mathbf{H_i} \\cup \\mathbf{C_i}\\)\n\n\\(\\mathbf{H_i}\\): motivated by the research question to understand specific effect heterogeneity in a pre-defined the target subpopulation.\n\\(\\mathbf{C_i}\\): confounders that are required for identification.\n\n\n\n\n\nRandomized experiments - no confounders:\n\nCATE defined with respect to considered heterogeneity variables: \\(\\mathbf{X_i} = \\mathbf{H_i}\\)\n\n\n\n\n\nMeasured Confounding - distinguish two types of CATEs:\n\nGroup ATE (GATE) for groups G defined by H: \\(\\tau(\\mathbf{g}) = \\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{G_i = g}]\\)\nIndividualized ATE (IATE = CATE): \\(\\tau(\\mathbf{x}) = \\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{X_i = x}]\\)\n\nmost flexible/ personalized/ individualized effect prediction\n\nEstimation step is affected by whether we are interested in GATEs or IATEs."
  },
  {
    "objectID": "slides/06_hte.html#treatment-effect-heterogeneity-identification",
    "href": "slides/06_hte.html#treatment-effect-heterogeneity-identification",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Treatment Effect Heterogeneity: Identification",
    "text": "Treatment Effect Heterogeneity: Identification\n\nNo need to establish new identification results:\n\nAll target parameters can be thought of as special cases of conditioning ITE on some function \\(f(\\mathbf{X_i = x})\\)\nAnd by the Law of Iterated Expectations (LIE):\n\n\n\\[\n\\begin{align*}\n\\mathbb{E}[Y_i(1) - Y_i(0) | f(\\mathbf{X_i}) = f(\\mathbf{x})] &= \\mathbb{E}[\\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{X_i = x}, f(\\mathbf{X_i = x}) ] | f(\\mathbf{X_i = x})] \\\\\n&= \\mathbb{E}[\\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{X_i = x} ] | f(\\mathbf{X_i = x})]\n\\end{align*}\n\\]\n\n\nAs \\(\\mathbf{X_i} = \\mathbf{H_i} \\cup \\mathbf{C_i}\\) is assumed to contain all confounders, the inner expectation \\(\\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{X_i = x} ]\\) is identified in randomized experiments or under measured confounding\n=&gt; All aggregations with respect to a function \\(f(\\mathbf{X_i})\\) are also identified."
  },
  {
    "objectID": "slides/06_hte.html#group-ates-examples",
    "href": "slides/06_hte.html#group-ates-examples",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Group ATEs: Examples",
    "text": "Group ATEs: Examples\n\nGroup ATE (GATE): \\(\\tau(\\mathbf{g}) = \\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{G_i = g}]\\)\nExamples for subgroups of interest:\n\nMutually exclusive subgroups, e.g.: \\(G = \\{\\text{female}, \\text{male}\\}\\), \\(G = \\{ \\text{age} &lt; 50, \\text{age} \\geq 50 \\}\\), \\(G = \\{ \\text{age} &lt; 50 \\space \\& \\space \\text{female}, \\text{age} \\geq 50 \\space \\& \\space \\text{female}, \\text{age} \\geq 50 \\space \\& \\space \\text{male}, \\dots  \\}\\), …\nSingle or low-dimensional continuous variable, e.g.: G = age, G = income, …\nOther functions or small subsets of \\(\\mathbf{X_i}\\)\n\nGroups should be pre-determined and not be the result of data snooping"
  },
  {
    "objectID": "slides/06_hte.html#group-ates-estimation",
    "href": "slides/06_hte.html#group-ates-estimation",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Group ATEs: Estimation",
    "text": "Group ATEs: Estimation\n\nThree strategies:\n\nStratify the data and rerun the analysis for each subgroup.\n\nDownside: Requires a lot of data and computation, can lead to high variance estimates for small subgroups.\n\nSpecify an interaction term in an OLS regression model:\n\n\\(Y_i = \\beta_{0} + \\tau T_i + \\beta_{G_i} G_{i} + \\beta_{T_iG_i} T_{i} G_{i} + \\mathbf{\\beta_{X_i}X_{i}}+ \\epsilon_i\\)\nDownside: Requires a correct model specification, can be sensitive to misspecification.\n\nDouble Machine Learning with AIPW model to estimate the GATEs directly."
  },
  {
    "objectID": "slides/06_hte.html#group-ates-double-machine-learning",
    "href": "slides/06_hte.html#group-ates-double-machine-learning",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Group ATEs: Double Machine Learning",
    "text": "Group ATEs: Double Machine Learning\n\nPrevious lecture: ATE (AIPW) can be estimated as mean of a pseudo-outcome:\n\n\\(\\hat{\\tau}_{\\text{ATE}}^{\\text{AIPW}} = \\frac{1}{N}\\sum_{i=1}^n \\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}}\\)\n\nPseudo-outcome is given by:\n\n\\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} = \\hat{\\mu}(1, \\mathbf{X_i}) - \\hat{\\mu}(0, \\mathbf{X_i}) + \\frac{T_i(Y_i - \\hat{\\mu}(1, \\mathbf{X_i}))}{\\hat{e}_1(\\mathbf{X_i})} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}(0, \\mathbf{X_i})}{\\hat{e}_0(\\mathbf{X_i}))}\\)\n\n\n\n\nEquivalent to a linear regression model with pseudo-outcome and constant:\n\n\\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} = \\alpha + \\epsilon_i\\) with \\(\\hat{\\alpha} = \\hat{\\tau}_{\\text{ATE}}^{\\text{AIPW}}\\)\n\nCan be extended with heterogeneity variable(s) \\(G_i\\):\n\n\\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} = \\alpha + \\beta G_i + \\epsilon_i\\)\n=&gt; Modelling the level of the effect, not the level of the outcome."
  },
  {
    "objectID": "slides/06_hte.html#group-ates-advantages-of-dml",
    "href": "slides/06_hte.html#group-ates-advantages-of-dml",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Group ATEs: Advantages of DML",
    "text": "Group ATEs: Advantages of DML\n\nNeyman-orthogonality of \\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}}\\) allows to apply standard statistical inference (Semenova and Chernozhukov, 2021).\nComputationally less expensive than subgroup analyses\n\nOnly one additional OLS, no new nuisance parameters).\n\nMore flexible than specifying interaction terms in a linear model, as we flexibly adjust for confounding by ML methods.\nAs \\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}}\\) is an unbiased signal, i.e. \\(\\mathbb{E}[\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} | G_i = g] = \\tau(g)\\), to regress the pseudo-outcome \\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}}\\) on low-dimensional \\(G_i\\) we can either use\n\nOLS or series regression (Semenova and Chernozhukov, 2021).\nKernel regression (Fan et al., 2022; Zimmert & Lechner, 2019)."
  },
  {
    "objectID": "slides/06_hte.html#group-ates-proof-of-dml",
    "href": "slides/06_hte.html#group-ates-proof-of-dml",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Group ATEs: Proof of DML",
    "text": "Group ATEs: Proof of DML\n\nProof that \\(\\mathbb{E}[\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} \\mid G_i = g] = \\tau(g)\\):\n\n\\[\n\\begin{align*}\n\\mathbb{E}[\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} \\mid G_i = g] &= \\mathbb{E} \\left[  \\mu(1,\\mathbf{X_i}) + \\frac{T_i(Y_i - \\mu(1,\\mathbf{X_i}))}{e(\\mathbf{X_i})} - \\mu(0,\\mathbf{X_i}) - \\frac{(1-T_i)(Y_i - \\mu(0,\\mathbf{X_i}))}{1 - e(\\mathbf{X_i})} \\bigg| G_i = g \\right] \\\\\n&\\overset{LIE}{=} \\mathbb{E} \\left[ \\underbrace{\\mathbb{E} \\left[ \\mu(1, \\mathbf{X_i}) + \\frac{T_i(Y_i - \\mu(1, \\mathbf{X_i}))}{e(\\mathbf{X_i})} \\mid \\mathbf{X_i = x} \\right]}_{\\text{CAPO-AIPW =&gt; }\\mathbb{E}[Y_i(1) \\mid \\mathbf{X_i = x}]} - \\underbrace{\\mathbb{E} \\left[ \\mu(0, \\mathbf{X_i}) + \\frac{(1-T_i)(Y_i - \\mu(0, \\mathbf{X_i}))}{1 - e(\\mathbf{X_i})} \\mid \\mathbf{X_i = x} \\right]}_{CAPO-AIPW =&gt; \\mathbb{E}[Y(0) \\mid \\mathbf{X_i = x}]} \\bigg| G_i = g \\right] \\\\\n&= \\mathbb{E}\\left[\\mathbb{E}[Y_i(1) \\mid \\mathbf{X_i = x}] - \\mathbb{E}[Y_i(0) \\mid \\mathbf{X_i = x}] \\bigg| G_i = g\\right] \\\\\n&\\overset{LIE}{=} \\mathbb{E}[Y_i(1) - Y_i(0) \\mid G_i = g] \\\\\n&= \\tau(g)\n\\end{align*}\n\\]\n\nLaw of Iterated Expectations uses that \\(G_i\\) is a function of \\(X_i\\)."
  },
  {
    "objectID": "slides/06_hte.html#group-ates-example-based-on-dml",
    "href": "slides/06_hte.html#group-ates-example-based-on-dml",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Group ATEs: Example based on DML",
    "text": "Group ATEs: Example based on DML\n\nAssess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.\nFirst step (not shown): Estimate \\(\\hat{\\tau}_{\\text{ATE}}^{\\text{AIPW}}\\) using DoubleML.\n\n\n\n\n# Get the indvidual ATEs (pseudo-outcomes)\ndata$ate_i &lt;- dml_irm_forest[[\"psi_b\"]] # get numerator of score function, which is equal to pseudo outcome\nmean_ate = mean(data$ate_i) # mean of pseudo outcomes = ATE\n\nlibrary(estimatr) # for linear robust post estimation\nsummary(lm_robust(ate_i ~ hown, data = data))\n\n\n\nEstimates and significance testing of the effect of target variables\n     Estimate. Std. Error t value Pr(&gt;|t|)    \ne401      8206       1106   7.421 1.16e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCall:\nlm_robust(formula = ate_i ~ hown, data = data)\n\nStandard error type:  HC2 \n\nCoefficients:\n            Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper   DF\n(Intercept)     3477        711   4.890 1.025e-06     2083     4870 9913\nhown            7445       1835   4.058 4.990e-05     3849    11041 9913\n\nMultiple R-squared:  0.00106 ,  Adjusted R-squared:  0.0009588 \nF-statistic: 16.47 on 1 and 9913 DF,  p-value: 4.99e-05\n\n\n\n\nlibrary(np) # for kernel post estimation\nage = data$age            \nate_i = data$ate_i                \nnp_model = npreg(ate_i ~ age)  # kernel regression\nplot(np_model)  # plot the kernel regression"
  },
  {
    "objectID": "slides/06_hte.html#predicting-individualized-ates",
    "href": "slides/06_hte.html#predicting-individualized-ates",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Predicting Individualized ATEs",
    "text": "Predicting Individualized ATEs\n\nGroup-level heterogeneity variables were hand-picked.\nNow predict individualized treatment effects based on all covariates \\(\\mathbf{X_i}\\):\n\nIndividualized ATE (IATE = CATE): \\(\\tau(\\mathbf{x}) = \\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{X_i = x}]\\)\nConditional expectation with unobserved outcome (counterfactuals)\n\nGiven the assumptions of observed confounding, we can write the CATE as:\n\n\\(\\tau(\\mathbf{x}) = \\mathbb{E}[Y_i(1) - Y_i(0) | \\mathbf{X_i = x}] = \\mathbb{E}[Y_i | T_i, \\mathbf{X_i = x}] - \\mathbb{E}[Y_i | T_i, \\mathbf{X_i = x}]\\)\nwhich can be approximated with ML."
  },
  {
    "objectID": "slides/06_hte.html#s-learner-and-t-learner",
    "href": "slides/06_hte.html#s-learner-and-t-learner",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "S-Learner and T-Learner",
    "text": "S-Learner and T-Learner\n\nS-learner:\n\n\nUse ML estimator of your choice to fit outcome model using \\(\\mathbf{X_i}\\) AND \\(T_i\\) in the full sample: \\(\\hat{\\mu}(T_i; \\mathbf{X_i})\\).\n\n\nEstimate CATE as \\(\\hat{\\tau}(\\mathbf{x}) = \\hat{\\mu}(1; \\mathbf{X_i}) - \\hat{\\mu}(0; \\mathbf{X_i})\\).\n\n\n\n\n\nT-learner:\n\n\nUse ML estimator of your choice to fit model \\(\\hat{\\mu}(1; \\mathbf{X_i})\\) in treated subsample.\n\n\nUse ML estimator of your choice to fit model \\(\\hat{\\mu}(0; \\mathbf{X_i})\\) in control subsample.\n\n\nEstimate CATE as \\(\\hat{\\tau}(\\mathbf{x}) = \\hat{\\mu}(1; \\mathbf{X_i}) - \\hat{\\mu}(0; \\mathbf{X_i})\\)."
  },
  {
    "objectID": "slides/06_hte.html#s-learner-and-t-learner-example",
    "href": "slides/06_hte.html#s-learner-and-t-learner-example",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "S-Learner and T-Learner: Example",
    "text": "S-Learner and T-Learner: Example\n\nAssess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.\nExamples without proper cross-fitting.\n\n\n\n\nlibrary(hdm) # for the data\nlibrary(grf) # generalized random forests, could also use mlr3\n\n\n# Get data\ndata(pension)\n# Outcome\nY = pension$net_tfa\n# Treatment\nT = pension$p401\n# Create main effects matrix\nX = model.matrix(~ 0 + age + db + educ + fsize + hown + inc + male + marr + pira + twoearn, data = pension)\n\n# Implement the S-Learner\nTX = cbind(T,X)\nrf = regression_forest(TX,Y)\nT0X = cbind(rep(0,length(Y)),X)\nT1X = cbind(rep(1,length(Y)),X)\ncate_sl = predict(rf,T1X)$predictions - predict(rf,T0X)$predictions\nhist(cate_sl)\n\n\n# Implement the T-Learner\nrfmu1 = regression_forest(X[T==1,],Y[T==1])\nrfmu0 = regression_forest(X[T==0,],Y[T==0])\ncate_tl = predict(rfmu1, X)$predictions - predict(rfmu0, X)$predictions\nhist(cate_tl)"
  },
  {
    "objectID": "slides/06_hte.html#s-learner-and-t-learner-disadvantage",
    "href": "slides/06_hte.html#s-learner-and-t-learner-disadvantage",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "S-Learner and T-Learner: Disadvantage",
    "text": "S-Learner and T-Learner: Disadvantage\n\nThe prediction problems do not know of joint goal to approximate a difference:\n\n\\(\\hat{\\mu}(1; \\mathbf{X_i})\\) minimizes \\(MSE(\\hat{\\mu}(1; \\mathbf{x})) = \\mathbb{E}[(\\hat{\\mu}(1; \\mathbf{x}) - \\mu(1; \\mathbf{X_i}))^2]\\).\n\\(\\hat{\\mu}(0; \\mathbf{X_i})\\) minimizes \\(MSE(\\hat{\\mu}(0; \\mathbf{x})) = \\mathbb{E}[(\\hat{\\mu}(0; \\mathbf{x}) - \\mu(0; \\mathbf{X_i}))^2]\\).\nBUT they should aim to minimize:\n\n\n\\[\n\\begin{align*}\n\\text{MSE}(\\hat{\\tau}(\\mathbf{x}))) &= \\mathbb{E}[(\\hat{\\tau}(\\mathbf{x})) - \\tau(\\mathbf{x})))^2] \\\\\n&= \\mathbb{E}[(\\hat{\\mu}(1, \\mathbf{x})) - \\hat{\\mu}(0, \\mathbf{x})) - (\\mu(1, \\mathbf{x})) - \\mu(0, \\mathbf{x}))))^2] \\\\\n&= \\mathbb{E}[(\\hat{\\mu}(1, \\mathbf{x})) - \\mu(1, \\mathbf{x})))^2] + \\mathbb{E}[(\\hat{\\mu}(0, \\mathbf{x})) - \\mu(0, \\mathbf{x})))^2] \\\\\n&\\quad - 2\\mathbb{E}[(\\hat{\\mu}(1, \\mathbf{x})) - \\mu(1, \\mathbf{x})))(\\hat{\\mu}(0, \\mathbf{x})) - \\mu(0, \\mathbf{x})))] \\\\\n&= \\text{MSE}(\\hat{\\mu}(1, \\mathbf{x}))) + \\text{MSE}(\\hat{\\mu}(0, \\mathbf{x}))) - 2\\text{MCE}(\\hat{\\mu}(1, \\mathbf{x})), \\hat{\\mu}(0, \\mathbf{x})))\n\\end{align*}\n\\]\n\n\nLechner (2018) calls the additional term Mean Correlated Error (MCE): correlated errors matter less\nExample - both make same error: \\(\\hat{\\mu}(1; \\mathbf{X_i}) = \\mu(1; \\mathbf{X_i}) + 2\\) and \\(\\hat{\\mu}(0; \\mathbf{X_i}) = \\mu(0; \\mathbf{X_i}) + 2\\)\n\nBut their CATE would still be on point: \\(MSE(\\hat{\\tau}(\\mathbf{x})) = 4 + 4 - 2(2 \\cdot 2) = 0\\)\n\nExample - errors go in different direction: \\(\\hat{\\mu}(1; \\mathbf{X_i}) = \\mu(1; \\mathbf{X_i}) + 2\\) and \\(\\hat{\\mu}(0; \\mathbf{X_i}) = \\mu(0; \\mathbf{X_i}) - 2\\)\n\nBut their CATE would be off: \\(MSE(\\hat{\\tau}(\\mathbf{x})) = 4 + 4 - 2(2 \\cdot (-2)) = 16\\)"
  },
  {
    "objectID": "slides/06_hte.html#two-approaches-to-improvements",
    "href": "slides/06_hte.html#two-approaches-to-improvements",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Two Approaches to Improvements",
    "text": "Two Approaches to Improvements\n\nModify supervised ML methods to target causal effect estimation\n\nMethod specific, e.g.:\n\nCausal tree (Athey and Imbens, 2016)\nCausal forest (Athey, Tibshirani & Wager, 2019)\n\nNot covered here (does not scale very well to high-dimensional data)\n\nCombine supervised ML methods to target causal effect estimation\n\nGeneric approach - Metalearners, e.g.:\n\nX-learner (Künzel et al., 2019)\n\nnot covered here; handles sample imbalance, but not doubly robust\n\nR-learner\nDR-learner"
  },
  {
    "objectID": "slides/06_hte.html#what-are-metalearners",
    "href": "slides/06_hte.html#what-are-metalearners",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "What are Metalearners?",
    "text": "What are Metalearners?\n\nMetalearners combine multiple supervised ML steps in a pipeline that outputs predicted CATEs.\nThe common ones require the following steps:\n\nEstimate nuisance parameters using suitable ML method.\nPlug them into a clever minimization problem targeting CATE.\nSolve the minimization problem using suitable ML method.\nPredict CATE using the model learned in 3.\n\nMost popular ML methods are suitable and can be applied in steps 1, 3 and 4.\nLike for standard prediction methods, statistical inference is usually not available."
  },
  {
    "objectID": "slides/06_hte.html#r-learner-idea",
    "href": "slides/06_hte.html#r-learner-idea",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "R-learner: Idea",
    "text": "R-learner: Idea\n\nPartially linear model, but now allowing for treatment effects that vary with \\(\\mathbf{X}\\):\n\n\\(Y_i = \\tau(\\mathbf{X_i}) T_i + g(\\mathbf{X_i}) + \\epsilon_{Y_i}, \\quad \\mathbb{E}(\\epsilon_{Y_i} | T_i,\\mathbf{X_i}) = 0\\)\n=&gt; \\(\\underbrace{Y_i - \\overbrace{\\mathbb{E}[Y_i \\mid \\mathbf{X_i}]}^{\\mu(\\mathbf{X_i})}}_{\\text{outcome residual}} = \\tau(\\mathbf{X_i}) \\underbrace{( T_i - \\overbrace{\\mathbb{E}[T_i \\mid \\mathbf{X_i}]}^{e(\\mathbf{X_i})})}_{\\text{treatment residual}} + \\epsilon_{Y_i}\\)\n\nThis motivates the R-learner of Nie and Wager, 2020:\n\n\\(\\hat{\\tau}_{\\text{RL}}(\\mathbf{x}) = \\arg \\min_{\\tau} \\sum_{i=1}^n ( Y_i - \\hat{\\mu}(\\mathbf{X_i}) - \\tau(\\mathbf{X_i}) ( T_i - \\hat{e}(\\mathbf{X_i})))^2\\)\nwith cross-fitted high-quality nuisance parameters from first step.\nBut how to estimate it?"
  },
  {
    "objectID": "slides/06_hte.html#r-learner-with-linear-ml-methods",
    "href": "slides/06_hte.html#r-learner-with-linear-ml-methods",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "R-learner with Linear ML-Methods",
    "text": "R-learner with Linear ML-Methods\n\nCATE as linear function \\(\\tau(\\mathbf{X_i}) = \\mathbf{\\beta' X_i}\\):\n\n\\[\n\\begin{align*}\n\\hat{\\beta}_{RL} &= \\underset{\\beta}{\\operatorname{arg\\,min}} \\sum_{i=1}^N( Y_i - \\hat{\\mu}(\\mathbf{X_i}) - \\mathbf{\\beta'} \\underbrace{(T_i - \\hat{e}(\\mathbf{X_i})) \\mathbf{X_i}}_{=\\mathbf{\\tilde{X}_i}})^2 \\\\\n&= \\underset{\\beta}{\\operatorname{arg\\,min}} \\sum_{i=1}^N \\left( Y_i - \\hat{\\mu}(\\mathbf{X_i}) - \\mathbf{\\beta'} \\mathbf{\\tilde{X}_i} \\right)^2\n\\end{align*}\n\\]\n\n\\(\\mathbf{\\tilde{X}_i} = (T_i - \\hat{e}(\\mathbf{X_i})) \\mathbf{X_i}\\) are modified / pseudo-covariates.\n\\(\\hat{\\tau}_{\\text{RL}}(\\mathbf{x}) = \\mathbf{\\hat{\\beta}_{RL} x} \\neq \\mathbf{\\hat{\\beta}_{RL} \\tilde{x}}\\) is the estimated CATE for a specific \\(\\mathbf{x}\\).\nAll linear shrinkage estimators (Lasso and friends) can be applied, nuisance parameters can still be estimated with non-linear ML."
  },
  {
    "objectID": "slides/06_hte.html#r-learner-with-generic-ml-methods",
    "href": "slides/06_hte.html#r-learner-with-generic-ml-methods",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "R-learner with Generic ML-Methods",
    "text": "R-learner with Generic ML-Methods\n\nIf we are not willing to impose linearity of the CATE, we can rewrite the R-learner:\n\n\\[\n\\begin{align*}\n\\hat{\\tau}_{\\text{RL}}(\\mathbf{x}) &= \\arg \\min_{\\tau} \\sum_{i=1}^n ( Y_i - \\hat{\\mu}(\\mathbf{X_i}) - \\tau(\\mathbf{X_i}) ( T_i - \\hat{e}(\\mathbf{X_i})))^2 \\\\\n&= \\arg \\min_{\\tau} \\sum_{i=1}^n \\frac{( T_i - \\hat{e}(\\mathbf{X_i}))^2}{(T_i - \\hat{e}(\\mathbf{X_i}))^2}(Y_i - \\hat{\\mu}(\\mathbf{X_i}) - \\tau(\\mathbf{X_i}) ( T_i - \\hat{e}(\\mathbf{X_i})))^2 \\\\\n&= \\arg \\min_{\\tau} \\sum_{i=1}^n (T_i - \\hat{e}(\\mathbf{X_i}))^2 \\bigg(\\frac{Y_i - \\hat{\\mu}(\\mathbf{X_i}) - \\tau(\\mathbf{X_i}) ( T_i - \\hat{e}(\\mathbf{X_i}))}{ T_i - \\hat{e}(\\mathbf{X_i})}\\bigg)^2 \\\\\n&= \\arg \\min_{\\tau} \\sum_{i=1}^n (T_i - \\hat{e}(\\mathbf{X_i}))^2 \\bigg(\\frac{Y_i - \\hat{\\mu}(\\mathbf{X_i})}{ T_i - \\hat{e}(\\mathbf{X_i})} - \\tau(\\mathbf{X_i})\\bigg)^2 \\\\\n\\end{align*}\n\\]\n\nSupervised ML methods that can deal with weighted minimization (e.g. neural nets, random forest, boosting, …) with\n\nweights: \\((T_i - \\hat{e}(\\mathbf{X_i}))^2\\).\npseudo-outcome: \\(\\frac{Y_i - \\hat{\\mu}(\\mathbf{X_i})}{ T_i - \\hat{e}(\\mathbf{X_i})}\\).\nthe unmodified covariates: \\(\\mathbf{X_i}\\)."
  },
  {
    "objectID": "slides/06_hte.html#dr-learner",
    "href": "slides/06_hte.html#dr-learner",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "DR-learner",
    "text": "DR-learner\n\nRecall the pseudo-outcome of the AIPW-ATE from previous lecture and condition on \\(\\mathbf{X_i}\\) (same “trick” as for GATE estimation):\n\n\\(\\tau_{\\text{DR}}(\\mathbf{x}) = \\mathbb{E}\\bigg[ \\underbrace{\\hat{\\mu}(1, \\mathbf{X_i}) - \\hat{\\mu}(0, \\mathbf{X_i}) + \\frac{T_i(Y_i - \\hat{\\mu}(1, \\mathbf{X_i}))}{ \\hat{e}_1(\\mathbf{X_i})} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}(0, \\mathbf{X_i})}{\\hat{e}_0(\\mathbf{X_i}))}}_{\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}}} \\bigg| \\mathbf{X_i= x} \\bigg]\\)\n\\(\\tau_{\\text{DR}}(\\mathbf{x}) = \\mathbb{E}\\bigg[ \\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} \\bigg| \\mathbf{X_i= x} \\bigg]\\)\n\nDR-learner by Kennedy (2020) uses \\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}}\\) in a generic ML problem:\n\n\\(\\hat{\\tau}_{RL}(\\mathbf{x}) = \\underset{\\tau}{\\operatorname{arg\\,min}} \\sum_{i=1}^N \\left( \\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} - \\tau(\\mathbf{X_i})\\right)^2\\)\nCross-fitting: in 4 subsamples (1) train a model for \\(\\hat{e(\\mathbf{X_i})}\\), (2) train a model for \\(\\hat{\\mu(\\mathbf{X_i})}\\), (3) construct \\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}}\\) and regress on \\(\\mathbf{X_i}\\), (4) predict \\(\\hat{\\tau}_{RL}(\\mathbf{x})\\). Then rotate."
  },
  {
    "objectID": "slides/06_hte.html#dr-learner-example",
    "href": "slides/06_hte.html#dr-learner-example",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "DR-learner: Example",
    "text": "DR-learner: Example\n\nAssess the effect of 401(k) program participation on net financial assets of 9,915 households in the US in 1991.\n\n\n\n\nlibrary(hdm) # for the data\nlibrary(causalDML) # generalized random forests, could also use mlr3\n\n\n# Get data\ndata(pension)\n# Outcome\nY = pension$net_tfa\n# Treatment\nT = pension$p401\n# Create main effects matrix\nX = model.matrix(~ 0 + age + db + educ + fsize + hown + inc + male + marr + pira + twoearn, data = pension)\n\n# Implement the DR-Learner\ndr = dr_learner(Y,T,X,\n      ml_w = list(create_method(\"forest_grf\")),\n      ml_y = list(create_method(\"forest_grf\")),\n      ml_tau = list(create_method(\"forest_grf\"))\n)\n\n# DR-learner distribution of B-A\nhist(dr$cates[,1])"
  },
  {
    "objectID": "slides/06_hte.html#how-to-evaluate-estimated-cates",
    "href": "slides/06_hte.html#how-to-evaluate-estimated-cates",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "How to evaluate estimated CATEs?",
    "text": "How to evaluate estimated CATEs?\n\nDescriptive: histogram, kernel density plots, box plots, etc. …\nInference: test whether effect heterogeneity is systematic or just noise.\nExplore what drives the heterogeneous effects.\n\n\n\nChallenges with inference:\n\nUnique to causal ML: Due to missing counterfactual, we cannot benchmark predicted against effect =&gt; no classic out-of-sample testing.\nShared with supervised ML: statistical inference for predicted CATE is not available or at least challenging.\n\nApproach to inference:\n\nRather than (consistent) estimation of & inference on the individual CATEs directly, derive summary statistics of their (noisy) distribution.\nTest joint hypothesis that there is effect heterogeneity & the applied estimation method is able to detect it at least partially.\n\n\n\n\n\nWe discuss the three methods proposed by Chernozhukov et al. (2017-2023):\n\nBest Linear Predictor (BLP).\nHigh-vs.-low Sorted Group Average Treatment Effect (GATES).\nClassification Analysis (CLAN) to explore what drives the heterogeneous effects."
  },
  {
    "objectID": "slides/06_hte.html#best-linear-predictor-blp---definition",
    "href": "slides/06_hte.html#best-linear-predictor-blp---definition",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Best Linear Predictor (BLP) - Definition",
    "text": "Best Linear Predictor (BLP) - Definition\n\nBLP is defined as the solution of the hypothetical regression of the true CATE on the demeaned predicted CATE:\n\n\n\n\nDefinition “Best Linear Predictor (BLP)”\n\n\nThe best linear predictor of \\(\\tau(\\mathbf{X_i})\\) by \\(\\hat{\\tau}(\\mathbf{X_i})\\) is the solution to:\n\\((\\beta_1, \\beta_2) = \\underset{\\tilde{\\beta_1}, \\tilde{\\beta_2}}{\\operatorname{arg\\,min}} \\space \\mathbb{E} \\left[ \\left( \\tau(\\mathbf{X_i}) - \\tilde{\\beta_1} - \\tilde{\\beta_2} \\left( \\hat{\\tau}(\\mathbf{X_i}) - \\mathbb{E}[\\hat{\\tau}(\\mathbf{X_i})] \\right) \\right)^2 \\right]\\)\n\nwhich, if exists, is defined as\n\n\\(\\mathbb{E}[\\tau(\\mathbf{X_i}) | \\hat{\\tau}(\\mathbf{X_i}) ] := \\beta_1 + \\beta_2\\underbrace{(\\hat{\\tau}(\\mathbf{X_i}) - \\mathbb{E}[\\hat{\\tau}(\\mathbf{X_i})])}_{\\text{demeaned prediction}}\\)\n\nwhere\n\n\\(\\beta_1 = \\mathbb{E}[\\tau(\\mathbf{X_i})] = \\text{ATE} \\text{ (because of the demeaning)}\\)\n\\(\\beta_2 = \\frac{\\text{Cov}[\\tau(\\mathbf{X_i}), \\hat{\\tau}(\\mathbf{X_i})]}{\\text{Var}[\\hat{\\tau}(\\mathbf{X_i})]}\\)"
  },
  {
    "objectID": "slides/06_hte.html#blp---interpretation",
    "href": "slides/06_hte.html#blp---interpretation",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "BLP - Interpretation",
    "text": "BLP - Interpretation\n\n\\(\\beta_2 = \\frac{\\text{Cov}[\\tau(\\mathbf{X_i}), \\hat{\\tau}(\\mathbf{X_i})]}{\\text{Var}[\\hat{\\tau}(\\mathbf{X_i})]} = 1\\) if \\(\\hat{\\tau}(\\mathbf{X_i}) = \\tau(\\mathbf{X_i})\\) (what we would like to see)\n\\(\\beta_2 = 0\\) if \\(\\text{Cov}[\\tau(\\mathbf{X_i}), \\hat{\\tau}(\\mathbf{X_i})] = 0\\), which can have two reasons:\n\n\n\\(\\tau(\\mathbf{X_i})\\) is constant (no heterogeneity to detect).\n\n\n\\(\\tau(\\mathbf{X_i})\\) is not constant but the estimator is not capable of finding it (bad estimator and/or not enough observations).\n\n\nTherefore, testing \\(H_0: \\beta_2 = 0\\) is a joint test of\n\n\nexistence of heterogeneity and\n\n\nthe estimators capability to find it."
  },
  {
    "objectID": "slides/06_hte.html#blp---identification-strategy-a",
    "href": "slides/06_hte.html#blp---identification-strategy-a",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "BLP - Identification Strategy A",
    "text": "BLP - Identification Strategy A\nStrategy A: Weighted residual BLP\n\n\\((\\beta_1, \\beta_2) = \\underset{\\tilde{\\beta_1}, \\tilde{\\beta_2}}{\\operatorname{arg\\,min}} \\space \\mathbb{E} \\left[ \\omega(\\mathbf{X_i}) \\left( Y_i - \\tilde{\\beta_1}(T_i - e(X_i)) - \\tilde{\\beta_2} (T_i - e(X_i)) \\left( \\hat{\\tau}(\\mathbf{X_i}) - \\mathbb{E}[\\hat{\\tau}(\\mathbf{X_i})] \\right) \\color{#005e73}{- \\alpha \\mathbf{X^{C}_{i}}} \\right)^2 \\right]\\)\nwhere:\n\n\\(\\omega(\\mathbf{X_i}) = \\frac{1}{e(\\mathbf{X_i})(1-e(\\mathbf{X_i}))}\\)\n\\(\\color{#005e73}{\\mathbf{X^{C}_{i}}}\\) is not required for identification, but contains optional functions of \\(X_i\\) to reduce estimation noise, e.g. \\([1,\\hat\\mu(0,\\mathbf{X_i}), e(\\mathbf{X_i}), e(\\mathbf{X_i})\\hat{\\tau}(\\mathbf{X_i})]\\)\n\nSee Appendix A in Chernozhukov et al. (2017-2023) for a detailed derivation."
  },
  {
    "objectID": "slides/06_hte.html#blp---identification-strategy-b",
    "href": "slides/06_hte.html#blp---identification-strategy-b",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "BLP - Identification Strategy B",
    "text": "BLP - Identification Strategy B\nStrategy B: Horvitz-Thompson BLP\n\n\\((\\beta_1, \\beta_2) = \\underset{\\tilde{\\beta_1}, \\tilde{\\beta_2}}{\\operatorname{arg\\,min}} \\space \\mathbb{E} \\left[  \\left( H_iY_i - \\tilde{\\beta_1} - \\tilde{\\beta_2} \\left( \\hat{\\tau}(\\mathbf{X_i}) - \\mathbb{E}[\\hat{\\tau}(\\mathbf{X_i})] \\right) \\color{#005e73}{- \\alpha H_i \\mathbf{X^{C}_{i}}} \\right)^2 \\right]\\)\nwhere:\n\n\\(H_i = \\frac{T_i-e(\\mathbf{X_i})}{e(\\mathbf{X_i})(1-e(\\mathbf{X_i}))}\\) are the Horvitz-Thompson (IPW) weights.\n\\(H_iY_i\\) serves as a pseudo-outcome.\n\\(\\color{#005e73}{\\mathbf{X^{C}_{i}}}\\) is not required for identification, but contains optional functions of \\(X_i\\) to reduce estimation noise, e.g. \\([1,\\hat\\mu(0,\\mathbf{X_i}), e(\\mathbf{X_i}), e(\\mathbf{X_i})\\hat{\\tau}(\\mathbf{X_i})]\\)\n\nSee Appendix A in Chernozhukov et al. (2017-2023) for a detailed derivation."
  },
  {
    "objectID": "slides/06_hte.html#sorted-group-average-treatment-effect-gates",
    "href": "slides/06_hte.html#sorted-group-average-treatment-effect-gates",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Sorted Group Average Treatment Effect (GATES)",
    "text": "Sorted Group Average Treatment Effect (GATES)\n\n\n\nIdea:\n\nslice the distribution of \\(\\hat{\\tau}(\\mathbf{X_i})\\) into \\(K\\) parts and compare the average treatment effect of individuals within each slice.\nif \\(\\hat{\\tau}(\\mathbf{X_i})\\) is a good approximation of \\(\\tau(\\mathbf{X_i})\\), then we expect to observe the following monotonicity: \\(\\gamma_1 \\leq \\gamma_2 \\leq \\ldots \\leq \\gamma_K\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition “Sorted Group Average Treatment Effect (GATES)”\n\n\n\\(\\gamma_k := \\mathbb{E}[ \\tau(\\mathbf{X_i}) | G_k]\\), \\(k = 1, \\ldots, K\\)\n\nwhere \\(G_k= \\{\\hat{\\tau}(\\mathbf{X_i}) \\in I_k \\}\\) with \\(I_k = [l_{k-1},l_k)\\) and \\(-\\infty = l_0 &lt; l_1 &lt; \\dots &lt; l_K = \\infty\\)."
  },
  {
    "objectID": "slides/06_hte.html#gates---identification",
    "href": "slides/06_hte.html#gates---identification",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "GATES - Identification",
    "text": "GATES - Identification\nStrategy A: Weighted residual GATES\n\n\\((\\gamma_1, \\dots, \\gamma_K) = \\underset{\\tilde{\\gamma}_1, \\dots, \\tilde{\\gamma}_K}{\\operatorname{arg\\,min}} \\space \\mathbb{E} \\left[ \\omega(\\mathbf{X_i}) \\left( Y_i - \\sum_k\\tilde{\\gamma_k}(T_i - e(X_i))\\mathbb{1}[G_k]  \\color{#005e73}{- \\alpha \\mathbf{X^{C}_{i}}} \\right)^2 \\right]\\)\n\nwhere \\(\\omega(\\mathbf{X_i}) = \\frac{1}{e(\\mathbf{X_i})(1-e(\\mathbf{X_i}))}\\).\n\n\nStrategy B: Horvitz-Thompson GATES\n\n\\((\\gamma_1, \\dots, \\gamma_K) = \\underset{\\tilde{\\gamma}_1, \\dots, \\tilde{\\gamma}_K}{\\operatorname{arg\\,min}} \\space \\mathbb{E} \\left[  \\left( H_iY_i -\\sum_k \\tilde{\\gamma_k}\\mathbb{1}[G_k] \\color{#005e73}{- \\alpha H_i \\mathbf{X^{C}_{i}}} \\right)^2 \\right]\\)\n\nwhere \\(H_iY_i\\) serves as a pseudo-outcome and \\(H_i = \\frac{T_i-e(\\mathbf{X_i})}{e(\\mathbf{X_i})(1-e(\\mathbf{X_i}))}\\) being the Horvitz-Thompson (IPW) weights.\n\n\\(\\color{#005e73}{\\mathbf{X^{C}_{i}}}\\) is not required for identification, but contains optional functions of \\(X_i\\) to reduce estimation noise, e.g. \\([1,\\hat\\mu(0,\\mathbf{X_i}), e(\\mathbf{X_i}), e(\\mathbf{X_i})\\hat{\\tau}(\\mathbf{X_i})]\\)\nSee Appendix A in Chernozhukov et al. (2017-2023) for a detailed derivation."
  },
  {
    "objectID": "slides/06_hte.html#classification-analysis-clan",
    "href": "slides/06_hte.html#classification-analysis-clan",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Classification Analysis (CLAN)",
    "text": "Classification Analysis (CLAN)\nClassification Analysis (CLAN) can be implemented by simple mean comparisons of covariates in extreme GATES groups:\n\n\n\nDefinition “Classification Analysis (CLAN)”\n\n\nClassification Analysis (CLAN) compares the covariate values of the least affected group G1 with the most affected group GK defined for the GATES:\n\n\\(\\delta_K - \\delta_1\\)\n\nwhere\n\n\\(\\delta_k = \\mathbb{E}[X_i | G_k] = \\frac{1}{n_k} \\sum_{i=1}^{n} X_i \\mathbb{1}[G_k]\\)."
  },
  {
    "objectID": "slides/06_hte.html#blp-gates-clan---implementation",
    "href": "slides/06_hte.html#blp-gates-clan---implementation",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "BLP, GATES & CLAN - Implementation",
    "text": "BLP, GATES & CLAN - Implementation\n\nR package GenericML by Welz, Alfons, Demirer, and Chernozhukov (2022). \nAlgorithm:\n\nIN: \\(\\text{Data} = (Y_i, \\mathbf{X_i}, T_i )^{N}_{i=1}\\), significance level \\(\\alpha\\), a suite of ML methods, number of splits \\(S\\).\nOUT: \\(p-\\text{values}\\) and \\((1-2\\alpha)\\) confidence intervals of point estimates of each target parameter in GATES, BLP, and CLAN. \n\n\nCompute propensity scores \\(\\hat{e}(\\mathbf{X_i})\\).\nDo S splits of \\(\\{1, . . . ,N\\}\\) into disjoint sets \\(A\\) and \\(M\\) of same size.\nfor each ML method and each split \\(s = 1, . . . , S\\), do\n\nTune and train each ML method to learn \\(\\hat{\\mu}(0, \\mathbf{X_i})\\) and \\(\\hat{\\tau}(\\mathbf{X_i})\\) on A.\nOn M, use \\(\\hat{\\mu}(0, \\mathbf{X_i})\\) and \\(\\hat{\\tau}(\\mathbf{X_i})\\) to estimate the BLP, GATES, CLAN target parameters.\nCompute some performance measures for the ML methods.\n\nChoose the best ML method based on the medians of the performance measures.\nCalculate the medians of the confidence bounds, p-values, and point estimates of each target parameter.\nAdjust the confidence bounds and p-values."
  },
  {
    "objectID": "slides/06_hte.html#more-references",
    "href": "slides/06_hte.html#more-references",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "More References",
    "text": "More References\n\nCATE Prediction Methods:\n\nBART (Hahn, Murray & Carvalho, 2020).\nCausal Boosting/MARS, … (Powers, Qian, Jung, Schuler, Shah, Hastie & Tibshirani, 2019).\nDragonnet (Shi, Blei & Veitch, 20191).\nModified Causal Forest (Lechner & Mareckova, 2022).\nOrthogonal Random Forest (Oprescu, Syrgkanis & Wu, 2019).\nTARNet (Shalit, Johansson & Sontag 2019).\nX-learner (Künzel, Sekhon, Bickel & Yu, 2019).\n\n\n\n\nHET Evaluation:\n\nRank-Weighted Average Treatment Effect (RATE) (Yadlowsky et al., 2021).\nCalibration Error for Heterogeneous Treatment Effects (Xu & Yadlowsky, 2022).\nMore on GATES in experiments (Imai & Li, 2022-2024)."
  },
  {
    "objectID": "slides/06_hte.html#optimal-policy-learning---goal",
    "href": "slides/06_hte.html#optimal-policy-learning---goal",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Optimal Policy Learning - Goal",
    "text": "Optimal Policy Learning - Goal\n\nFrom evaluation (What works for whom?) towards data-driven (personalized) treatment recommendations:\n\nHow to optimally treat whom?  \n\nNotation:\n\nBinary treatment indicator: \\(T_i \\in \\{0, 1\\}\\)\nPotential outcome (PO) under treatment \\(t\\): \\(Y_i(t)\\)\nExogenous covariate(s): \\(\\mathbf{X_i}\\)\nConditional Average PO: \\(\\mu_t(\\mathbf{x}) := \\mathbb{E}[Y(t) \\mid \\mathbf{X_i = x}]\\)\nConditional Average Treatment Effect (CATE): \\(\\tau(\\mathbf{x}) := \\mu_1(\\mathbf{x}) - \\mu_0(\\mathbf{x})\\)\n\nAdditional notation:\n\nPolicy rule for \\(x\\) (conditional treatment choice): \\(\\pi(\\mathbf{X_i}) \\in \\{0,1\\}\\).\nPO under policy \\(\\pi(\\mathbf{X_i})\\): \\(Y_i(\\pi(\\mathbf{X_i}))\\).\nValue function (average PO under policy \\(\\pi(\\mathbf{X_i})\\)): \\(Q(\\pi) := \\mathbb{E}[Y_i(\\pi(\\mathbf{X_i}))]\\).  \n\nGoal: Find the optimal policy \\(\\pi^*\\) that maximizes the value function \\(Q(\\pi)\\)."
  },
  {
    "objectID": "slides/06_hte.html#optimal-policy-alternatives",
    "href": "slides/06_hte.html#optimal-policy-alternatives",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Optimal Policy Alternatives",
    "text": "Optimal Policy Alternatives\n\n\nAssign individuals to treatment with higher PO under treatment than without?\n\n\n\\(\\pi^* = \\mathbb{1}[Y_i(1) &gt; Y_i(0)] = \\mathbb{1}[Y_i(1) - Y_i(0) &gt; 0] = \\mathbb{1}[\\tau_i &gt; 0]\\)\nFundamental problem of causal inference: counterfactuals unknown.\n\n\n\n\n\nAssign individuals to treatment with higher CATE than without?\n\n\n\\(\\pi^* = \\mathbb{1}[Y_i(1) &gt; Y_i(0) | \\mathbf{X_i = x}] = \\mathbb{1}[\\tau(\\mathbf{X_i = x}) &gt; 0]\\)\nProblem: minimizing \\(\\text{MSE}_{\\text{CATE}} = \\mathbb{E}[(\\hat{\\tau}(\\mathbf{x}) - \\tau(\\mathbf{x})^2]\\) does not necessarily improve downstream policy rule learning (Qian & Murphy, 2011).\nSimilar to the case where MSE minimization in treated and control groups separately is not the best strategy to minimize CATE MSE.\n\n\n\n\n\n\nInstead: \\(\\pi^* = \\underset{\\pi}{\\operatorname{arg\\,min}} \\space \\mathbb{E}[Y_i(\\pi(\\mathbf{X_i}))] = \\underset{\\pi}{\\operatorname{arg\\,min}} \\space Q(\\pi(\\mathbf{X_i})))\\)"
  },
  {
    "objectID": "slides/06_hte.html#optimal-policy-objective-function",
    "href": "slides/06_hte.html#optimal-policy-objective-function",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Optimal Policy Objective Function",
    "text": "Optimal Policy Objective Function\n\nObjective function can have many different forms but one has proven very useful in the context of ML policy learning:\n\nComparing the value function against a benchmark policy that assigns treatments via fair coin flip:\n\n50-50 chance of being treated: \\(\\pi^{\\text{coin}} \\sim \\text{Bernoulli}(0,5)\\).\n\n\n\n\\[\n\\begin{align*}\n\\pi^* &= \\arg \\max_{\\pi} Q(\\pi) = \\arg \\max_{\\pi} \\mathbb{E}[Y(\\pi)] = \\arg \\max_{\\pi} \\mathbb{E}[Y(\\pi) \\color{#005e73}{- 0.5 \\mathbb{E}[Y(1)] + 0.5 \\mathbb{E}[Y(0)]}] \\\\\n&= \\arg \\max_{\\pi} \\mathbb{E}[\\pi Y(1) + (1 - \\pi) Y(0)] - 0.5 \\mathbb{E}[Y(1)] - 0.5 \\mathbb{E}[Y(0)] \\\\\n&= \\arg \\max_{\\pi} \\mathbb{E}[(\\pi - 0.5) Y(1)] + \\mathbb{E}[(0.5 - \\pi) Y(0)] = \\arg \\max_{\\pi} \\mathbb{E}[(\\pi - 0.5) (Y(1) - Y(0))] \\\\\n&= \\arg \\max_{\\pi}  \\color{#005e73}{2} \\mathbb{E}[(\\pi - 0.5) (Y(1) - Y(0))] \\\\\n&= \\arg \\max_{\\pi} \\mathbb{E}[(2\\pi - 1)(Y(1) - Y(0))] \\\\\n&\\overset{LIE}{=} \\arg \\max_{\\pi} \\mathbb{E}[(2\\pi - 1) \\tau(\\mathbf{X_i})] \\\\\n&= \\arg \\max_{\\pi}  \\underbrace{\\mathbb{E}[|\\tau(\\mathbf{X_i})| \\text{sign}(\\tau(\\mathbf{X_i})) (2\\pi(\\mathbf{X_i}) - 1)]}_{A(\\pi)} \\\\\n\\end{align*}\n\\]\n\nwhere \\((2\\pi(\\mathbf{X_i}) - 1) \\in \\{-1,1\\}\\) is one if policy assigns treatment and minus one if not."
  },
  {
    "objectID": "slides/06_hte.html#optimal-policy-objective-function---intuition",
    "href": "slides/06_hte.html#optimal-policy-objective-function---intuition",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Optimal Policy Objective Function - Intuition",
    "text": "Optimal Policy Objective Function - Intuition\n\n\\(A(\\pi) := \\mathbb{E}[|\\tau(\\mathbf{X_i})| \\text{sign}(\\tau(\\mathbf{X_i})) (2\\pi(\\mathbf{X_i}) - 1)]\\) measures the advantage of a policy compared to random allocation:\n\nIf \\(\\text{sign}(\\tau(\\mathbf{X_i})) (2\\pi(\\mathbf{X_i}) - 1) = 1\\), i.e. if the policy picks the better treatment for \\(\\mathbf{X_i}\\), we earn the absolute value of the CATE.\nIf \\(\\text{sign}(\\tau(\\mathbf{X_i})) (2\\pi(\\mathbf{X_i}) - 1) = -1\\), i.e. if the policy picks the worse treatment for \\(\\mathbf{X_i}\\), we lose the absolute value of the CATE.\n\nWe need to get it right for those with biggest CATEs, those with CATEs close to zero are negligible.\nThis shows the difference to CATE MSE minimization, where we need to find good approximations everywhere."
  },
  {
    "objectID": "slides/06_hte.html#optimal-policy-identification-estimation",
    "href": "slides/06_hte.html#optimal-policy-identification-estimation",
    "title": "(6) Heterogeneous Treatment Effects",
    "section": "Optimal Policy Identification & Estimation",
    "text": "Optimal Policy Identification & Estimation\n\nPotential outcomes or CATE functions unknown, need to be identified before optimization.\nAthey and Wager (2021) recommend the pseudo-outcome (again) because of all the nice properties:\n\n\\(\\tilde{\\tau_i}_{\\text{ATE}}^{\\text{AIPW}} = \\hat{\\mu}(1, \\mathbf{X_i}) - \\hat{\\mu}(0, \\mathbf{X_i}) + \\frac{T_i(Y_i - \\hat{\\mu}(1, \\mathbf{X_i}))}{\\hat{e}_1(\\mathbf{X_i})} - \\frac{(1-T_i)(Y_i - \\hat{\\mu}(0, \\mathbf{X_i})}{\\hat{e}_0(\\mathbf{X_i}))}\\)\n\n\n\n\nBinary weighted classification problem: classify the sign of the CATE while favoring correct classifications with larger absolute CATEs.\n\n\\(\\hat{\\pi} = \\underset{\\pi \\in \\Pi}{\\arg \\max} \\left\\{ \\frac{1}{N} \\sum_{i=1}^N \\overbrace{|\\hat{Y}_{i,\\text{ATE}}|}^{\\text{weight}} \\underbrace{\\operatorname{sign}(\\hat{Y}_{i,\\text{ATE}}}_{\\text{to be classified}} \\overbrace{(2\\pi(X_i) - 1)}^{\\text{function to be learned}} \\right\\}\\)\n\nPossible methods: e.g. decision trees/forests, logistic lasso, SVM, etc."
  }
]